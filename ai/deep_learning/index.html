<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Deep learning PRO - Documentación de Javi</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Deep learning PRO";
        var mkdocs_page_input_path = "ai/deep_learning.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Documentación de Javi
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">CLI tools</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/bash/">Bash</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/git/">GIT</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/jupyter/">Jupyter</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/nano/">Nano</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/pacman/">Pacman</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/ssh/">SSH</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/tmux/">TMUX</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/vim/">Vim</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/bash/">ZSH</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">CLI data tools</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/free_text/">⚪️ FREE TEXT (regex)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/csv/">🟢 Excel,CSV,TSV (cut, paste, tr, sed, awk)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/html/">🟡 HTML (pup)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/json/">🟠 JSON (jq)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/pdf/">🔴 PDF (Xpdf, poppler)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/image/">🔵 Image (ImageMagick)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools_data/sound_video/">🟣 Sound,Video (ffmepg, sox)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Software 1.0</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/bash/">Bash</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/python/">Python</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/ruby/">♦️ Ruby</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/monitoring/">Monitoring</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/profiling/">Profiling</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/debugging/">Debugging</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../programming/makefile/">Makefile</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Software 2.0</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../numpy.md">🟦 Numpy</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../machine_learning.md">🟫 Sklearn</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../pytorch.md">🟥 Pytorch</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../tensorflow.md">🟧 Tensorflow</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../onnx.md">⬜️ ONNX</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../tensorrt.md">🟩 TensorRT</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Others</span></p>
              <ul>
                  <li class="toctree-l1"><a class="" href="../../others/process.md">⏳ Process</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../others/cryptography.md">🔑 Cryptography</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/linux_insides/">Linux insides</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/remote_administration/">🖥️ Remote admin</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/web_scraping/">⬇️ Web Scraping (curl, wget)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/pentesting/">🗡️ Pentesting (nmap)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/deffensive/">🛡️ Deffensive</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../others/dns.md">DNS (dig, nslookup, whois)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/vpn/">VPN</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/firewall/">📛 Firewall</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../others/packets.md">📦 Packets (wireshark)</a>
                  </li>
                  <li class="toctree-l1"><a class="" href="../../others/load_balancer.md">Load balancer</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../others/public_ip/">Public IP</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Documentación de Javi</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" alt="Docs"></a> &raquo;</li><li>Deep learning PRO</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>

          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="deep-learning-pro">Deep learning PRO</h1>
<h2 id="1-read-data-from-disk-fast">1. Read data from disk fast</h2>
<ul>
<li>ERROR: Slow reading</li>
<li>PIL</li>
<li>OpenCV</li>
<li>GOOD: Fast file reading</li>
<li>turbojpeg: For faster</li>
<li>VERY GOOD: Preparsear los ficheros y cargar diercamente el tensor</li>
<li>Numpy Memmap or Torch storage</li>
<li><a href="https://ffcv.io">FFCV</a></li>
</ul>
<blockquote>
<p>Note: Buy NVMe drives and put the dataset there</p>
</blockquote>
<h2 id="2-fast-dataaug-transfoms">2. Fast DataAug &amp; transfoms</h2>
<ul>
<li>ERROR</li>
<li>Torchvision tranforms (based on PIL)</li>
<li>Albumatations (based on OpenCV)</li>
<li>GOOD</li>
<li>Fastai agmentations (on GPU)</li>
<li>Kornia: agmentations (on GPU)</li>
</ul>
<h2 id="3-model-optimizaation">3. Model optimizaation</h2>
<ul>
<li>Quantization aware training</li>
<li>Float16</li>
</ul>
<h2 id="4-training-loop-optimization">4. Training loop optimization</h2>
<ul>
<li>Composer</li>
</ul>
<h2 id="5-distributed-treainng-several-gpus">5. Distributed treainng (Several GPUs)</h2>
<ul>
<li><a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">Pytorch DDP</a>: Data parallelisom</li>
<li><a href="https://www.deepspeed.ai">DeepSpeed</a>: : Model parallelisom</li>
<li><a href="https://fairscale.readthedocs.io/en/stable/api/nn/fsdp.html">FSDP</a></li>
</ul>
<blockquote>
<h2 id="references">References</h2>
<ul>
<li>https://pytorch.org/blog/efficient-pytorch-io-library-for-large-datasets-many-files-many-gpus/</li>
<li>https://towardsdatascience.com/setting-a-strong-deep-learning-baseline-in-minutes-with-pytorch-c0dfe41f7d7</li>
<li>https://towardsdatascience.com/gpus-are-fast-datasets-are-your-bottleneck-e5ac9bf2ad27</li>
<li>https://towardsdatascience.com/pytorch-lightning-vs-deepspeed-vs-fsdp-vs-ffcv-vs-e0d6b2a95719</li>
<li>https://neptune.ai/blog/image-segmentation-tips-and-tricks-from-kaggle-competitions</li>
</ul>
</blockquote>
<h2 id="avoid-cuda-out-of-memory-oom-error-5-1-tricks">AVOID CUDA OUT OF MEMORY (OOM) ERROR. 5 + 1 tricks</h2>
<p>If you get a OOM error on the first batch, try...</p>
<table>
<thead>
<tr>
<th>Trick</th>
<th>Description</th>
<th>Disadvantage</th>
</tr>
</thead>
<tbody>
<tr>
<td>1. Smaller batch size</td>
<td>Use Gradient Accumulation to simultate larger BS</td>
<td>Slower training</td>
</tr>
<tr>
<td>2. Smaller input size</td>
<td>Decrease image resolution</td>
<td>Lower accuracy</td>
</tr>
<tr>
<td>3. Smaller model</td>
<td></td>
<td>Lower accuracy</td>
</tr>
<tr>
<td>4. Half/Mixed precision</td>
<td>Float16 instead of Float32</td>
<td>Lower accuracy. Training may not converge…</td>
</tr>
<tr>
<td>5. Gradient checkpointing</td>
<td>Compute some acts again instad of store them</td>
<td>Slower training</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Gradient checkpointing is also known as Buffer checkpointing
Gradient checkpointing reduces the model's memory cost by 60%..70% (at the cost of 25% greater training time).</p>
</blockquote>
<h3 id="extra-6th-trick-do-not-store-the-unnecesary-cuda-variables-in-the-training-loop">Extra 6th trick: Do not store the unnecesary cuda variables in the training loop.</h3>
<p>If you get a OOM error in the middle of training, you probably has an increasingly memeory leak.</p>
<p>Delete it after the loss computation</p>
<pre><code class="language-python">output = model(input)
loss   = loss_fn(output, target)
del output
gc.collect()
</code></pre>
<p>Or do comoute the loss directly:</p>
<pre><code class="language-python">loss = loss_fn(model(input), target)
</code></pre>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Pytorch code</th>
<th>GPU memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>(0) Model to GPU</td>
<td><code>model.cuda()</code></td>
<td>model</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(1) Foward pass</td>
<td><code>out = model(inp)</code></td>
<td>model + activations + out</td>
</tr>
<tr>
<td>(1) Loss func</td>
<td><code>l = loss(out, tar)</code></td>
<td>model + activations + out + l</td>
</tr>
<tr>
<td>(1) Backward pass</td>
<td><code>l.backward()</code></td>
<td>model + out + l + grads</td>
</tr>
<tr>
<td>(1) Optimizer step</td>
<td><code>optimizer.step()</code></td>
<td>model + out + l + grads + grads_mom</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>(2) Foward pass</td>
<td><code>out = model(inp)</code></td>
<td>model + activations + out</td>
</tr>
<tr>
<td>(2) Loss func</td>
<td><code>l = loss(out, tar)</code></td>
<td>model + activations + out + l</td>
</tr>
<tr>
<td>(2) Backward pass</td>
<td><code>l.backward()</code></td>
<td>model + out + l + grads</td>
</tr>
<tr>
<td>(2) Optimizer step</td>
<td><code>optimizer.step()</code></td>
<td>model + out + l + grads + grads_mom</td>
</tr>
</tbody>
</table>
<h3 id="faq">FAQ</h3>
<h4 id="why-do-i-need-to-store-the-activations-during-the-foward-pass">Why do I need to store the activations during the foward pass?</h4>
<p>Each layer with learnable parameters will need to store its input until the backward pass due to the <strong>chain rule</strong></p>
<blockquote>
<h3 id="reference">Reference</h3>
<ul>
<li><a href="https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/02/19/gradient-accumulation.html">Gradient Accumulation</a></li>
<li><a href="https://spell.ml/blog/gradient-checkpointing-pytorch-YGypLBAAACEAefHs">Gradient Checkpointing 1</a></li>
<li><a href="https://github.com/prigoyal/pytorch_memonger/blob/master/tutorial/Checkpointing_for_PyTorch_models.ipynb">Gradient Checkpointing 2</a></li>
<li><a href="https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html">Pytorch Performance Tuning Guide</a></li>
<li><a href="https://towardsdatascience.com/7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259">7 Tips To Maximize PyTorch Performance</a></li>
<li><a href="https://medium.com/deep-learning-for-protein-design/a-comprehensive-guide-to-memory-usage-in-pytorch-b9b7c78031d3">Memory usage in Pytorch 1</a></li>
<li><a href="https://www.sicara.fr/blog/2019-28-10-deep-learning-memory-usage-and-pytorch-optimization-tricks">Memory usage in Pytorch 2</a></li>
</ul>
</blockquote>
<h2 id="layer-wise-learning-rate-in-pytorch">Layer-Wise Learning Rate in PyTorch</h2>
<p>https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2022/03/29/discriminative-lr.html</p>
              
            </div>
          </div><footer>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
