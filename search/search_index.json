{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Useful resources Bash https://www.slackbook.org/html/ Advanced Bash-Scripting Guide by Mendel Cooper Bash Reference Manual \u2b50 The Bash Hackers Wiki \u2b50\u2b50 Greg Wooledge's Wiki \u2b50\u2b50\u2b50 Massive information about Bash and UNIX. BashGuide For learing Bash. Start here. BashSheet For a quick reference of Bash. BashProgramming For more advanced shell topics. BashFAQ 121 Frequently Asked Questions about Bash. BashPitfalls Common mistakes made by Bash programmers. Data science Data Science at the Command Line, 2nd edition (2021) Command Line Data Wrangling (Github readme) Command-line Tools can be 235x Faster than your Hadoop Cluster Reverse Engineering Google Colab The Missing Semester MIT Course 2020 Course 2019 Linux internals linux-insides Understanding the bin, sbin, usr/bin, usr/sbin split C/C++ https://www.youtube.com/user/Nietmetal Misc DevOps notes readthedocs Julia Evans a tornado of razorblades BY ADAM WIGGINS Fun Tech Projects A Web Server in 1 Line of Bash Everything you ever wanted to know about terminals (but were afraid to ask) Why is using a shell loop to process text considered bad practice? Documentaci\u00f3n de Alvaro Sainz-Pardo Programming Historian lessons Suck less Linuxjourney Linuxito","title":"Home"},{"location":"#useful-resources","text":"","title":"Useful resources"},{"location":"#bash","text":"https://www.slackbook.org/html/ Advanced Bash-Scripting Guide by Mendel Cooper Bash Reference Manual \u2b50 The Bash Hackers Wiki \u2b50\u2b50 Greg Wooledge's Wiki \u2b50\u2b50\u2b50 Massive information about Bash and UNIX. BashGuide For learing Bash. Start here. BashSheet For a quick reference of Bash. BashProgramming For more advanced shell topics. BashFAQ 121 Frequently Asked Questions about Bash. BashPitfalls Common mistakes made by Bash programmers.","title":"Bash"},{"location":"#data-science","text":"Data Science at the Command Line, 2nd edition (2021) Command Line Data Wrangling (Github readme) Command-line Tools can be 235x Faster than your Hadoop Cluster Reverse Engineering Google Colab","title":"Data science"},{"location":"#the-missing-semester-mit","text":"Course 2020 Course 2019","title":"The Missing Semester MIT"},{"location":"#linux-internals","text":"linux-insides Understanding the bin, sbin, usr/bin, usr/sbin split","title":"Linux internals"},{"location":"#cc","text":"https://www.youtube.com/user/Nietmetal","title":"C/C++"},{"location":"#misc","text":"DevOps notes readthedocs Julia Evans a tornado of razorblades BY ADAM WIGGINS Fun Tech Projects A Web Server in 1 Line of Bash Everything you ever wanted to know about terminals (but were afraid to ask) Why is using a shell loop to process text considered bad practice? Documentaci\u00f3n de Alvaro Sainz-Pardo Programming Historian lessons Suck less Linuxjourney Linuxito","title":"Misc"},{"location":"cli_tools/1_dirs/","text":"Directories ############## Programas which echo # En que path est\u00e1 el programa echo man echo # Muestra el manual de un programa tldr echo # Muestra el manual de ejemplos de un programa lsb_release -a # Ver mi sistema operativo man title Man sections 1 User-level commands and applications 2 System calls and kernel error codes 3 Library calls 4 Device drivers and network protocols 5 configuration file . Standard file formats 6 Games and demonstrations 7 Miscellaneous files and documents 8 System administration commands 9 Obscure kernel specs and interfaces \ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f Navigate pwd : p rint w orking d irectory cd c hange d irectory cd : go to home cd ~ : go to home cd / : go to root cd - : go to previous dir ls : l i s t directories ls -a : show hidden too ls -l : show long (more info: permissions, size, date) `ls -lh: Human readable size `ls -S: Sort files by size ls *.png : only png files ls *.??g : only png and jpg files lsd : Better ls tree lsd --tree Better tree broot nnn ranger \ud83d\udd0e Search: find find ..... 2>/dev/null Do not show STDERR (denied acces) find {where} -name {what} -type {what type} find /etc Filter by type/name/path find . -type f Find only files find . -type d Find only directories find . -name '*.tar.gz' find . -name src -type d Find all directories named src find . -path '*/test/*.py' -type f Find all python files that have a folder named test in their path Filter by modification time find . -mtime -1 Find all files modified in the last day Filter by permission find -readable -writabe -executable find -readable -writabe ! -executable Filter by size find . -size 500c Exact 500 bytes find . -size +500k -size -10M Find all zip files with size in range 500k to 10M Find, then do some action find . -name '*.tmp' -exec rm {} \\; Delete all files with .tmp extension find . -name '*.png' -exec convert {} {}.jpg \\; Find all PNG files and convert them to JPG fd : a simple, fast, and user-friendly alternative to find . \ud83d\udd0e indexed search: updatedb + locate locate is FreeBSD includes locate as part of the base system. In Linux, the old implementation of locate is in the mlocate package, the current implemetation is plocate $ sudo updatedb compiles some sort of indexed database for quickly searching. Usually updated daily via cron or systemD timers. $ locate some_file uses the database for quickly searching. (Actually is plocate ) With the existing systemD timer - /lib/systemd/system/plocate-updatedb.service - /lib/systemd/system/plocate-updatedb.timer sudo pacman -S locate # This installs plocate sudo systemctl enable plocate-updatedb.timer sudo systemctl start plocate-updatedb.timer Find installed programs which whereis pacman -Q \ud83d\udcbd Disk usage du : d isk u sage du FILE : Disk usage of a file du -sh */ | sort -rh du -sh -- * | sort -h -r Disk usage of current dir ncdu FILE : Interactive version of Disk usage dust duf df / \ud83d\udcbd Hard drives See available drives Option 1: lsblk Option 2: fdisk -l Option 3: ls /dev/sd?? Mount sudo mkdir /hdd sudo mount -t auto /dev/sda1 /hdd Umount umount /hdd \ud83d\udccd Special dirs /dev devices /dev/sd?? Hard drive /dev/tcp/127.0.0.1/30000 TCP connection on 127.0.0.1:3000 /proc Procesos /sys System hardware (brightness, leds, sensors,...) /sys/class/thermal/thermal_zone*/temp CPU temperature","title":"\ud83d\udcc1 Dirs (cd,ls,find,ranger)"},{"location":"cli_tools/1_dirs/#directories","text":"############## Programas which echo # En que path est\u00e1 el programa echo man echo # Muestra el manual de un programa tldr echo # Muestra el manual de ejemplos de un programa lsb_release -a # Ver mi sistema operativo man title Man sections 1 User-level commands and applications 2 System calls and kernel error codes 3 Library calls 4 Device drivers and network protocols 5 configuration file . Standard file formats 6 Games and demonstrations 7 Miscellaneous files and documents 8 System administration commands 9 Obscure kernel specs and interfaces","title":"Directories"},{"location":"cli_tools/1_dirs/#navigate","text":"pwd : p rint w orking d irectory cd c hange d irectory cd : go to home cd ~ : go to home cd / : go to root cd - : go to previous dir ls : l i s t directories ls -a : show hidden too ls -l : show long (more info: permissions, size, date) `ls -lh: Human readable size `ls -S: Sort files by size ls *.png : only png files ls *.??g : only png and jpg files lsd : Better ls tree lsd --tree Better tree broot nnn ranger","title":"\ud83d\udeb6\ud83c\udffb\u200d\u2642\ufe0f Navigate"},{"location":"cli_tools/1_dirs/#search-find","text":"find ..... 2>/dev/null Do not show STDERR (denied acces) find {where} -name {what} -type {what type} find /etc","title":"\ud83d\udd0e Search: find"},{"location":"cli_tools/1_dirs/#filter-by-typenamepath","text":"find . -type f Find only files find . -type d Find only directories find . -name '*.tar.gz' find . -name src -type d Find all directories named src find . -path '*/test/*.py' -type f Find all python files that have a folder named test in their path","title":"Filter by type/name/path"},{"location":"cli_tools/1_dirs/#filter-by-modification-time","text":"find . -mtime -1 Find all files modified in the last day","title":"Filter by modification time"},{"location":"cli_tools/1_dirs/#filter-by-permission","text":"find -readable -writabe -executable find -readable -writabe ! -executable","title":"Filter by permission"},{"location":"cli_tools/1_dirs/#filter-by-size","text":"find . -size 500c Exact 500 bytes find . -size +500k -size -10M Find all zip files with size in range 500k to 10M","title":"Filter by size"},{"location":"cli_tools/1_dirs/#find-then-do-some-action","text":"find . -name '*.tmp' -exec rm {} \\; Delete all files with .tmp extension find . -name '*.png' -exec convert {} {}.jpg \\; Find all PNG files and convert them to JPG fd : a simple, fast, and user-friendly alternative to find .","title":"Find, then do some action"},{"location":"cli_tools/1_dirs/#indexed-search-updatedb-locate","text":"locate is FreeBSD includes locate as part of the base system. In Linux, the old implementation of locate is in the mlocate package, the current implemetation is plocate $ sudo updatedb compiles some sort of indexed database for quickly searching. Usually updated daily via cron or systemD timers. $ locate some_file uses the database for quickly searching. (Actually is plocate ) With the existing systemD timer - /lib/systemd/system/plocate-updatedb.service - /lib/systemd/system/plocate-updatedb.timer sudo pacman -S locate # This installs plocate sudo systemctl enable plocate-updatedb.timer sudo systemctl start plocate-updatedb.timer","title":"\ud83d\udd0e indexed search: updatedb + locate"},{"location":"cli_tools/1_dirs/#find-installed-programs","text":"which whereis pacman -Q","title":"Find installed programs"},{"location":"cli_tools/1_dirs/#disk-usage","text":"du : d isk u sage du FILE : Disk usage of a file du -sh */ | sort -rh du -sh -- * | sort -h -r Disk usage of current dir ncdu FILE : Interactive version of Disk usage dust duf df /","title":"\ud83d\udcbd Disk usage"},{"location":"cli_tools/1_dirs/#hard-drives","text":"See available drives Option 1: lsblk Option 2: fdisk -l Option 3: ls /dev/sd?? Mount sudo mkdir /hdd sudo mount -t auto /dev/sda1 /hdd Umount umount /hdd","title":"\ud83d\udcbd Hard drives"},{"location":"cli_tools/1_dirs/#special-dirs","text":"/dev devices /dev/sd?? Hard drive /dev/tcp/127.0.0.1/30000 TCP connection on 127.0.0.1:3000 /proc Procesos /sys System hardware (brightness, leds, sensors,...) /sys/class/thermal/thermal_zone*/temp CPU temperature","title":"\ud83d\udccd Special dirs"},{"location":"cli_tools/2_files/","text":"Files Types of files file directory executable symbolic link socket FIFO whiteout (not in Linux, only in UNIX) Linux. it's a type of file that stops further lookup for a file but reports that it doesn't exist. \ud83d\udc41\ufe0f See files See head or tail of file head : shows the beginning of a file (defaults to first 10 lines). head -n5 : only 5 lines tail : shows the ending of a file (defaults to last 10 lines). tail -n5 : only 5 lines (head; echo ...;tail) shows head and tail (head; tail) < file.txt cat file.txt | (head; tail) See entire content of text file cat : con cat enate and print files. bat : Better cat mdcat : cat for markdown Pager ( echo $PAGER ) more : less : Beter than more. Interactive file viwer. Load the file dynamically (faster than cat) less -N Add line number most : Better than less. Capable of viewing any number of files. See entire content of binary files cat file | od -c | head hexdump : Para ver ficheros binarios xxd : make a hexdump or do the reverse. hexeditor : strings my_file : See parts of text data in a binary file See info file stat file my_file stat my_file Rename, Move and copy files mv OLD NEW : Move or rename files or directories for file in *; do; mv \"$file ${file// /_}\"; done; : Replace spaces with underscores cp FROM TO : Copy a file rm PATH : Remove a file rm -r PATH : Remove a directory recusively rmdir PATH : Remove an empty directory touch NEW_FILE : Create a file mkdir PATH : Make a directory mkdir My\\ photos : Make a directory with spaces mkdir \"My photos\" : Make a directory with spaces ln FROM TO : Create link (acceso directo) ln src_file dest_file : Hard link ln -s src_file dest_file : Symbolic link ln -s -f src_file dest_file : Symbolyc link \ud83d\uddd1\ufe0f Deep remove files scrub : Real delete files in disk shred : Real delete files in disk bash deep_rm () { scrub -p dod $1 shred -zun 10 -v $1 } Compare files and Find duplicates cmp diff comm comm -12 <(sort words.txt | uniq) <(sort countries.txt | uniq) comm -23 <(ls march) <(ls april) OPTION A) Comparing filenames ls | sort | uniq -d OPTION B) Comparing line by line (text files) diff {file1} {file2} : See differencs between files sdiff {file1} {file2} : side-by-side merge of file differences cmp {file1} {file2} : See differencs between files comm : select or reject lines comm on to two files OPTION C) Comparing Byte by byte (binary files) OPTION D) Comparing Checksums, hashes, fingerprints md5sum sha1sum, Some filesytems already computes th checksums ZFS: Performs automatic file integrity checking using checksums fdupes: https://atareao.es/software/utilidades/eliminar-duplicados https://unix.stackexchange.com/questions/28895/open-source-duplicate-image-finder-for-linux Type of files and magic numbers The first bytes of a file determine the type of file file * : see the types of every file in the current directory Magic numbers: 89 50 4e 47 0d 0a 1a 0a magic number of PNG file Users and Privileges (when ls -l ) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500> Permission of user (owner) \u2502 \u250c\u2500\u2500\u2500\u2500> Permission of group (of users) \u2502 \u2502 \u250c\u2500> Permission of others (users) \u2502 \u2502 \u2502 / \\/ \\/ \\ rwxrwxrwx ownerUser userGroup 13B file Manage users whoami : See the current user i am su otherUser : Change to other user `exit: Change to prevous user Manage files chmod [ u user| g roup| o thers][+|-][ r ead| w rite|e x ecute] file chmod +x file : Add execution permission to everyone chmod g+w file : Add write permission to group users. chmod o-r file : Remove read permission to other users. chmod o+rw file : Add read and write permission to other users. chmod g+r,o-w file : Modifiy several users permission at the same time chmod 640 file : Modifiy several users permission at the same time chgrp userGroup file : Change the user group lsattr file List special atributers of file chattr +i file Change special atributes of file (add i atribute) chattr -i file Change special atributes of file (remove i atribute)","title":"\ud83d\udcc4 Files (cat,file,stat)"},{"location":"cli_tools/2_files/#files","text":"","title":"Files"},{"location":"cli_tools/2_files/#types-of-files","text":"file directory executable symbolic link socket FIFO whiteout (not in Linux, only in UNIX) Linux. it's a type of file that stops further lookup for a file but reports that it doesn't exist.","title":"Types of files"},{"location":"cli_tools/2_files/#see-files","text":"","title":"\ud83d\udc41\ufe0f See files"},{"location":"cli_tools/2_files/#see-head-or-tail-of-file","text":"head : shows the beginning of a file (defaults to first 10 lines). head -n5 : only 5 lines tail : shows the ending of a file (defaults to last 10 lines). tail -n5 : only 5 lines (head; echo ...;tail) shows head and tail (head; tail) < file.txt cat file.txt | (head; tail)","title":"See head or tail of file"},{"location":"cli_tools/2_files/#see-entire-content-of-text-file","text":"cat : con cat enate and print files. bat : Better cat mdcat : cat for markdown","title":"See entire content of text file"},{"location":"cli_tools/2_files/#pager-echo-pager","text":"more : less : Beter than more. Interactive file viwer. Load the file dynamically (faster than cat) less -N Add line number most : Better than less. Capable of viewing any number of files.","title":"Pager (echo $PAGER)"},{"location":"cli_tools/2_files/#see-entire-content-of-binary-files","text":"cat file | od -c | head hexdump : Para ver ficheros binarios xxd : make a hexdump or do the reverse. hexeditor : strings my_file : See parts of text data in a binary file","title":"See entire content of binary files"},{"location":"cli_tools/2_files/#see-info-file-stat","text":"file my_file stat my_file","title":"See info file stat"},{"location":"cli_tools/2_files/#rename-move-and-copy-files","text":"mv OLD NEW : Move or rename files or directories for file in *; do; mv \"$file ${file// /_}\"; done; : Replace spaces with underscores cp FROM TO : Copy a file rm PATH : Remove a file rm -r PATH : Remove a directory recusively rmdir PATH : Remove an empty directory touch NEW_FILE : Create a file mkdir PATH : Make a directory mkdir My\\ photos : Make a directory with spaces mkdir \"My photos\" : Make a directory with spaces ln FROM TO : Create link (acceso directo) ln src_file dest_file : Hard link ln -s src_file dest_file : Symbolic link ln -s -f src_file dest_file : Symbolyc link","title":"Rename, Move and copy files"},{"location":"cli_tools/2_files/#deep-remove-files","text":"scrub : Real delete files in disk shred : Real delete files in disk bash deep_rm () { scrub -p dod $1 shred -zun 10 -v $1 }","title":"\ud83d\uddd1\ufe0f Deep remove files"},{"location":"cli_tools/2_files/#compare-files-and-find-duplicates","text":"cmp diff comm comm -12 <(sort words.txt | uniq) <(sort countries.txt | uniq) comm -23 <(ls march) <(ls april) OPTION A) Comparing filenames ls | sort | uniq -d OPTION B) Comparing line by line (text files) diff {file1} {file2} : See differencs between files sdiff {file1} {file2} : side-by-side merge of file differences cmp {file1} {file2} : See differencs between files comm : select or reject lines comm on to two files OPTION C) Comparing Byte by byte (binary files) OPTION D) Comparing Checksums, hashes, fingerprints md5sum sha1sum, Some filesytems already computes th checksums ZFS: Performs automatic file integrity checking using checksums fdupes: https://atareao.es/software/utilidades/eliminar-duplicados https://unix.stackexchange.com/questions/28895/open-source-duplicate-image-finder-for-linux","title":"Compare files and Find duplicates"},{"location":"cli_tools/2_files/#type-of-files-and-magic-numbers","text":"The first bytes of a file determine the type of file file * : see the types of every file in the current directory Magic numbers: 89 50 4e 47 0d 0a 1a 0a magic number of PNG file","title":"Type of files and magic numbers"},{"location":"cli_tools/2_files/#users-and-privileges-when-ls-l","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500> Permission of user (owner) \u2502 \u250c\u2500\u2500\u2500\u2500> Permission of group (of users) \u2502 \u2502 \u250c\u2500> Permission of others (users) \u2502 \u2502 \u2502 / \\/ \\/ \\ rwxrwxrwx ownerUser userGroup 13B file Manage users whoami : See the current user i am su otherUser : Change to other user `exit: Change to prevous user Manage files chmod [ u user| g roup| o thers][+|-][ r ead| w rite|e x ecute] file chmod +x file : Add execution permission to everyone chmod g+w file : Add write permission to group users. chmod o-r file : Remove read permission to other users. chmod o+rw file : Add read and write permission to other users. chmod g+r,o-w file : Modifiy several users permission at the same time chmod 640 file : Modifiy several users permission at the same time chgrp userGroup file : Change the user group lsattr file List special atributers of file chattr +i file Change special atributes of file (add i atribute) chattr -i file Change special atributes of file (remove i atribute)","title":"Users and Privileges (when ls -l)"},{"location":"cli_tools/3_process/","text":"Processes Basics A process is an instance of a program/command. Each process has a unique PID (5 digits number). Every process has a parent (the one who create the process). When you close/kill the parent pocess you kill all the child processes How to start a process: Manually (run command in terminal) At boot time (services or daemons) Scheduled ( crontab ) From anothter process (child process) ====== PROCESSES COMMAND & # EJecuta el proceso n 2o plano diswon # independiza el proceso pwdx 1732127 # En que ruta se inicio el proceso con PID=1732127 lsof Lists open files (belonging to active processes). lsof -i:80 Que procesos eta ocupando el puerto 80 lsof -iTCP -sTCP:LISTEN to list all processes that are listening on a TCP port for network requests. https://copyconstruct.medium.com/lsof-f2b224eee7b5 socat socat TCP-LISTEN:9000,fork,reuseaddr,bind=localhost TCP:$HOSTNAME:9000 : If the connection is refused by the server, will use socat to forward traffic from localhost:9000 to $HOSTNAME:9000 and back. https://copyconstruct.medium.com/socat-29453e9fc8a6 ss Sockets Your system is alive! inotify : monitoring filesystem events inotifywait : wait for changes to files using inotify iostat : Report Central Processing Unit (CPU) statistics and input/output statistics for devices, partitions and network filesystems (NFS). Processes VS Jobs A job is a concept used by the shell. Foreground process, backegraund process and suspended processces in the current shell is a job. You can have a large number of background jobs running at the same time, but you can only have one foreground job processes jobs definition instances of a program/command processes of the current shell tracked by the Operating System the current shell identifier pid (example: 1 ) jobspec (example: %1 ) see all ps jobs commands kill , wait , disown , suspend fg , bg , jobs Action Command Shortcut Start a foreground process command Start a background process (shell depen.) command & Start a background process (independent) nohup command & See all the jobs (running & stopped) jobs Stop/pause current process (SIGSTOP) stop {PID} Ctrl Z Resume last stopped job in background bg Resume last stopped job in foreground fg Resume job number 2 in foreground fg %2 Waits for all background jobs to finish wait Waits for job number 1 to finish wait %1 Independice all background jobs disown -a Kill/finish job (SIGINT) kill {PID} Ctrl C Kill/finish job (SIGQUIT) Ctrl \\ Clean terminal Ctrl L digraph { /////////////////////// NODES rankdir=LR; // Left to Right node direction ranksep=.5; { rank = same; \"fg\"; \"st\"; \"bg\";}; nodesep=.5; start [shape=point] fg [ label=\"Running in\\nforegroung\" ] bg [ label=\"Running in\\nbackgroung\" ] bg2 [ label=\"Running in\\nbackgroung\" ] st [ label=\"Stopped\\n(paused)\" ] end [shape=point] /////////////////////// EDGES subgraph cluster1 { label = \"Processes with Parent PID = current shell\\n(when shell dies, Processes dies too)\\n($ jobs to see all these processes)\"; fg -> st [ label=\"Ctrl Z\" ]; st -> fg [ label=\"fg\" ]; st -> bg [ label=\"bg\" ]; bg -> st [ label=\"stop job#\" ]; } start -> fg [ label=\"command\" ]; start -> bg [ label=\"command &\" ]; start -> bg2 [ label=\"nohup command &\" ]; fg -> end [ label=\"Ctrl C\" ]; st -> end [ label=\"kill job#\" ]; bg -> end [ label=\"kill job#\" ]; bg -> bg2 [ label=\"disown job#\"]; } https://copyconstruct.medium.com/bash-job-control-4a36da3e4aa7 https://www.baeldung.com/linux/foreground-background-process https://www.baeldung.com/linux/jobs-job-control-bash https://fsl.fmrib.ox.ac.uk/fslcourse/unix_intro/job.html Coprocess https://copyconstruct.medium.com/bash-coprocess-2092a93ad912 Process states Processes can have several states: Running (R) Uninterruptible Sleep (D) Interruptable Sleep (S) Stopped (T) Zombie (Z) Processes and Threads Process priorities https://www.tecmint.com/set-linux-process-priority-using-nice-and-renice-commands/ Tracking ongoing processes ( ps ) ps (Process status) can be used to see/list all the running processes. ps -f (full) For more information variables ps 19 For single-process information, ps along with process id is used UID: User ID that this process belongs to (the person running it) PID: Process ID PPID: Parent process ID (the ID of the process that started it) C: CPU utilization of process STIME: Process start time TTY: Terminal type associated with the process TIME: CPU time is taken by the process CMD: The command that started this process UID PID PPID C STIME TTY TIME CMD 0 1 0 0 5may22 ?? 98:12.93 /sbin/launchd 0 69 1 0 5may22 ?? 4:07.06 /usr/sbin/syslogd Proc dir It has PID 28, so we check the /proc https://www.digitalocean.com/community/tutorials/how-to-use-top-netstat-du-other-tools-to-monitor-server-resources https://www.digitalocean.com/community/tutorials/how-to-use-ps-kill-and-nice-to-manage-processes-in-linux https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files https://opensource.com/article/20/1/inter-process-communication-linux https://opensource.com/downloads/guide-inter-process-communication-linux","title":"\u23f3 Process (ps,top)"},{"location":"cli_tools/3_process/#processes","text":"","title":"Processes"},{"location":"cli_tools/3_process/#basics","text":"A process is an instance of a program/command. Each process has a unique PID (5 digits number). Every process has a parent (the one who create the process). When you close/kill the parent pocess you kill all the child processes How to start a process: Manually (run command in terminal) At boot time (services or daemons) Scheduled ( crontab ) From anothter process (child process) ====== PROCESSES COMMAND & # EJecuta el proceso n 2o plano diswon # independiza el proceso pwdx 1732127 # En que ruta se inicio el proceso con PID=1732127","title":"Basics"},{"location":"cli_tools/3_process/#lsof","text":"Lists open files (belonging to active processes). lsof -i:80 Que procesos eta ocupando el puerto 80 lsof -iTCP -sTCP:LISTEN to list all processes that are listening on a TCP port for network requests. https://copyconstruct.medium.com/lsof-f2b224eee7b5","title":"lsof"},{"location":"cli_tools/3_process/#socat","text":"socat TCP-LISTEN:9000,fork,reuseaddr,bind=localhost TCP:$HOSTNAME:9000 : If the connection is refused by the server, will use socat to forward traffic from localhost:9000 to $HOSTNAME:9000 and back. https://copyconstruct.medium.com/socat-29453e9fc8a6","title":"socat"},{"location":"cli_tools/3_process/#ss","text":"Sockets","title":"ss"},{"location":"cli_tools/3_process/#your-system-is-alive","text":"inotify : monitoring filesystem events inotifywait : wait for changes to files using inotify iostat : Report Central Processing Unit (CPU) statistics and input/output statistics for devices, partitions and network filesystems (NFS).","title":"Your system is alive!"},{"location":"cli_tools/3_process/#processes-vs-jobs","text":"A job is a concept used by the shell. Foreground process, backegraund process and suspended processces in the current shell is a job. You can have a large number of background jobs running at the same time, but you can only have one foreground job processes jobs definition instances of a program/command processes of the current shell tracked by the Operating System the current shell identifier pid (example: 1 ) jobspec (example: %1 ) see all ps jobs commands kill , wait , disown , suspend fg , bg , jobs Action Command Shortcut Start a foreground process command Start a background process (shell depen.) command & Start a background process (independent) nohup command & See all the jobs (running & stopped) jobs Stop/pause current process (SIGSTOP) stop {PID} Ctrl Z Resume last stopped job in background bg Resume last stopped job in foreground fg Resume job number 2 in foreground fg %2 Waits for all background jobs to finish wait Waits for job number 1 to finish wait %1 Independice all background jobs disown -a Kill/finish job (SIGINT) kill {PID} Ctrl C Kill/finish job (SIGQUIT) Ctrl \\ Clean terminal Ctrl L digraph { /////////////////////// NODES rankdir=LR; // Left to Right node direction ranksep=.5; { rank = same; \"fg\"; \"st\"; \"bg\";}; nodesep=.5; start [shape=point] fg [ label=\"Running in\\nforegroung\" ] bg [ label=\"Running in\\nbackgroung\" ] bg2 [ label=\"Running in\\nbackgroung\" ] st [ label=\"Stopped\\n(paused)\" ] end [shape=point] /////////////////////// EDGES subgraph cluster1 { label = \"Processes with Parent PID = current shell\\n(when shell dies, Processes dies too)\\n($ jobs to see all these processes)\"; fg -> st [ label=\"Ctrl Z\" ]; st -> fg [ label=\"fg\" ]; st -> bg [ label=\"bg\" ]; bg -> st [ label=\"stop job#\" ]; } start -> fg [ label=\"command\" ]; start -> bg [ label=\"command &\" ]; start -> bg2 [ label=\"nohup command &\" ]; fg -> end [ label=\"Ctrl C\" ]; st -> end [ label=\"kill job#\" ]; bg -> end [ label=\"kill job#\" ]; bg -> bg2 [ label=\"disown job#\"]; } https://copyconstruct.medium.com/bash-job-control-4a36da3e4aa7 https://www.baeldung.com/linux/foreground-background-process https://www.baeldung.com/linux/jobs-job-control-bash https://fsl.fmrib.ox.ac.uk/fslcourse/unix_intro/job.html Coprocess https://copyconstruct.medium.com/bash-coprocess-2092a93ad912","title":"Processes VS Jobs"},{"location":"cli_tools/3_process/#process-states","text":"Processes can have several states: Running (R) Uninterruptible Sleep (D) Interruptable Sleep (S) Stopped (T) Zombie (Z)","title":"Process states"},{"location":"cli_tools/3_process/#processes-and-threads","text":"","title":"Processes and Threads"},{"location":"cli_tools/3_process/#process-priorities","text":"https://www.tecmint.com/set-linux-process-priority-using-nice-and-renice-commands/","title":"Process priorities"},{"location":"cli_tools/3_process/#tracking-ongoing-processes-ps","text":"ps (Process status) can be used to see/list all the running processes. ps -f (full) For more information variables ps 19 For single-process information, ps along with process id is used UID: User ID that this process belongs to (the person running it) PID: Process ID PPID: Parent process ID (the ID of the process that started it) C: CPU utilization of process STIME: Process start time TTY: Terminal type associated with the process TIME: CPU time is taken by the process CMD: The command that started this process UID PID PPID C STIME TTY TIME CMD 0 1 0 0 5may22 ?? 98:12.93 /sbin/launchd 0 69 1 0 5may22 ?? 4:07.06 /usr/sbin/syslogd","title":"Tracking ongoing processes (ps)"},{"location":"cli_tools/3_process/#proc-dir","text":"It has PID 28, so we check the /proc https://www.digitalocean.com/community/tutorials/how-to-use-top-netstat-du-other-tools-to-monitor-server-resources https://www.digitalocean.com/community/tutorials/how-to-use-ps-kill-and-nice-to-manage-processes-in-linux https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files https://opensource.com/article/20/1/inter-process-communication-linux https://opensource.com/downloads/guide-inter-process-communication-linux","title":"Proc dir"},{"location":"cli_tools/4_systemd/","text":"SystemD Unit type Description .service A system service .socket An IPC socket .device A device file .mount A mount point in the filesystem .automount An automount point in the filesystem .swap A swap device or file .target A group of units. Equivalent of trditional init\u2019s run levels .path A path (file or directory) monitored by systemd .timer A timer controlled by systemd .snapshot A saved state of systemd .slice A group of units, hierarchically organized in a tree, for managing processes .scope A scope unit for managing externally created processes Where store the units ? Directory Description /etc/systemd/system Administrator-configured units Your local units can go here /lib/systemd/system Package-installed units you shouldn\u2019t modify them /run/systemd/system Non-persistent runtime modifications An area for transient units If there\u2019s any conflict, the files in /etc have the highest priority systemctl : manage systemd systemctl # Eqivalent to systemctl list-units systemctl list-units # shows LOADED and ACTIVE services, sockets, targets, mounts, and devices. systemctl list-units --type=service # shows LOADED and ACTIVE services. systemctl list-unit-files # See all unit files, regardless of whether or not they\u2019re active systemctl list-unit-files --type=service # See all services files, regardless of whether or not they\u2019re active. systemctl status cups.service # systemctl status cups # The same (systemctl can usually accept a unit name without a unit-type suffix) systemctl Subcommand Function list-units Shows LOADED services, sockets, targets, mounts, and devices. list-units --type=service list-units [ pattern ] list-unit-files --type=service list-unit-files [ pattern ] Shows installed units; optionally matching pattern enable unit Start unit at boot disable unit Not start unit at boot start unit Start unit immediately stop unit Stop unit immediately restart unit Restarts unit immediately status unit Shows unit\u2019s status and recent log entries kill pattern Sends a signal to units matching pattern reboot Reboots the computer daemon-reload Reloads unit files and systemd configuration units can be full name ( cups.service ) or sometimes without a unit-type suffix can be accepted ( cups ) Unit statuses systemctl list-units LOAD ACTIVE SUB Meaning not-found inactive dead loaded inactive dead loaded active exited loaded active running Unit file statuses systemctl list-unit-files State Meaning bad Some kind of problem within systemd; usually a bad unit file disabled Present, but not configured to start autonomously enabled Installed and runnable; will start autonomously indirect Disabled, but has peers in Also clauses that may be enabled linked Unit file available through a symlink masked Banished from the systemd world from a logical perspective man .target units (dependencies) Manage \"units\" in a dependency graph Se puede definir que un servicio empiece antes que otro SystemV Run level SystemD Target Description Run level 0 poweroff.target System halt emergency emergency.target Bare-bones shell for system recovery Run level 1 rescue.target Single-user mode Run level 2 multi-user.target Multiuser mode (command line) Run level 3 multi-user.target Multiuser mode with networking Run level 4 multi-user.target Not normally used by init Run level 5 graphical.target Multiuser mode with networking and GUI Run level 6 reboot.target System reboot systemctl list-units --type=target # To see all the system\u2019s available targets systemctl list-dependencies graphical.target # Explore dependency order of some unit # To change the system\u2019s current operating mode, use the systemctl isolate command: sudo systemctl isolate multi-user.target # To see the target the system boots into by default, run the get-default subcommand: systemctl get-default # Most Linux distributions boot to graphical.target by default, # which isn\u2019t appropriate for servers that don\u2019t need a GUI. # But that\u2019s easily changed: sudo systemctl set-default multi-user.target Under traditional init, you use the telinit command to change run levels once the system is booted. More info on man systemd.target .service units specifies the location of the executable file for the daemon tells systemd how to start and stop the service and identifies any other units that the service depends on Create a service ( my_custom.service ) an place it in /etc/systemd/system Refresh systemD avaialblae services sudo systemctl daemon-reload Start the service sudo systemctl start my_custom.service OPTINAL: Enable on booting sudo systemctl start my_custom.service See output (logging) of a u nit journalctl -u triton.service journalctl -u triton.service -f To f ollow the latest changes in real time Example of rsync.service : [Unit] Description=fast remote file copy program daemon ConditionPathExists=/etc/rsyncd.conf [Service] ExecStart=/usr/bin/rsync --daemon --no-detach [Install] WantedBy=multi-user.target [Unit] Description=The SAMPLE server After=syslog.target network.target remote-fs.target nss-lookup.target [Service] # Esta seccion solo esta para units de tipo .service Type=forking PIDFile=/run/sample.pid ExecStartPre=/usr/sbin/sample -t ExecStart=/usr/sbin/sample ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] # Esta seccion es la encargada de poner la unit en el dependency tree WantedBy=app.service # This unit should start when app.service is starting Servicio que se levanta solo, si se cae dentro de [Service] si especificamos Restart=on-failure conseguimos esta funcionalidad. Ademas podemos definir RestartSec=5s para que se levante a los 5 segundos de haberse caido. [Unit] Description=Triton [Service] ExecStart=/home/javi/wesog/models/5_Triton_server/start.sh Restart=on-failure RestartSec=5s [Install] WantedBy=multi-user.target https://www.redhat.com/sysadmin/systemd-automate-recovery More info on man systemd.service .service + .socket Cuando el servicio esta inactivo (se esta iniciando, se cae, o se reinicia con una nueva version), las peticiones que recibe durante ese tiempo no se pierden sino que se meantienen en su socket, hasta que el servicio este operativo de nuevo. A esto se le conoce como Socket activation. Asi que las servidos no deben crear sus sockets manuelamente, sino usar el socket que le da systemD. Un servicio se crea con socket ativation crando con el mismo nombre myservwithsocket.service y myservwithsocket.socket myservwithsocket.service : [Unit] Description=My service with socket activation [Service] ExecStart=/path/to/exec myservwithsocket.socket : [Socket] ListenStream=8000 BindIPv6Only=both [Install] WantedBy=sockets.target # After sockets is availabe .service + .timer si quieres que un servicio que termina (script) se ejecute periodicamente (con la sisntaxis de CRON) puedes a\u00f1adir un .timer unit con el mismo nombre que el .service date.timer : [Unit] Description=Run date.service every 10 minutes [Timer] OnCalendar=*:0/10 Timer type Description OnCalendar A specific day and time. OnBootSec Seconds after system boot time. OnStartupSec Seconds after systemd was started. OnActiveSec Seconds after the timer itself was activated. OnUnitActiveSec Seconds after the specified unit was last active. OnUnitInactiveSec Seconds after the specified unit was last inactive. OnBootSec=2h 1m OnStartupSec=1week 2days 3hours OnActiveSec=1hr20m30sec10msec # Ver los timers actuales systemctl list-timers # archlinux-keyring-wkd-sync.timer | Refresh existing PGP keys of archlinux-keyring regularly # fstrim.timer | Discard unused blocks once a week # shadow.timer | Daily verification of password and group files # systemd-tmpfiles-clean.timer | Daily Cleanup of Temporary Directories https://wiki.archlinux.org/title/Systemd/Timers CRON Syntax \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0=Sun - 6=Sat) \u2502 \u2502 \u2502 \u2502 \u2502 * * * * * minute hour day of the month month day of the week 0..59 0..23 1..31 1..12 0..6 (Sun,Mon,..,Sat) * means \u201cevery\u201d , value list separator - Range of values. / step values. Eg. /5 * * * * means every 5 minutes. Examples: * * * * * : Every minute */5 * * * * : Every 5 minutes */5 8-16 * * 1-5 : Every 5 minutes from 8:00 to 16:00, from Mon to Fri. 0 * * * * : Every hour (at minute 0) 0 0 * * * : Every day (at 00:00) 0 0 * * 0 : Every week (at 00:00 on Sunday) 0 0 1 * * : Mothly (at 00:00 on day 1) 0 0 1 1 * : Yearly (at 00:00 on day 1 of January) Check crontab guru to come up with the cron syntax for your schedule. Logging Systemd tiene su propio log (journal) Permission No se recomienda que el proprieerio del servicio sea el usurario root, para no tocar cosas que no debe. Todo se ejecuta con cgroups Reference https://www.youtube.com/watch?v=r_haLf5mWhE https://www.softprayog.in/tutorials/systemd-system-and-service-manager-in-linux https://alesnosek.com/blog/2016/12/04/controlling-a-multi-service-application-with-systemd ==================== Booting OLD (GRUB + SystemV) NEW (UEFI + SystemD) Power On 1 Load BIOS/UEFI from NVRAM Load BIOS firmware from ROM UEFI Probe for hardware Select boot device (disk, net,...) MBR (Master Boot Record) GPT (GUID Partition Table) Identify EFI system partition Load boot loader GRUB systemd-bootctl Determine which kernel to boot Load kernel Instantiate kernel data structures Start init/systemd as PID 1 Execute startup scripts Runlevel programs /etc/rc.d/ SystemD uses \"targets\" Running system BIOS (Basic Input/Output System) MBR (Master Boot Record) GRUB (Grand Unified Bootloader) Kernel Process managers launchd (OS X) Upstart (Ubuntu) (antiguo y tradicional sistema init) SystemV (SysV) (antiguo y tradicional sistema init) SystemD (el mas usado (y odiado) en la acutailidad Systemd-shim (alternativa moderna) In BSD, the init binary doesn't do much regarding startup, basically just executes /etc/rc; it's shell scripts all the way afterwards. SystemV SystemD Distros Gentoo, Slackware, Linux from Scratch ArchLinux, AWS, Red Hat, CentOS, Fedora, Debian, Ubuntu Restart /etc/init.d/sshd start systemctl restart sshd Enable systemctl enable NetworkManager.service systemctl enable wpa_supplicant https://papers.freebsd.org/2018/bsdcan/rice-the_tragedy_of_systemd/ FreeBSD ventajas: init system, LLVM, documentation, ZFS, dtrace Boot time (System V) BIOS (Basic Input/Output System) MBR (Master Boot Record) GRUB (Grand Unified Bootloader) Kernel Mounts the root file system as specified in the \u201croot=\u201d in grub.conf Kernel executes the /sbin/init program Init (PID=1) Es el primer proceso que se inicia durante el arranque del sistema por parte del kernel. Se ejecutar\u00e1 en segundo plano continuamente hasta que el sistema se apague. Lee el archivo /etc/inittab para decidir el nivel de ejecuci\u00f3n de Linux. luego inicia todos los dem\u00e1s procesos. Run level 0 \u2013> halt (CAUTION: never set initdefault to this) Run level 1 \u2013> Single user mode Run level 2 \u2013> Multiuser, without NFS (The same as 3, if you do not have networking) Run level 3 \u2013> Full multiuser mode (common initdefault) Run level 4 \u2013> unused Run level 5 \u2013> X11 (common initdefault) Run level 6 \u2013> reboot (CAUTION: never set initdefault to this) Ejemplo de inittab: id:3:initdefault: Runlevel programs Depending on your default init level setting, the system will execute the programs from one of the following directories. Run level 0 \u2013> /etc/rc.d/rc0.d/ Run level 1 \u2013> /etc/rc.d/rc1.d/ Run level 2 \u2013> /etc/rc.d/rc2.d/ Run level 3 \u2013> /etc/rc.d/rc3.d/ Run level 4 \u2013> /etc/rc.d/rc4.d/ Run level 5 \u2013> /etc/rc.d/rc5.d/ Run level 6 \u2013> /etc/rc.d/rc6.d/ Programs starts with S are used during startup. S for startup. Programs starts with K are used during shutdown. K for kill. Ejemplo de un script que: # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 rc3: Ser\u00e1 ejecutado en el Run level 3 # \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 S: Ser\u00e1 ejecutado al encenderse # \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 98: Momento de ejecuci\u00f3n, a menor n\u00famero, antes se ejecuta # \u2502 \u2502 \u2502 /etc/rc3.d/S98miscript # Puede ser un enlace simbolico a un script que est\u00e9 en otro sitio ln -s /etc/init.d/mi_script /etc/rc3.d/S98miscript Reference: https://www.thegeekstuff.com/2011/02/linux-boot-process/ Boot time (SystemD) SystemD uses \"targets\" instead of runlevels. By default, there are two main targets: - multi-user.target: analogous to runlevel 3 - graphical.target: analogous to runlevel 5 systemd not only manages processes in parallel, but also manages: - network connections (networkd) - kernel log entries (journald) - and logins (logind). # To view current default target, run: systemctl get-default # To set a default target, run: #systemctl set-default TARGET.target # Establezca el nivel de ejecuci\u00f3n actual en 3 (comenzar en modo de l\u00ednea de comando) systemctl set-default multi-user.target # Establezca el nivel de ejecuci\u00f3n actual en 5 (encendido para la interfaz gr\u00e1fica) systemctl set-default graphical.target systemD haters you may find it informative to peruse the Arguments against systemd section at without-systemd.org","title":"SystemD"},{"location":"cli_tools/4_systemd/#systemd","text":"Unit type Description .service A system service .socket An IPC socket .device A device file .mount A mount point in the filesystem .automount An automount point in the filesystem .swap A swap device or file .target A group of units. Equivalent of trditional init\u2019s run levels .path A path (file or directory) monitored by systemd .timer A timer controlled by systemd .snapshot A saved state of systemd .slice A group of units, hierarchically organized in a tree, for managing processes .scope A scope unit for managing externally created processes","title":"SystemD"},{"location":"cli_tools/4_systemd/#where-store-the-units","text":"Directory Description /etc/systemd/system Administrator-configured units Your local units can go here /lib/systemd/system Package-installed units you shouldn\u2019t modify them /run/systemd/system Non-persistent runtime modifications An area for transient units If there\u2019s any conflict, the files in /etc have the highest priority","title":"Where store the units ?"},{"location":"cli_tools/4_systemd/#systemctl-manage-systemd","text":"systemctl # Eqivalent to systemctl list-units systemctl list-units # shows LOADED and ACTIVE services, sockets, targets, mounts, and devices. systemctl list-units --type=service # shows LOADED and ACTIVE services. systemctl list-unit-files # See all unit files, regardless of whether or not they\u2019re active systemctl list-unit-files --type=service # See all services files, regardless of whether or not they\u2019re active. systemctl status cups.service # systemctl status cups # The same (systemctl can usually accept a unit name without a unit-type suffix) systemctl Subcommand Function list-units Shows LOADED services, sockets, targets, mounts, and devices. list-units --type=service list-units [ pattern ] list-unit-files --type=service list-unit-files [ pattern ] Shows installed units; optionally matching pattern enable unit Start unit at boot disable unit Not start unit at boot start unit Start unit immediately stop unit Stop unit immediately restart unit Restarts unit immediately status unit Shows unit\u2019s status and recent log entries kill pattern Sends a signal to units matching pattern reboot Reboots the computer daemon-reload Reloads unit files and systemd configuration units can be full name ( cups.service ) or sometimes without a unit-type suffix can be accepted ( cups )","title":"systemctl: manage systemd"},{"location":"cli_tools/4_systemd/#unit-statuses-systemctl-list-units","text":"LOAD ACTIVE SUB Meaning not-found inactive dead loaded inactive dead loaded active exited loaded active running","title":"Unit statuses systemctl list-units"},{"location":"cli_tools/4_systemd/#unit-file-statuses-systemctl-list-unit-files","text":"State Meaning bad Some kind of problem within systemd; usually a bad unit file disabled Present, but not configured to start autonomously enabled Installed and runnable; will start autonomously indirect Disabled, but has peers in Also clauses that may be enabled linked Unit file available through a symlink masked Banished from the systemd world from a logical perspective man","title":"Unit file statuses systemctl list-unit-files"},{"location":"cli_tools/4_systemd/#target-units-dependencies","text":"Manage \"units\" in a dependency graph Se puede definir que un servicio empiece antes que otro SystemV Run level SystemD Target Description Run level 0 poweroff.target System halt emergency emergency.target Bare-bones shell for system recovery Run level 1 rescue.target Single-user mode Run level 2 multi-user.target Multiuser mode (command line) Run level 3 multi-user.target Multiuser mode with networking Run level 4 multi-user.target Not normally used by init Run level 5 graphical.target Multiuser mode with networking and GUI Run level 6 reboot.target System reboot systemctl list-units --type=target # To see all the system\u2019s available targets systemctl list-dependencies graphical.target # Explore dependency order of some unit # To change the system\u2019s current operating mode, use the systemctl isolate command: sudo systemctl isolate multi-user.target # To see the target the system boots into by default, run the get-default subcommand: systemctl get-default # Most Linux distributions boot to graphical.target by default, # which isn\u2019t appropriate for servers that don\u2019t need a GUI. # But that\u2019s easily changed: sudo systemctl set-default multi-user.target Under traditional init, you use the telinit command to change run levels once the system is booted. More info on man systemd.target","title":".target units (dependencies)"},{"location":"cli_tools/4_systemd/#service-units","text":"specifies the location of the executable file for the daemon tells systemd how to start and stop the service and identifies any other units that the service depends on Create a service ( my_custom.service ) an place it in /etc/systemd/system Refresh systemD avaialblae services sudo systemctl daemon-reload Start the service sudo systemctl start my_custom.service OPTINAL: Enable on booting sudo systemctl start my_custom.service See output (logging) of a u nit journalctl -u triton.service journalctl -u triton.service -f To f ollow the latest changes in real time Example of rsync.service : [Unit] Description=fast remote file copy program daemon ConditionPathExists=/etc/rsyncd.conf [Service] ExecStart=/usr/bin/rsync --daemon --no-detach [Install] WantedBy=multi-user.target [Unit] Description=The SAMPLE server After=syslog.target network.target remote-fs.target nss-lookup.target [Service] # Esta seccion solo esta para units de tipo .service Type=forking PIDFile=/run/sample.pid ExecStartPre=/usr/sbin/sample -t ExecStart=/usr/sbin/sample ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] # Esta seccion es la encargada de poner la unit en el dependency tree WantedBy=app.service # This unit should start when app.service is starting","title":".service units"},{"location":"cli_tools/4_systemd/#servicio-que-se-levanta-solo-si-se-cae","text":"dentro de [Service] si especificamos Restart=on-failure conseguimos esta funcionalidad. Ademas podemos definir RestartSec=5s para que se levante a los 5 segundos de haberse caido. [Unit] Description=Triton [Service] ExecStart=/home/javi/wesog/models/5_Triton_server/start.sh Restart=on-failure RestartSec=5s [Install] WantedBy=multi-user.target https://www.redhat.com/sysadmin/systemd-automate-recovery More info on man systemd.service","title":"Servicio que se levanta solo, si se cae"},{"location":"cli_tools/4_systemd/#service-socket","text":"Cuando el servicio esta inactivo (se esta iniciando, se cae, o se reinicia con una nueva version), las peticiones que recibe durante ese tiempo no se pierden sino que se meantienen en su socket, hasta que el servicio este operativo de nuevo. A esto se le conoce como Socket activation. Asi que las servidos no deben crear sus sockets manuelamente, sino usar el socket que le da systemD. Un servicio se crea con socket ativation crando con el mismo nombre myservwithsocket.service y myservwithsocket.socket myservwithsocket.service : [Unit] Description=My service with socket activation [Service] ExecStart=/path/to/exec myservwithsocket.socket : [Socket] ListenStream=8000 BindIPv6Only=both [Install] WantedBy=sockets.target # After sockets is availabe","title":".service + .socket"},{"location":"cli_tools/4_systemd/#service-timer","text":"si quieres que un servicio que termina (script) se ejecute periodicamente (con la sisntaxis de CRON) puedes a\u00f1adir un .timer unit con el mismo nombre que el .service date.timer : [Unit] Description=Run date.service every 10 minutes [Timer] OnCalendar=*:0/10 Timer type Description OnCalendar A specific day and time. OnBootSec Seconds after system boot time. OnStartupSec Seconds after systemd was started. OnActiveSec Seconds after the timer itself was activated. OnUnitActiveSec Seconds after the specified unit was last active. OnUnitInactiveSec Seconds after the specified unit was last inactive. OnBootSec=2h 1m OnStartupSec=1week 2days 3hours OnActiveSec=1hr20m30sec10msec # Ver los timers actuales systemctl list-timers # archlinux-keyring-wkd-sync.timer | Refresh existing PGP keys of archlinux-keyring regularly # fstrim.timer | Discard unused blocks once a week # shadow.timer | Daily verification of password and group files # systemd-tmpfiles-clean.timer | Daily Cleanup of Temporary Directories https://wiki.archlinux.org/title/Systemd/Timers","title":".service + .timer"},{"location":"cli_tools/4_systemd/#cron-syntax","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59) \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23) \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the month (1 - 31) \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12) \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of the week (0=Sun - 6=Sat) \u2502 \u2502 \u2502 \u2502 \u2502 * * * * * minute hour day of the month month day of the week 0..59 0..23 1..31 1..12 0..6 (Sun,Mon,..,Sat) * means \u201cevery\u201d , value list separator - Range of values. / step values. Eg. /5 * * * * means every 5 minutes.","title":"CRON Syntax"},{"location":"cli_tools/4_systemd/#examples","text":"* * * * * : Every minute */5 * * * * : Every 5 minutes */5 8-16 * * 1-5 : Every 5 minutes from 8:00 to 16:00, from Mon to Fri. 0 * * * * : Every hour (at minute 0) 0 0 * * * : Every day (at 00:00) 0 0 * * 0 : Every week (at 00:00 on Sunday) 0 0 1 * * : Mothly (at 00:00 on day 1) 0 0 1 1 * : Yearly (at 00:00 on day 1 of January) Check crontab guru to come up with the cron syntax for your schedule.","title":"Examples:"},{"location":"cli_tools/4_systemd/#logging","text":"Systemd tiene su propio log (journal)","title":"Logging"},{"location":"cli_tools/4_systemd/#permission","text":"No se recomienda que el proprieerio del servicio sea el usurario root, para no tocar cosas que no debe.","title":"Permission"},{"location":"cli_tools/4_systemd/#todo-se-ejecuta-con-cgroups","text":"","title":"Todo se ejecuta con cgroups"},{"location":"cli_tools/4_systemd/#reference","text":"https://www.youtube.com/watch?v=r_haLf5mWhE https://www.softprayog.in/tutorials/systemd-system-and-service-manager-in-linux https://alesnosek.com/blog/2016/12/04/controlling-a-multi-service-application-with-systemd ====================","title":"Reference"},{"location":"cli_tools/4_systemd/#booting","text":"OLD (GRUB + SystemV) NEW (UEFI + SystemD) Power On 1 Load BIOS/UEFI from NVRAM Load BIOS firmware from ROM UEFI Probe for hardware Select boot device (disk, net,...) MBR (Master Boot Record) GPT (GUID Partition Table) Identify EFI system partition Load boot loader GRUB systemd-bootctl Determine which kernel to boot Load kernel Instantiate kernel data structures Start init/systemd as PID 1 Execute startup scripts Runlevel programs /etc/rc.d/ SystemD uses \"targets\" Running system BIOS (Basic Input/Output System) MBR (Master Boot Record) GRUB (Grand Unified Bootloader) Kernel","title":"Booting"},{"location":"cli_tools/4_systemd/#process-managers","text":"launchd (OS X) Upstart (Ubuntu) (antiguo y tradicional sistema init) SystemV (SysV) (antiguo y tradicional sistema init) SystemD (el mas usado (y odiado) en la acutailidad Systemd-shim (alternativa moderna) In BSD, the init binary doesn't do much regarding startup, basically just executes /etc/rc; it's shell scripts all the way afterwards. SystemV SystemD Distros Gentoo, Slackware, Linux from Scratch ArchLinux, AWS, Red Hat, CentOS, Fedora, Debian, Ubuntu Restart /etc/init.d/sshd start systemctl restart sshd Enable systemctl enable NetworkManager.service systemctl enable wpa_supplicant https://papers.freebsd.org/2018/bsdcan/rice-the_tragedy_of_systemd/ FreeBSD ventajas: init system, LLVM, documentation, ZFS, dtrace","title":"Process managers"},{"location":"cli_tools/4_systemd/#boot-time-system-v","text":"BIOS (Basic Input/Output System) MBR (Master Boot Record) GRUB (Grand Unified Bootloader) Kernel Mounts the root file system as specified in the \u201croot=\u201d in grub.conf Kernel executes the /sbin/init program Init (PID=1) Es el primer proceso que se inicia durante el arranque del sistema por parte del kernel. Se ejecutar\u00e1 en segundo plano continuamente hasta que el sistema se apague. Lee el archivo /etc/inittab para decidir el nivel de ejecuci\u00f3n de Linux. luego inicia todos los dem\u00e1s procesos. Run level 0 \u2013> halt (CAUTION: never set initdefault to this) Run level 1 \u2013> Single user mode Run level 2 \u2013> Multiuser, without NFS (The same as 3, if you do not have networking) Run level 3 \u2013> Full multiuser mode (common initdefault) Run level 4 \u2013> unused Run level 5 \u2013> X11 (common initdefault) Run level 6 \u2013> reboot (CAUTION: never set initdefault to this) Ejemplo de inittab: id:3:initdefault: Runlevel programs Depending on your default init level setting, the system will execute the programs from one of the following directories. Run level 0 \u2013> /etc/rc.d/rc0.d/ Run level 1 \u2013> /etc/rc.d/rc1.d/ Run level 2 \u2013> /etc/rc.d/rc2.d/ Run level 3 \u2013> /etc/rc.d/rc3.d/ Run level 4 \u2013> /etc/rc.d/rc4.d/ Run level 5 \u2013> /etc/rc.d/rc5.d/ Run level 6 \u2013> /etc/rc.d/rc6.d/ Programs starts with S are used during startup. S for startup. Programs starts with K are used during shutdown. K for kill. Ejemplo de un script que: # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 rc3: Ser\u00e1 ejecutado en el Run level 3 # \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 S: Ser\u00e1 ejecutado al encenderse # \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 98: Momento de ejecuci\u00f3n, a menor n\u00famero, antes se ejecuta # \u2502 \u2502 \u2502 /etc/rc3.d/S98miscript # Puede ser un enlace simbolico a un script que est\u00e9 en otro sitio ln -s /etc/init.d/mi_script /etc/rc3.d/S98miscript Reference: https://www.thegeekstuff.com/2011/02/linux-boot-process/","title":"Boot time (System V)"},{"location":"cli_tools/4_systemd/#boot-time-systemd","text":"SystemD uses \"targets\" instead of runlevels. By default, there are two main targets: - multi-user.target: analogous to runlevel 3 - graphical.target: analogous to runlevel 5 systemd not only manages processes in parallel, but also manages: - network connections (networkd) - kernel log entries (journald) - and logins (logind). # To view current default target, run: systemctl get-default # To set a default target, run: #systemctl set-default TARGET.target # Establezca el nivel de ejecuci\u00f3n actual en 3 (comenzar en modo de l\u00ednea de comando) systemctl set-default multi-user.target # Establezca el nivel de ejecuci\u00f3n actual en 5 (encendido para la interfaz gr\u00e1fica) systemctl set-default graphical.target","title":"Boot time (SystemD)"},{"location":"cli_tools/4_systemd/#systemd-haters","text":"you may find it informative to peruse the Arguments against systemd section at without-systemd.org","title":"systemD haters"},{"location":"cli_tools/5_ipc/","text":"Inter Process Comunication (IPC) Shared files Shared memory (with semaphores) Pipes unnamed pipes | named pipes mkfifo my_pipe Message queues Sockets Unix domain sockets TCP/IP sockets Signals semaphores Practical IPC with python Unix domain socket < gRPC < HTTP | | Unix domain socket | gRPC | HTTP | address unix:// data is exchanged via a Unix domain socket (unix:// address) instead of a TCP socket https://www.mpi-hd.mpg.de/personalhomes/fwerner/research/2021/09/grpc-for-ipc/","title":"5 ipc"},{"location":"cli_tools/5_ipc/#inter-process-comunication-ipc","text":"Shared files Shared memory (with semaphores) Pipes unnamed pipes | named pipes mkfifo my_pipe Message queues Sockets Unix domain sockets TCP/IP sockets Signals semaphores","title":"Inter Process Comunication (IPC)"},{"location":"cli_tools/5_ipc/#practical-ipc-with-python","text":"Unix domain socket < gRPC < HTTP | | Unix domain socket | gRPC | HTTP | address unix:// data is exchanged via a Unix domain socket (unix:// address) instead of a TCP socket https://www.mpi-hd.mpg.de/personalhomes/fwerner/research/2021/09/grpc-for-ipc/","title":"Practical IPC with python"},{"location":"cli_tools/6_monitoring/","text":"Monitoring CPU & RAM - top - htop - Pres F5 to see a tree view of processes . - glances https://www.brendangregg.com/linuxperf.html GPU nvidia-smi watch -n 0.1 nvidia-smi : Watch every 0.1 seconds the output of nvidia-smi nvidia-smi --query-gpu=timestamp,name,pci.bus_id,temperature.gpu,utilization.gpu,utilization.memory --format=csv -l 1 Others: - nvidia-smi -q -d TEMPERATURE,PERFORMANCE : To see the slowdown/shutdown behavieour based on their temperature. If you frequently see HW Slowdown is activated, you probably need to improve the cooling of your machine. - nvidia-smi topo -m : shows the \u201cGPU topology\u201c, which describes how GPUs are connected. The topology is important to understand if data transfers between GPUs are being made via direct memory access (DMA) or through host devices. gpustat a Python libary ( pip install --user gpustat ) to in a more concise, prettier, and simpler way (one line per GPU) nvtop nvitop jupyterlab-nvdashboard pip install --user jupyterlab_nvdashboard Weights & Biases Grafana Reference https://lambdalabs.com/blog/keeping-an-eye-on-your-gpus-2/","title":"Monitoring"},{"location":"cli_tools/6_monitoring/#monitoring","text":"","title":"Monitoring"},{"location":"cli_tools/6_monitoring/#cpu-ram","text":"- top - htop - Pres F5 to see a tree view of processes . - glances https://www.brendangregg.com/linuxperf.html","title":"CPU &amp; RAM"},{"location":"cli_tools/6_monitoring/#gpu","text":"","title":"GPU"},{"location":"cli_tools/6_monitoring/#nvidia-smi","text":"watch -n 0.1 nvidia-smi : Watch every 0.1 seconds the output of nvidia-smi nvidia-smi --query-gpu=timestamp,name,pci.bus_id,temperature.gpu,utilization.gpu,utilization.memory --format=csv -l 1 Others: - nvidia-smi -q -d TEMPERATURE,PERFORMANCE : To see the slowdown/shutdown behavieour based on their temperature. If you frequently see HW Slowdown is activated, you probably need to improve the cooling of your machine. - nvidia-smi topo -m : shows the \u201cGPU topology\u201c, which describes how GPUs are connected. The topology is important to understand if data transfers between GPUs are being made via direct memory access (DMA) or through host devices.","title":"nvidia-smi"},{"location":"cli_tools/6_monitoring/#gpustat","text":"a Python libary ( pip install --user gpustat ) to in a more concise, prettier, and simpler way (one line per GPU)","title":"gpustat"},{"location":"cli_tools/6_monitoring/#nvtop","text":"","title":"nvtop"},{"location":"cli_tools/6_monitoring/#nvitop","text":"","title":"nvitop"},{"location":"cli_tools/6_monitoring/#jupyterlab-nvdashboard","text":"pip install --user jupyterlab_nvdashboard","title":"jupyterlab-nvdashboard"},{"location":"cli_tools/6_monitoring/#weights-biases","text":"","title":"Weights &amp; Biases"},{"location":"cli_tools/6_monitoring/#grafana","text":"","title":"Grafana"},{"location":"cli_tools/6_monitoring/#reference","text":"https://lambdalabs.com/blog/keeping-an-eye-on-your-gpus-2/","title":"Reference"},{"location":"cli_tools/bash_scripting/","text":"Bash scripting Shells Terminal Promt Hashbang/Shebang Configuration file sh $ #!/bin/sh bash $ #!/bin/bash .bashrc zsh $ #!/bin/zsh csh or tcsh % #!/bin/csh [Shebang line](https://en.wikipedia.org/wiki/Shebang_(Unix): First line, This is going to be the interpreter: - #!/bin/sh : Bourne shell script - #!/bin/bash : Bash shell script ./myScript.sh - #!/usr/bin/env bash : Bash shell script - #!/usr/bin/python : Python script ./myScript.py - #!/usr/bin/env python : Python script (more portable because looks for python comand) ./myScript.py - #!/usr/bin/expect expect para automatizar scripts que tienen un input manual Print: echo , printf echo echo Value is $myvarible : Print some variable badly echo 'Value is $myvarible' : Print some variable correctly (with newlines) echo \"Value is $myvarible\" : Print some variable correctly (with newlines) echo $PATH : Sitios donde la shell busca programas echo -n \"no new line\" : do not output the newline echo -e \"[33m ERROR\" : interpret backslash escapes (useful for displaying colors) enable interpretation of backslash escapes printf printf \"dfadf\" Sitios donde la shell busca programas Generate data touch Create a new file or changes the Last Modified time of an existing file. echo \"bla bla bla\" > file.txt seq seq 10 seq 3 9 primes 1 100 \ud83d\udcc5 See current date date cal File descriptors (fd) Every command (every porcess in fact) has its own file despcriptor table. By default (assuming your terminal is /dev/tty0): File descriptor Meaning Initial value 0 stdin /dev/tty0 1 stdout /dev/tty0 2 stderr /dev/tty0 Style output Use ~~ncurses~~ scape charaacters !!! Colours greenColour=\"\\e[0;32m\\033[1m\" endColour=\"\\033[0m\\e[0m\" redColour=\"\\e[0;31m\\033[1m\" blueColour=\"\\e[0;34m\\033[1m\" yellowColour=\"\\e[0;33m\\033[1m\" purpleColour=\"\\e[0;35m\\033[1m\" turquoiseColour=\"\\e[0;36m\\033[1m\" grayColour=\"\\e[0;37m\\033[1m\" # Example of usage echo -e \"\\n\\n${yellowColour}[*]${endColour}${grayColour} Exiting...\\n${endColour}\" IO Redirection IO Redirection modifies the file descriptors table of a command. Redirect from/to file: < > command < file # Redirect stdin to the command. FD0 = file command > file # Redirect stdout to file. FD1 = file command 1> file # Redirect stdout to file. FD1 = file command 2> file # Redirect stderr to file. FD2 = file command &> file # Redirect stdout & stderr to file FD1 = FD2 = file command > /dev/null # When we dont care about the output of a command echo hello > hello.txt # Crea (o sobrescribe) un fichero con la salida del programa anterior Redirect output of several comandas { command1 command2 } > /some/file { command1; command2; } >/some/file { command1 & command2 & } >/some/file Inplace modify the same file: sponge some_command_which_modifies /some/file | sponge /some/file head /some/file | sponge /some/file Append to file: >> command >> file # Redirect and append stdout to a file. command 1>> file # Redirect and append stdout to file command 2>> file # Redirect and append stderr to file echo hello >> hello.txt # A\u00f1ade (append) a un fichero la salida del programa anterior << << is known as here-document structure Read from variable: <<< <<< is known as here-string structure Pipelines Regular Pipes | Assign the stdout (FD1) of the first command to the pipe. Assign the stdin (FD0) of the second command to the pipe. ls -l | tail -n2 # Pipe: Imprime solo los ultimos 2 ficheros ls -l | tail -n2 > hello.txt # Pipe and file writting ls | xargs rm # | xargs is when the inputs is IN THE ARGUMENTS rm $(ls) # same of above cmd1 |& cmd1 # command1's stdout AND stderr is redirected to command2's stdin Machine Learning with Unix Pipes Named Pipes: mkfifo Example Bash script ############## Variables myVar=someValue echo $myVar myVar = someValue # No funciona con espacios echo \"Value is $myVar\" # Imprime: Value is someValue echo 'Value is $myVar' # Imprime: Value is $myVar ############## Functions #!/bin/bash mcd () { mkdir -p \"$1\" cd \"$1\" } # $0: The name of the script # $1: The 1st argument # $9: The 9th argument ########## command substitution myDir=$(pwd) # The output of a command in a varaible echo \"we are in $(pwd)\" for file in $(ls) Variables variables in funcions has global scope by defualt, (unless you define with local ) Special variables $0 : Name of the script $1 to $9 : Arguments to the script. \"$10\" and so on for the rest. $@ : All the arguments $# : Number of arguments $$ : Process identification number (PID) for the current script $? : Return code of the previous command !! : Entire last command, including arguments. A common pattern is to execute a command only for it to fail due to missing permissions; you can quickly re-execute the command with sudo by doing sudo !! $_ : Last argument from the last command. If you are in an interactive shell, you can also quickly get this value by typing Esc followed by . or Alt+. Arrays An array is a numbered list of strings: It maps integers to strings. Creating Arrays names=(\"Bob\" \"Peter\" \"$USER\" \"Big Bad John\") Simple way names=([0]=\"Bob\" [1]=\"Peter\" [20]=\"$USER\" [21]=\"Big Bad John\") Explicit indexes (sparse array) names[0]=\"Bob\" files=(~/*.jpg) Result of a glob photos=(~/\"My Photos\"/*.jpg) Result of a glob files=$(ls) BAD, BAD, BAD! files=($(ls)) STILL BAD! files=(*) GOOD: filenames in the current directory http://mywiki.wooledge.org/BashGuide/Arrays http://mywiki.wooledge.org/BashFAQ/005 Associative Arrays (Dictionaries) fullNames=( [\"lhunath\"]=\"Maarten Billemont\" [\"greycat\"]=\"Greg Wooledge\" ) http://mywiki.wooledge.org/BashGuide/Arrays#Associative_Arrays http://mywiki.wooledge.org/BashFAQ/006 Control Operators ( && and || ) my_command_2 && my_command_2 # Do my_command_2 only if my_command_2 was success someCommand && echo \"Previos comand worked (exit estatus==0)\" someCommand || echo \"Previos comand failed (exit estatus!=0)\" rm /etc/some_file.conf || echo \"I couldn't remove the file\" [ a = a ]; echo $? # 0 (True) [ a = b ]; echo $? # 1 (False) true; echo $? # 0 (True) false; echo $? # 1 (False) If if [[ $filename = *.jpg ]]; then echo \"$filename is a jpeg\" fi 6. Choices (case and select) Each choice in a case statement consists of a pattern (or a list of patterns) case $LANG in en*) echo 'Hello!' ;; fr*) echo 'Salut!' ;; de*) echo 'Guten Tag!' ;; nl*) echo 'Hallo!' ;; it*) echo 'Ciao!' ;; es*) echo 'Hola!' ;; C|POSIX) echo 'hello world' ;; *) echo 'I do not speak your language.' ;; esac Loops There are 4 different loops expressions: for variable in words : Repeat the loop for each word, setting variable to each word in turn. for i in 1 2 3 4 for i in {1..4} for file in *.mp3 for file in *.jpg *.jpeg for (( expr ; expr ; expr )) : C style for loop for (( i=1; i < 5; i++ )) while command : Repeat so long as command is executed successfully (exit code is 0). while (( i < 5 )) while true : Infinite loop while sleep 300 Infinite loop every 5 minutes while read -p \"Input something:\" input_variable Wait for user input until command : Repeat so long as command is executed unsuccessfully (exit code is not 0). Not very used because is the same as while ! command loop_expresion do commads done While loop while /bin/true do # Code goes here done while true; do # Code goes here done Functions Functions can only return an integer in range of 0 - 255. Parameter expansion http://mywiki.wooledge.org/BashGuide/Parameters#Parameter_Expansion Simple usage $VARIABLE ${VARIABLE} Indirection ${!VARIABLE} Case modification ${VARIABLE^} ${VARIABLE^^} ${VARIABLE,} ${VARIABLE,,} ${VARIABLE~} ${VARIABLE~~} Variable name expansion ${!PREFIX*} ${!PREFIX@} Substring removal ${VARIABLE#PATTERN} ${VARIABLE##PATTERN} ${VARIABLE%PATTERN} ${VARIABLE%%PATTERN} Search and replace ${VARIABLE/PATTERN/STRING} ${VARIABLE//PATTERN/STRING} for file in *; do; mv \"$file ${file// /_}\"; done; : Replace spaces with underscores ${VARIABLE/PATTERN} ${VARIABLE//PATTERN} String or array length ${#VARIABLE} Substring expansion ${VARIABLE:OFFSET} ${VARIABLE:OFFSET:LENGTH} Use a default value ${VARIABLE:-WORD} ${VARIABLE-WORD} Assign a default value ${VARIABLE:=WORD} ${VARIABLE=WORD} Use an alternate value ${VARIABLE:+WORD} ${VARIABLE+WORD} Display error if null or unset ${VARIABLE:?WORD} ${VARIABLE?WORD} file=\"$HOME/.secrets/007\" echo \"File location: $file\" # /home/lhunath/.secrets/007 echo \"Filename: ${file##*/}\" # 007 echo \"Directory: ${file%/*}\" # /home/lhunath/.secrets echo echo \"Non-secret file: ${file/secrets/not_secret}\" # /home/lhunath/.not_secret/007 echo echo \"Other file location: ${other:-There is no other file}\" # There is no other file echo \"Using file if there is no other file: ${other:=$file}\" # /home/lhunath/.secrets/007 echo \"Other filename: ${other##*/}\" # 007 echo \"Other file location length: ${#other}\" # 26 # Note: You cannot use multiple Param Exps together file=$HOME/image.jpg file=${file##*/} echo \"${file%.*}\" # image version=1.5.9 echo \"MAJOR: ${version%%.*}\" # MAJOR: 1 echo \"MINOR: ${version#*.}.\" # MINOR: 5.9. echo \"Dash: ${version/./-}\" # Dash: 1-5.9 echo \"Dashes: ${version//./-}.\" # Dashes: 1-5-9. parameter result ----------- ------------------------------ $name polish.ostrich.racing.champion ${name#*.} ostrich.racing.champion ${name##*.} champion ${name%%.*} polish ${name%.*} polish.ostrich.racing Brace expansions Brace expansions can only be used to generate lists of words. You can not use with variables because brace expansion happens before parameter expansion. for i in {1..$n} Won't work! {a,b,c} : a b c {foo,bar} : foo bar {1..15} : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {9..1} : 9 8 7 6 5 4 3 2 1 {A..g} : A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ \u00b4 a b c d e f g {e..a} : e d c b a {a..c} {x..z} : a b c x y z {1..3} {a..c} 1 2 3 a b c {1..3}{a..c} : 1a 1b 1c 2a 2b 2c 3a 3b 3c {0,1}{0..9} : 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 https://www.gnu.org/software/bash/manual/html_node/Brace-Expansion.html Pattern Matching Globs (filename expansion) You can use it with ls , mkdir , echo , for i in {} Globs * : Matches any string, including the null string. But no the / chararcater */bin might match foo/bin but it cannot match /usr/local/bin . ? : Matches any single character. But no the / chararcater [...] : Matches any one of the enclosed characters. Extended Globs (off by default, activate with shopt -s extglob ) ?(pattern-list) : Matches zero or one occurrence of the given patterns. *(pattern-list) : Matches zero or more occurrences of the given patterns. +(pattern-list) : Matches one or more occurrences of the given patterns. @(pattern-list) : Matches one of the given patterns. !(pattern-list) : Matches anything except one of the given patterns. !(*jpg|*bmp) : anything that does not match the *jpg or the *bmp pattern Globs with brace expansion Because Brace expansion happens before Filename expansion, ls *{.jpg,.png} will become ls *.jpg *.png and then execute the comand.","title":"Bash scripting"},{"location":"cli_tools/bash_scripting/#bash-scripting","text":"","title":"Bash scripting"},{"location":"cli_tools/bash_scripting/#shells","text":"Terminal Promt Hashbang/Shebang Configuration file sh $ #!/bin/sh bash $ #!/bin/bash .bashrc zsh $ #!/bin/zsh csh or tcsh % #!/bin/csh [Shebang line](https://en.wikipedia.org/wiki/Shebang_(Unix): First line, This is going to be the interpreter: - #!/bin/sh : Bourne shell script - #!/bin/bash : Bash shell script ./myScript.sh - #!/usr/bin/env bash : Bash shell script - #!/usr/bin/python : Python script ./myScript.py - #!/usr/bin/env python : Python script (more portable because looks for python comand) ./myScript.py - #!/usr/bin/expect","title":"Shells"},{"location":"cli_tools/bash_scripting/#expect","text":"para automatizar scripts que tienen un input manual","title":"expect"},{"location":"cli_tools/bash_scripting/#print-echo-printf","text":"echo echo Value is $myvarible : Print some variable badly echo 'Value is $myvarible' : Print some variable correctly (with newlines) echo \"Value is $myvarible\" : Print some variable correctly (with newlines) echo $PATH : Sitios donde la shell busca programas echo -n \"no new line\" : do not output the newline echo -e \"[33m ERROR\" : interpret backslash escapes (useful for displaying colors) enable interpretation of backslash escapes printf printf \"dfadf\" Sitios donde la shell busca programas","title":"Print: echo, printf"},{"location":"cli_tools/bash_scripting/#generate-data","text":"touch Create a new file or changes the Last Modified time of an existing file. echo \"bla bla bla\" > file.txt seq seq 10 seq 3 9 primes 1 100","title":"Generate data"},{"location":"cli_tools/bash_scripting/#see-current-date","text":"date cal","title":"\ud83d\udcc5 See current date"},{"location":"cli_tools/bash_scripting/#file-descriptors-fd","text":"Every command (every porcess in fact) has its own file despcriptor table. By default (assuming your terminal is /dev/tty0): File descriptor Meaning Initial value 0 stdin /dev/tty0 1 stdout /dev/tty0 2 stderr /dev/tty0","title":"File descriptors (fd)"},{"location":"cli_tools/bash_scripting/#style-output","text":"Use ~~ncurses~~ scape charaacters !!!","title":"Style output"},{"location":"cli_tools/bash_scripting/#colours","text":"greenColour=\"\\e[0;32m\\033[1m\" endColour=\"\\033[0m\\e[0m\" redColour=\"\\e[0;31m\\033[1m\" blueColour=\"\\e[0;34m\\033[1m\" yellowColour=\"\\e[0;33m\\033[1m\" purpleColour=\"\\e[0;35m\\033[1m\" turquoiseColour=\"\\e[0;36m\\033[1m\" grayColour=\"\\e[0;37m\\033[1m\" # Example of usage echo -e \"\\n\\n${yellowColour}[*]${endColour}${grayColour} Exiting...\\n${endColour}\"","title":"Colours"},{"location":"cli_tools/bash_scripting/#io-redirection","text":"IO Redirection modifies the file descriptors table of a command.","title":"IO Redirection"},{"location":"cli_tools/bash_scripting/#redirect-fromto-file","text":"command < file # Redirect stdin to the command. FD0 = file command > file # Redirect stdout to file. FD1 = file command 1> file # Redirect stdout to file. FD1 = file command 2> file # Redirect stderr to file. FD2 = file command &> file # Redirect stdout & stderr to file FD1 = FD2 = file command > /dev/null # When we dont care about the output of a command echo hello > hello.txt # Crea (o sobrescribe) un fichero con la salida del programa anterior","title":"Redirect from/to file: &lt; &gt;"},{"location":"cli_tools/bash_scripting/#redirect-output-of-several-comandas","text":"{ command1 command2 } > /some/file { command1; command2; } >/some/file { command1 & command2 & } >/some/file","title":"Redirect output of several comandas"},{"location":"cli_tools/bash_scripting/#inplace-modify-the-same-file-sponge","text":"some_command_which_modifies /some/file | sponge /some/file head /some/file | sponge /some/file","title":"Inplace modify the same file: sponge"},{"location":"cli_tools/bash_scripting/#append-to-file","text":"command >> file # Redirect and append stdout to a file. command 1>> file # Redirect and append stdout to file command 2>> file # Redirect and append stderr to file echo hello >> hello.txt # A\u00f1ade (append) a un fichero la salida del programa anterior","title":"Append to file: &gt;&gt;"},{"location":"cli_tools/bash_scripting/#_1","text":"<< is known as here-document structure","title":"&lt;&lt;"},{"location":"cli_tools/bash_scripting/#read-from-variable","text":"<<< is known as here-string structure","title":"Read from variable: &lt;&lt;&lt;"},{"location":"cli_tools/bash_scripting/#pipelines","text":"","title":"Pipelines"},{"location":"cli_tools/bash_scripting/#regular-pipes","text":"Assign the stdout (FD1) of the first command to the pipe. Assign the stdin (FD0) of the second command to the pipe. ls -l | tail -n2 # Pipe: Imprime solo los ultimos 2 ficheros ls -l | tail -n2 > hello.txt # Pipe and file writting ls | xargs rm # | xargs is when the inputs is IN THE ARGUMENTS rm $(ls) # same of above cmd1 |& cmd1 # command1's stdout AND stderr is redirected to command2's stdin Machine Learning with Unix Pipes","title":"Regular Pipes |"},{"location":"cli_tools/bash_scripting/#named-pipes-mkfifo","text":"","title":"Named Pipes: mkfifo"},{"location":"cli_tools/bash_scripting/#example-bash-script","text":"############## Variables myVar=someValue echo $myVar myVar = someValue # No funciona con espacios echo \"Value is $myVar\" # Imprime: Value is someValue echo 'Value is $myVar' # Imprime: Value is $myVar ############## Functions #!/bin/bash mcd () { mkdir -p \"$1\" cd \"$1\" } # $0: The name of the script # $1: The 1st argument # $9: The 9th argument ########## command substitution myDir=$(pwd) # The output of a command in a varaible echo \"we are in $(pwd)\" for file in $(ls)","title":"Example Bash script"},{"location":"cli_tools/bash_scripting/#variables","text":"variables in funcions has global scope by defualt, (unless you define with local )","title":"Variables"},{"location":"cli_tools/bash_scripting/#special-variables","text":"$0 : Name of the script $1 to $9 : Arguments to the script. \"$10\" and so on for the rest. $@ : All the arguments $# : Number of arguments $$ : Process identification number (PID) for the current script $? : Return code of the previous command !! : Entire last command, including arguments. A common pattern is to execute a command only for it to fail due to missing permissions; you can quickly re-execute the command with sudo by doing sudo !! $_ : Last argument from the last command. If you are in an interactive shell, you can also quickly get this value by typing Esc followed by . or Alt+.","title":"Special variables"},{"location":"cli_tools/bash_scripting/#arrays","text":"An array is a numbered list of strings: It maps integers to strings. Creating Arrays names=(\"Bob\" \"Peter\" \"$USER\" \"Big Bad John\") Simple way names=([0]=\"Bob\" [1]=\"Peter\" [20]=\"$USER\" [21]=\"Big Bad John\") Explicit indexes (sparse array) names[0]=\"Bob\" files=(~/*.jpg) Result of a glob photos=(~/\"My Photos\"/*.jpg) Result of a glob files=$(ls) BAD, BAD, BAD! files=($(ls)) STILL BAD! files=(*) GOOD: filenames in the current directory http://mywiki.wooledge.org/BashGuide/Arrays http://mywiki.wooledge.org/BashFAQ/005","title":"Arrays"},{"location":"cli_tools/bash_scripting/#associative-arrays-dictionaries","text":"fullNames=( [\"lhunath\"]=\"Maarten Billemont\" [\"greycat\"]=\"Greg Wooledge\" ) http://mywiki.wooledge.org/BashGuide/Arrays#Associative_Arrays http://mywiki.wooledge.org/BashFAQ/006","title":"Associative Arrays (Dictionaries)"},{"location":"cli_tools/bash_scripting/#control-operators-and","text":"my_command_2 && my_command_2 # Do my_command_2 only if my_command_2 was success someCommand && echo \"Previos comand worked (exit estatus==0)\" someCommand || echo \"Previos comand failed (exit estatus!=0)\" rm /etc/some_file.conf || echo \"I couldn't remove the file\" [ a = a ]; echo $? # 0 (True) [ a = b ]; echo $? # 1 (False) true; echo $? # 0 (True) false; echo $? # 1 (False)","title":"Control Operators (&amp;&amp; and ||)"},{"location":"cli_tools/bash_scripting/#if","text":"if [[ $filename = *.jpg ]]; then echo \"$filename is a jpeg\" fi","title":"If"},{"location":"cli_tools/bash_scripting/#6-choices-case-and-select","text":"Each choice in a case statement consists of a pattern (or a list of patterns) case $LANG in en*) echo 'Hello!' ;; fr*) echo 'Salut!' ;; de*) echo 'Guten Tag!' ;; nl*) echo 'Hallo!' ;; it*) echo 'Ciao!' ;; es*) echo 'Hola!' ;; C|POSIX) echo 'hello world' ;; *) echo 'I do not speak your language.' ;; esac","title":"6. Choices (case and select)"},{"location":"cli_tools/bash_scripting/#loops","text":"There are 4 different loops expressions: for variable in words : Repeat the loop for each word, setting variable to each word in turn. for i in 1 2 3 4 for i in {1..4} for file in *.mp3 for file in *.jpg *.jpeg for (( expr ; expr ; expr )) : C style for loop for (( i=1; i < 5; i++ )) while command : Repeat so long as command is executed successfully (exit code is 0). while (( i < 5 )) while true : Infinite loop while sleep 300 Infinite loop every 5 minutes while read -p \"Input something:\" input_variable Wait for user input until command : Repeat so long as command is executed unsuccessfully (exit code is not 0). Not very used because is the same as while ! command loop_expresion do commads done","title":"Loops"},{"location":"cli_tools/bash_scripting/#while-loop","text":"while /bin/true do # Code goes here done while true; do # Code goes here done","title":"While loop"},{"location":"cli_tools/bash_scripting/#functions","text":"Functions can only return an integer in range of 0 - 255.","title":"Functions"},{"location":"cli_tools/bash_scripting/#parameter-expansion","text":"http://mywiki.wooledge.org/BashGuide/Parameters#Parameter_Expansion Simple usage $VARIABLE ${VARIABLE} Indirection ${!VARIABLE} Case modification ${VARIABLE^} ${VARIABLE^^} ${VARIABLE,} ${VARIABLE,,} ${VARIABLE~} ${VARIABLE~~} Variable name expansion ${!PREFIX*} ${!PREFIX@} Substring removal ${VARIABLE#PATTERN} ${VARIABLE##PATTERN} ${VARIABLE%PATTERN} ${VARIABLE%%PATTERN} Search and replace ${VARIABLE/PATTERN/STRING} ${VARIABLE//PATTERN/STRING} for file in *; do; mv \"$file ${file// /_}\"; done; : Replace spaces with underscores ${VARIABLE/PATTERN} ${VARIABLE//PATTERN} String or array length ${#VARIABLE} Substring expansion ${VARIABLE:OFFSET} ${VARIABLE:OFFSET:LENGTH} Use a default value ${VARIABLE:-WORD} ${VARIABLE-WORD} Assign a default value ${VARIABLE:=WORD} ${VARIABLE=WORD} Use an alternate value ${VARIABLE:+WORD} ${VARIABLE+WORD} Display error if null or unset ${VARIABLE:?WORD} ${VARIABLE?WORD} file=\"$HOME/.secrets/007\" echo \"File location: $file\" # /home/lhunath/.secrets/007 echo \"Filename: ${file##*/}\" # 007 echo \"Directory: ${file%/*}\" # /home/lhunath/.secrets echo echo \"Non-secret file: ${file/secrets/not_secret}\" # /home/lhunath/.not_secret/007 echo echo \"Other file location: ${other:-There is no other file}\" # There is no other file echo \"Using file if there is no other file: ${other:=$file}\" # /home/lhunath/.secrets/007 echo \"Other filename: ${other##*/}\" # 007 echo \"Other file location length: ${#other}\" # 26 # Note: You cannot use multiple Param Exps together file=$HOME/image.jpg file=${file##*/} echo \"${file%.*}\" # image version=1.5.9 echo \"MAJOR: ${version%%.*}\" # MAJOR: 1 echo \"MINOR: ${version#*.}.\" # MINOR: 5.9. echo \"Dash: ${version/./-}\" # Dash: 1-5.9 echo \"Dashes: ${version//./-}.\" # Dashes: 1-5-9. parameter result ----------- ------------------------------ $name polish.ostrich.racing.champion ${name#*.} ostrich.racing.champion ${name##*.} champion ${name%%.*} polish ${name%.*} polish.ostrich.racing","title":"Parameter expansion"},{"location":"cli_tools/bash_scripting/#brace-expansions","text":"Brace expansions can only be used to generate lists of words. You can not use with variables because brace expansion happens before parameter expansion. for i in {1..$n} Won't work! {a,b,c} : a b c {foo,bar} : foo bar {1..15} : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 {9..1} : 9 8 7 6 5 4 3 2 1 {A..g} : A B C D E F G H I J K L M N O P Q R S T U V W X Y Z [ \\ ] ^ _ \u00b4 a b c d e f g {e..a} : e d c b a {a..c} {x..z} : a b c x y z {1..3} {a..c} 1 2 3 a b c {1..3}{a..c} : 1a 1b 1c 2a 2b 2c 3a 3b 3c {0,1}{0..9} : 00 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 https://www.gnu.org/software/bash/manual/html_node/Brace-Expansion.html Pattern Matching","title":"Brace expansions"},{"location":"cli_tools/bash_scripting/#globs-filename-expansion","text":"You can use it with ls , mkdir , echo , for i in {} Globs * : Matches any string, including the null string. But no the / chararcater */bin might match foo/bin but it cannot match /usr/local/bin . ? : Matches any single character. But no the / chararcater [...] : Matches any one of the enclosed characters. Extended Globs (off by default, activate with shopt -s extglob ) ?(pattern-list) : Matches zero or one occurrence of the given patterns. *(pattern-list) : Matches zero or more occurrences of the given patterns. +(pattern-list) : Matches one or more occurrences of the given patterns. @(pattern-list) : Matches one of the given patterns. !(pattern-list) : Matches anything except one of the given patterns. !(*jpg|*bmp) : anything that does not match the *jpg or the *bmp pattern","title":"Globs (filename expansion)"},{"location":"cli_tools/bash_scripting/#globs-with-brace-expansion","text":"Because Brace expansion happens before Filename expansion, ls *{.jpg,.png} will become ls *.jpg *.png and then execute the comand.","title":"Globs with brace expansion"},{"location":"cli_tools/compression/","text":"\ud83d\udce6 Compression | Format | Compress | Preview | Decompress | |-------------|-----------------------|-------------- | | 7z l compressedFile | 7z x compressedFile | | | base64 | | base64 -d | zip file | | | tar -cvf compr.tar /dir/ tar file | | tar -xf | | | .gz | gunzip | | | bzip2` | | | Format | Extension | Tool |---------|-----------------| | ZIP | | | TAR | .tar.gz o .tgz | | GNU zip | .gz o .gzip | | p7zip | .7z | | BZIP2 | .bz2 | bzip2 FILE(S) | bzip2 \u2013d test.txt XZ GZIP TAR WIM .tar.bz2 o .tbz2 .tar.xz o .xz o .txz .gz o .gzip o .bzip2 .tar.lzma o .tlz:","title":"\ud83d\udddc\ufe0f Compress (zip,tar,bz)"},{"location":"cli_tools/compression/#compression","text":"| Format | Compress | Preview | Decompress | |-------------|-----------------------|-------------- | | 7z l compressedFile | 7z x compressedFile | | | base64 | | base64 -d | zip file | | | tar -cvf compr.tar /dir/ tar file | | tar -xf | | | .gz | gunzip | | | bzip2` | | | Format | Extension | Tool |---------|-----------------| | ZIP | | | TAR | .tar.gz o .tgz | | GNU zip | .gz o .gzip | | p7zip | .7z | | BZIP2 | .bz2 | bzip2 FILE(S) | bzip2 \u2013d test.txt XZ GZIP TAR WIM .tar.bz2 o .tbz2 .tar.xz o .xz o .txz .gz o .gzip o .bzip2 .tar.lzma o .tlz:","title":"\ud83d\udce6 Compression"},{"location":"cli_tools/cryptography/","text":"\ud83d\udd11 Cryptography Hash function: MD5, SHA-1, SHA-256 Non invertible Collision redundant md5 myFile.txt shasum myFile.txt sha1sum myFile.txt Symetric cryptography (1 key) keygen() -> key encrypt(plaintext, key) -> ciphertext decrypt(ciphertext, key) -> plaintext # AES openssl aes-256-cbc -salt -in aaa.py -out aaa.py.enc # Encription openssl aes-256-cbc -d -in aaa.py.ec -out aaa2.py # Decryption Asymmetric cryptography (public & private keys) keygen() -> public key, private key La clave p\u00fablica solo se usa para cifrar (la usar\u00e1 el otro) La clave privada solo se usa para descifrar (la usar\u00e9 yo) encrypt(plaintext, public key) -> ciphertext decrypt(ciphertext, private key) -> plaintext En general todo aque que quiera que LE LLEGEN los mensajes privados, debe comunicar su public key. Si AMBOS extremos comunican su public key, la comunicaci\u00f3n ser\u00e1 cifrada Ejemplos: - RSA - ED25519: more secure # RSA Hybrid cryptography Presmisa: - La Symetric cryptography es r\u00e1pida - La Asymmetric cryptography es lenta Entoces: Usar la Asymmetric cryptography SOLO PARA INTERCAMBIAR LA CLAVE SIMETRICA. Asi ya se tiene una Symetric cryptography que es m\u00e1s r\u00e1pida que la Asymmetric Asymmetric cryptography for signing keygen() -> public key, private key sign(message, private key) -> signature verify(message, signature, public key) -> bool (whether or not the signature is valid)","title":"\ud83d\udd11 Cryptography (base64)"},{"location":"cli_tools/cryptography/#cryptography","text":"","title":"\ud83d\udd11 Cryptography"},{"location":"cli_tools/cryptography/#hash-function-md5-sha-1-sha-256","text":"Non invertible Collision redundant md5 myFile.txt shasum myFile.txt sha1sum myFile.txt","title":"Hash function: MD5, SHA-1, SHA-256"},{"location":"cli_tools/cryptography/#symetric-cryptography-1-key","text":"keygen() -> key encrypt(plaintext, key) -> ciphertext decrypt(ciphertext, key) -> plaintext # AES openssl aes-256-cbc -salt -in aaa.py -out aaa.py.enc # Encription openssl aes-256-cbc -d -in aaa.py.ec -out aaa2.py # Decryption","title":"Symetric cryptography (1 key)"},{"location":"cli_tools/cryptography/#asymmetric-cryptography-public-private-keys","text":"keygen() -> public key, private key La clave p\u00fablica solo se usa para cifrar (la usar\u00e1 el otro) La clave privada solo se usa para descifrar (la usar\u00e9 yo) encrypt(plaintext, public key) -> ciphertext decrypt(ciphertext, private key) -> plaintext En general todo aque que quiera que LE LLEGEN los mensajes privados, debe comunicar su public key. Si AMBOS extremos comunican su public key, la comunicaci\u00f3n ser\u00e1 cifrada Ejemplos: - RSA - ED25519: more secure # RSA","title":"Asymmetric cryptography (public &amp; private keys)"},{"location":"cli_tools/cryptography/#hybrid-cryptography","text":"Presmisa: - La Symetric cryptography es r\u00e1pida - La Asymmetric cryptography es lenta Entoces: Usar la Asymmetric cryptography SOLO PARA INTERCAMBIAR LA CLAVE SIMETRICA. Asi ya se tiene una Symetric cryptography que es m\u00e1s r\u00e1pida que la Asymmetric","title":"Hybrid cryptography"},{"location":"cli_tools/cryptography/#asymmetric-cryptography-for-signing","text":"keygen() -> public key, private key sign(message, private key) -> signature verify(message, signature, public key) -> bool (whether or not the signature is valid)","title":"Asymmetric cryptography for signing"},{"location":"cli_tools/customization/","text":"\ud83c\udfa8 Customization (dotfiles) bash: ~/.bashrc , ~/.bash_profile zsh ~/.zshrc git: ~/.gitconfig vim: ~/.vimrc and the ~/.vim folder ssh: ~/.ssh/config tmux: ~/.tmux.conf nano: ~/.nanorc ZSH ~/.zshrc Change to zsh: sudo chsh -s /usr/bin/zsh javi curl -L http://install.ohmyz.sh | sh Change Bash to ZSH $ sudo pacman -S zsh # Install ZSH (and extras) $ zsh # Make sure that ZSH has been installed correctly $ chsh -l # List all installed shells $ chsh -s /usr/bin/zsh # WAY 1) Set new default shell (zsh) for your user $ usermod --shell /usr/bin/zsh javi # WAY 2) Set new default shell (zsh) for a user (S4vitar lo hizo asi) $ nano /etc/passwd # WAY 3) Set new default shell (zsh) for a user $ echo $SHELL # Comprobar la nueva shell https://wiki.archlinux.org/title/zsh#Installation https://wiki.archlinux.org/title/Command-line_shell#Changing_your_default_shell 3 Ways to Change a Users Default Shell Better prompt -> zsh-theme-powerlevel10k $ sudo pacman -S zsh-theme-powerlevel10k $ echo 'source /usr/share/zsh-theme-powerlevel10k/powerlevel10k.zsh-theme' >> ~/.zshrc $ source ~/.zshrc $ p10k configure https://github.com/ahillio/powerlevel10k/blob/master/README.md#arch-linux Colors on terminal outout alias ls='ls --color=auto' alias diff='diff --color=auto' alias grep='grep --color=auto' alias ip='ip -color=auto' Pacman has a color option. Uncomment the Color line in /etc/pacman.conf . https://wiki.archlinux.org/title/Color_output_in_console Other way is to install grml-zsh-config Colors on terminal commands -> zsh-syntax-highlighting $ sudo pacman -S zsh-syntax-highlighting $ echo 'source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh' >> ~/.zshrc Sugerir comandos del pasado -> zsh-autosuggestions $ sudo pacman -S zsh-autosuggestions $ echo 'source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh' >> ~/.zshrc ZSH: Other plugins zsh-completions zsh-sudo -> con esc esc te pone sudo al principio (source /usr/share/zsh-sudo/sudo.plugin.zsh ) zsh-suggestions fzf -> con ctrl + T busca # ZSH pluggins source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh source /usr/share/zsh-theme-powerlevel10k/powerlevel10k.zsh-theme # General alias l='lsd' alias ls='lsd' alias ll='lsd -l' alias la='lsd -a' alias lla='lsd -la' alias tree='lsd --tree' # Jupyter notebook alias jn=\"jupyter notebook\" # Pacman alias i=\"sudo pacman -S\" # install a package alias s=\"pacman -Ss\" # search for a package alias u=\"sudo pacman -Syu\" # update the packages alias r=\"sudo pacman -Rns\" # remove a package alias install=\"sudo pacman -S\" # install a package alias search=\"pacman -Ss\" # search for a package alias update=\"sudo pacman -Syu\" # update the packages alias remove=\"sudo pacman -Rns\" # remove a package # Others alias title=\"figlet\" # Git function commit() { git add . msg=$@ # Every argument git commit -m \"$msg\" git push } Nano: ~/.nanorc set autoindent # Tthe newly created line will contain the same indent as the preceding line set tabsize 4 # Use a tab size of number columns. The default value is 8. set softwrap # Enable soft line wrapping for easier viewing of very long lines set nowrap # Don\u2019t hard-wrap text at all # set nohelp # Don\u2019t display the two help lines at the bottom of the screen. set linenumbers # Display of line numbers in front of the text. include \"/usr/share/nano/*.nanorc\" # Default Syntax highlighting include \"/usr/share/nano-syntax-highlighting/*.nanorc\" # syntax highlighting enhancements* sudo pacman -S nano-syntax-highlighting TMUX ~/.tmux.conf ####### SAME PROMT set -g default-terminal \"screen-256color\" if 'infocmp -x tmux-256color > /dev/null 2>&1' 'set -g default-terminal \"tmux-256color\"' ####### MOUSE (enable scroll) set -g mouse on # For tmux version 2.1 and above set -g terminal-overrides 'xterm*:smcup@:rmcup@' # Sane scrolling (instead of mimic arrrow keys) ####### Number windows and panes start at 1 instead of 0 set -g base-index 1 set -g pane-base-index 1 Oh my tmux! : Self-contained, pretty & versatile tmux configuration Practical Tmux VIM: ~/.vimrc \" Comments in Vimscript start with a `\"`. \" If you open this file in Vim, it'll be syntax highlighted for you. \" Vim is based on Vi. Setting `nocompatible` switches from the default \" Vi-compatibility mode and enables useful Vim functionality. This \" configuration option turns out not to be necessary for the file named \" '~/.vimrc', because Vim automatically enters nocompatible mode if that file \" is present. But we're including it here just in case this config file is \" loaded some other way (e.g. saved as `foo`, and then Vim started with \" `vim -u foo`). set nocompatible \" Use a line cursor within insert mode and a block cursor everywhere else. \" \" Using iTerm2? Go-to preferences / profile / colors and disable the smart bar \" cursor color. Then pick a cursor and highlight color that matches your theme. \" That will ensure your cursor is always visible within insert mode. \" \" Reference chart of values: \" Ps = 0 -> blinking block. \" Ps = 1 -> blinking block (default). \" Ps = 2 -> steady block. \" Ps = 3 -> blinking underline. \" Ps = 4 -> steady underline. \" Ps = 5 -> blinking bar (xterm). \" Ps = 6 -> steady bar (xterm). let &t_SI = \"\\e[6 q\" let &t_EI = \"\\e[2 q\" \" Turn on syntax highlighting. syntax on \" Disable the default Vim startup message. set shortmess+=I \" Show line numbers. set number \" This enables relative line numbering mode. With both number and \" relativenumber enabled, the current line shows the true line number, while \" all other lines (above and below) are numbered relative to the current line. \" This is useful because you can tell, at a glance, what count is needed to \" jump up or down to a particular line, by {count}k to go up or {count}j to go \" down. set relativenumber \" Always show the status line at the bottom, even if you only have one window open. set laststatus=2 \" The backspace key has slightly unintuitive behavior by default. For example, \" by default, you can't backspace before the insertion point set with 'i'. \" This configuration makes backspace behave more reasonably, in that you can \" backspace over anything. set backspace=indent,eol,start \" By default, Vim doesn't let you hide a buffer (i.e. have a buffer that isn't \" shown in any window) that has unsaved changes. This is to prevent you from \" \" forgetting about unsaved changes and then quitting e.g. via `:qa!`. We find \" hidden buffers helpful enough to disable this protection. See `:help hidden` \" for more information on this. set hidden \" This setting makes search case-insensitive when all characters in the string \" being searched are lowercase. However, the search becomes case-sensitive if \" it contains any capital letters. This makes searching more convenient. set ignorecase set smartcase \" Enable searching as you type, rather than waiting till you press enter. set incsearch \" Unbind some useless/annoying default key bindings. nmap Q <Nop> \" 'Q' in normal mode enters Ex mode. You almost never want this. \" Disable audible bell because it's annoying. set noerrorbells visualbell t_vb= \" Enable mouse support. You should avoid relying on this too much, but it can \" sometimes be convenient. set mouse+=a \" Try to prevent bad habits like using the arrow keys for movement. This is \" not the only possible bad habit. For example, holding down the h/j/k/l keys \" for movement, rather than using more efficient movement commands, is also a \" bad habit. The former is enforceable through a .vimrc, while we don't know \" how to prevent the latter. \" Do this in normal mode... nnoremap <Left> :echoe \"Use h\"<CR> nnoremap <Right> :echoe \"Use l\"<CR> nnoremap <Up> :echoe \"Use k\"<CR> nnoremap <Down> :echoe \"Use j\"<CR> \" ...and in insert mode inoremap <Left> <ESC>:echoe \"Use h\"<CR> inoremap <Right> <ESC>:echoe \"Use l\"<CR> inoremap <Up> <ESC>:echoe \"Use k\"<CR> inoremap <Down> <ESC>:echoe \"Use j\"<CR> NeoVIM: ~/.vimrc sudo pacman -S neovim iTerm2 Shell Integration curl -L https://iterm2.com/shell_integration/zsh -o ~/.iterm2_shell_integration.zsh source ~/.iterm2_shell_integration.zsh # Add this line at ~/.zshrc # If hostname command not found install https://www.gnu.org/software/inetutils/ sudo pacman -S inetutils Download files from remote hosts with a click. You can right click on a filename (e.g., in the output of ls) to download it. Drag-drop files to upload with scp. Hold down option and drag-drop a file from Finder into iTerm2 to upload it. imgcat wget https://iterm2.com/utilities/imgcat ; chmod 755 imgcat` Ranger + imgcat Set NTP time sudo pacman -S ntp sudo timedatectl set-ntp true Comunity configs/dotfiles Savitar https://www.youtube.com/watch?v=fshLf6u8B-w&t=3276s https://s4vitar.github.io/bspwm-configuration-files/# Josean Martinez Terminal https://www.youtube.com/watch?v=CF1tMjvHDRA https://github.com/rxyhn/dotfiles","title":"\ud83c\udfa8 Customization (dotfiles)"},{"location":"cli_tools/customization/#customization-dotfiles","text":"bash: ~/.bashrc , ~/.bash_profile zsh ~/.zshrc git: ~/.gitconfig vim: ~/.vimrc and the ~/.vim folder ssh: ~/.ssh/config tmux: ~/.tmux.conf nano: ~/.nanorc","title":"\ud83c\udfa8 Customization (dotfiles)"},{"location":"cli_tools/customization/#zsh-zshrc","text":"Change to zsh: sudo chsh -s /usr/bin/zsh javi curl -L http://install.ohmyz.sh | sh","title":"ZSH ~/.zshrc"},{"location":"cli_tools/customization/#change-bash-to-zsh","text":"$ sudo pacman -S zsh # Install ZSH (and extras) $ zsh # Make sure that ZSH has been installed correctly $ chsh -l # List all installed shells $ chsh -s /usr/bin/zsh # WAY 1) Set new default shell (zsh) for your user $ usermod --shell /usr/bin/zsh javi # WAY 2) Set new default shell (zsh) for a user (S4vitar lo hizo asi) $ nano /etc/passwd # WAY 3) Set new default shell (zsh) for a user $ echo $SHELL # Comprobar la nueva shell https://wiki.archlinux.org/title/zsh#Installation https://wiki.archlinux.org/title/Command-line_shell#Changing_your_default_shell 3 Ways to Change a Users Default Shell","title":"Change Bash to ZSH"},{"location":"cli_tools/customization/#better-prompt-zsh-theme-powerlevel10k","text":"$ sudo pacman -S zsh-theme-powerlevel10k $ echo 'source /usr/share/zsh-theme-powerlevel10k/powerlevel10k.zsh-theme' >> ~/.zshrc $ source ~/.zshrc $ p10k configure https://github.com/ahillio/powerlevel10k/blob/master/README.md#arch-linux","title":"Better prompt -&gt; zsh-theme-powerlevel10k"},{"location":"cli_tools/customization/#colors-on-terminal-outout","text":"alias ls='ls --color=auto' alias diff='diff --color=auto' alias grep='grep --color=auto' alias ip='ip -color=auto' Pacman has a color option. Uncomment the Color line in /etc/pacman.conf . https://wiki.archlinux.org/title/Color_output_in_console Other way is to install grml-zsh-config","title":"Colors on terminal outout"},{"location":"cli_tools/customization/#colors-on-terminal-commands-zsh-syntax-highlighting","text":"$ sudo pacman -S zsh-syntax-highlighting $ echo 'source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh' >> ~/.zshrc","title":"Colors on terminal commands -&gt; zsh-syntax-highlighting"},{"location":"cli_tools/customization/#sugerir-comandos-del-pasado-zsh-autosuggestions","text":"$ sudo pacman -S zsh-autosuggestions $ echo 'source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh' >> ~/.zshrc","title":"Sugerir comandos del pasado -&gt; zsh-autosuggestions"},{"location":"cli_tools/customization/#zsh-other-plugins","text":"zsh-completions zsh-sudo -> con esc esc te pone sudo al principio (source /usr/share/zsh-sudo/sudo.plugin.zsh ) zsh-suggestions fzf -> con ctrl + T busca # ZSH pluggins source /usr/share/zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh source /usr/share/zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh source /usr/share/zsh-theme-powerlevel10k/powerlevel10k.zsh-theme # General alias l='lsd' alias ls='lsd' alias ll='lsd -l' alias la='lsd -a' alias lla='lsd -la' alias tree='lsd --tree' # Jupyter notebook alias jn=\"jupyter notebook\" # Pacman alias i=\"sudo pacman -S\" # install a package alias s=\"pacman -Ss\" # search for a package alias u=\"sudo pacman -Syu\" # update the packages alias r=\"sudo pacman -Rns\" # remove a package alias install=\"sudo pacman -S\" # install a package alias search=\"pacman -Ss\" # search for a package alias update=\"sudo pacman -Syu\" # update the packages alias remove=\"sudo pacman -Rns\" # remove a package # Others alias title=\"figlet\" # Git function commit() { git add . msg=$@ # Every argument git commit -m \"$msg\" git push }","title":"ZSH: Other plugins"},{"location":"cli_tools/customization/#nano-nanorc","text":"set autoindent # Tthe newly created line will contain the same indent as the preceding line set tabsize 4 # Use a tab size of number columns. The default value is 8. set softwrap # Enable soft line wrapping for easier viewing of very long lines set nowrap # Don\u2019t hard-wrap text at all # set nohelp # Don\u2019t display the two help lines at the bottom of the screen. set linenumbers # Display of line numbers in front of the text. include \"/usr/share/nano/*.nanorc\" # Default Syntax highlighting include \"/usr/share/nano-syntax-highlighting/*.nanorc\" # syntax highlighting enhancements* sudo pacman -S nano-syntax-highlighting","title":"Nano: ~/.nanorc"},{"location":"cli_tools/customization/#tmux-tmuxconf","text":"####### SAME PROMT set -g default-terminal \"screen-256color\" if 'infocmp -x tmux-256color > /dev/null 2>&1' 'set -g default-terminal \"tmux-256color\"' ####### MOUSE (enable scroll) set -g mouse on # For tmux version 2.1 and above set -g terminal-overrides 'xterm*:smcup@:rmcup@' # Sane scrolling (instead of mimic arrrow keys) ####### Number windows and panes start at 1 instead of 0 set -g base-index 1 set -g pane-base-index 1 Oh my tmux! : Self-contained, pretty & versatile tmux configuration Practical Tmux","title":"TMUX ~/.tmux.conf"},{"location":"cli_tools/customization/#vim-vimrc","text":"\" Comments in Vimscript start with a `\"`. \" If you open this file in Vim, it'll be syntax highlighted for you. \" Vim is based on Vi. Setting `nocompatible` switches from the default \" Vi-compatibility mode and enables useful Vim functionality. This \" configuration option turns out not to be necessary for the file named \" '~/.vimrc', because Vim automatically enters nocompatible mode if that file \" is present. But we're including it here just in case this config file is \" loaded some other way (e.g. saved as `foo`, and then Vim started with \" `vim -u foo`). set nocompatible \" Use a line cursor within insert mode and a block cursor everywhere else. \" \" Using iTerm2? Go-to preferences / profile / colors and disable the smart bar \" cursor color. Then pick a cursor and highlight color that matches your theme. \" That will ensure your cursor is always visible within insert mode. \" \" Reference chart of values: \" Ps = 0 -> blinking block. \" Ps = 1 -> blinking block (default). \" Ps = 2 -> steady block. \" Ps = 3 -> blinking underline. \" Ps = 4 -> steady underline. \" Ps = 5 -> blinking bar (xterm). \" Ps = 6 -> steady bar (xterm). let &t_SI = \"\\e[6 q\" let &t_EI = \"\\e[2 q\" \" Turn on syntax highlighting. syntax on \" Disable the default Vim startup message. set shortmess+=I \" Show line numbers. set number \" This enables relative line numbering mode. With both number and \" relativenumber enabled, the current line shows the true line number, while \" all other lines (above and below) are numbered relative to the current line. \" This is useful because you can tell, at a glance, what count is needed to \" jump up or down to a particular line, by {count}k to go up or {count}j to go \" down. set relativenumber \" Always show the status line at the bottom, even if you only have one window open. set laststatus=2 \" The backspace key has slightly unintuitive behavior by default. For example, \" by default, you can't backspace before the insertion point set with 'i'. \" This configuration makes backspace behave more reasonably, in that you can \" backspace over anything. set backspace=indent,eol,start \" By default, Vim doesn't let you hide a buffer (i.e. have a buffer that isn't \" shown in any window) that has unsaved changes. This is to prevent you from \" \" forgetting about unsaved changes and then quitting e.g. via `:qa!`. We find \" hidden buffers helpful enough to disable this protection. See `:help hidden` \" for more information on this. set hidden \" This setting makes search case-insensitive when all characters in the string \" being searched are lowercase. However, the search becomes case-sensitive if \" it contains any capital letters. This makes searching more convenient. set ignorecase set smartcase \" Enable searching as you type, rather than waiting till you press enter. set incsearch \" Unbind some useless/annoying default key bindings. nmap Q <Nop> \" 'Q' in normal mode enters Ex mode. You almost never want this. \" Disable audible bell because it's annoying. set noerrorbells visualbell t_vb= \" Enable mouse support. You should avoid relying on this too much, but it can \" sometimes be convenient. set mouse+=a \" Try to prevent bad habits like using the arrow keys for movement. This is \" not the only possible bad habit. For example, holding down the h/j/k/l keys \" for movement, rather than using more efficient movement commands, is also a \" bad habit. The former is enforceable through a .vimrc, while we don't know \" how to prevent the latter. \" Do this in normal mode... nnoremap <Left> :echoe \"Use h\"<CR> nnoremap <Right> :echoe \"Use l\"<CR> nnoremap <Up> :echoe \"Use k\"<CR> nnoremap <Down> :echoe \"Use j\"<CR> \" ...and in insert mode inoremap <Left> <ESC>:echoe \"Use h\"<CR> inoremap <Right> <ESC>:echoe \"Use l\"<CR> inoremap <Up> <ESC>:echoe \"Use k\"<CR> inoremap <Down> <ESC>:echoe \"Use j\"<CR>","title":"VIM: ~/.vimrc"},{"location":"cli_tools/customization/#neovim-vimrc","text":"sudo pacman -S neovim","title":"NeoVIM: ~/.vimrc"},{"location":"cli_tools/customization/#iterm2","text":"","title":"iTerm2"},{"location":"cli_tools/customization/#shell-integration","text":"curl -L https://iterm2.com/shell_integration/zsh -o ~/.iterm2_shell_integration.zsh source ~/.iterm2_shell_integration.zsh # Add this line at ~/.zshrc # If hostname command not found install https://www.gnu.org/software/inetutils/ sudo pacman -S inetutils Download files from remote hosts with a click. You can right click on a filename (e.g., in the output of ls) to download it. Drag-drop files to upload with scp. Hold down option and drag-drop a file from Finder into iTerm2 to upload it.","title":"Shell Integration"},{"location":"cli_tools/customization/#imgcat","text":"wget https://iterm2.com/utilities/imgcat ; chmod 755 imgcat` Ranger + imgcat","title":"imgcat"},{"location":"cli_tools/customization/#set-ntp-time","text":"sudo pacman -S ntp sudo timedatectl set-ntp true","title":"Set NTP time"},{"location":"cli_tools/customization/#comunity-configsdotfiles","text":"Savitar https://www.youtube.com/watch?v=fshLf6u8B-w&t=3276s https://s4vitar.github.io/bspwm-configuration-files/# Josean Martinez Terminal https://www.youtube.com/watch?v=CF1tMjvHDRA https://github.com/rxyhn/dotfiles","title":"Comunity configs/dotfiles"},{"location":"cli_tools/git/","text":"Git Setup 1. Git Install git: sudo pacman -S github-cli Configure git: $ git config --global user.name \"Javi\" $ git config --global user.email franfdk17@gmail.com $ git config --global core.editor nano 2. Github Go to Github.com -> Settings -> Developer settings -> Personal access tokens https://github.com/settings/tokens Generate a Personal Access Token (PAT) with the minimum required scopes are 'repo', 'read:org', 'workflow' Copy the Personal Access Token Go to the terminal and install the GitHub CLI On Mac: brew install gh On Archlinux: sudo pacman -S github-cli In the terminal, enter gh auth login , then follow the prompts. What account do you want to log into? GitHub.com What is your preferred protocol for Git operations? HTTPS Authenticate Git with your GitHub credentials? Yes How would you like to authenticate GitHub CLI? Paste an authentication token here Old way (deprecated and unsecure) Save in ~/.git-credentials -> https://USER:PASS@github.com Execute git config --global credential.helper store https://atareao.es/software/programacion/github-en-el-terminal/ Git basics Undo local changes: git checkout . # Revert modified files (in this . directory) git clean -fd # Remove new untracked files (-f) and new directories (-d): Github Actions Archivo YAML ubicado en: .github/workflows/mi_nombre.yml Basic syntax Minimal action example: name: Simple workflow # 1) Nombre de la acci\u00f3n/workflow [OPTIONAL] on: [push] # 2) Cuando se ejecutar\u00e1 (el trigger) [REQUIRED] jobs: # 3) Que har\u00e1 example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\" Ejemplos de triggers disponibles on: # MANUALMENTE (desde la interfaz de github) workflow_dispatch: # PERIODICAMENTE ( with delay :( ) # Generally, the delay time is about 3 to 10 minutes. # Sometimes, it may be more, even dozens of minutes, or more than one hour. schedule: # * is a special character in YAML so you have to quote this string - cron: '30 5,17 * * *' # Cuando haces un push al repo [push] # Cuando haces un push en la rama master push: branches: - master # Cuando te hacen crean un pull request o un issue [pull_request_target, issues] Ejemplos de acciones disponibles run : Acciones propias para ejecutar comandos uses : Acciones de terceros disponibles el github actions marketplace. sintaxis: user/repo@version . # ACCION QUE TE CLONA EL REPO EN LA MAQUINA VIRTUAL - name: \u2b07\ufe0f Checkout the repo uses: actions/checkout@master with: fetch-depth: 1 ####################### # ACCION QUE PONE EL PYTHON EN LA MAQUINA VIRTUAL - name: \ud83d\udc0d Set up Python 3.8 uses: actions/setup-python@v2 with: python-version: '3.8' # ACCION QUE TE INSTALA ALGUN PAQUETE DE PYTHON - name: \ud83d\udcbf Install Zotero2Readwise Python package run: pip install zotero2readwise # ACCION QUE EJECUTA ALGUN SCRIPT DE PYTHON - name: \ud83d\ude80 Run Automation run: python run.py ${{ secrets.READWISE_TOKEN }} ${{ secrets.ZOTERO_KEY }} ${{ secrets.ZOTERO_ID }} ################## - name: Give permision to some script run: chmod +x my_script - name: Run script run: ./permision ################## - name: Commit and push changes run: | git config --global user.name \"your username\" git config --global user.email \"your email\" git add -A git commit -m \"commit message\" git push Ejecucion de trabajos en paralelo name: Simple workflow # Nombre de la acci\u00f3n/workflow on: [push] # Cuando se ejecuta (el trigger) jobs: example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\" example-job-1: # Trabajo 2 (se ejecuta en paralelo al trabajo 1) runs-on: windows-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 2 was automatically triggered!\" Ejecucion condicional name: Simple workflow # Nombre de la acci\u00f3n/workflow on: [push] # Cuando se ejecuta (el trigger) jobs: example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\" example-job-1: # Trabajo 2 (se ejecuta despues del trabajo 1) needs: example-job-1 runs-on: windows-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 2 was automatically triggered!\" References Using Github Actions & Pages to Publish Static Pages Based on Dynamic Data (Oct 2, 2021) CI/CD for Machine Learning: Test and Deploy Your ML Model with GitHub Actions (Jun 08, 2022)","title":"GIT"},{"location":"cli_tools/git/#git","text":"","title":"Git"},{"location":"cli_tools/git/#setup","text":"","title":"Setup"},{"location":"cli_tools/git/#1-git","text":"Install git: sudo pacman -S github-cli Configure git: $ git config --global user.name \"Javi\" $ git config --global user.email franfdk17@gmail.com $ git config --global core.editor nano","title":"1. Git"},{"location":"cli_tools/git/#2-github","text":"Go to Github.com -> Settings -> Developer settings -> Personal access tokens https://github.com/settings/tokens Generate a Personal Access Token (PAT) with the minimum required scopes are 'repo', 'read:org', 'workflow' Copy the Personal Access Token Go to the terminal and install the GitHub CLI On Mac: brew install gh On Archlinux: sudo pacman -S github-cli In the terminal, enter gh auth login , then follow the prompts. What account do you want to log into? GitHub.com What is your preferred protocol for Git operations? HTTPS Authenticate Git with your GitHub credentials? Yes How would you like to authenticate GitHub CLI? Paste an authentication token here","title":"2. Github"},{"location":"cli_tools/git/#old-way-deprecated-and-unsecure","text":"Save in ~/.git-credentials -> https://USER:PASS@github.com Execute git config --global credential.helper store https://atareao.es/software/programacion/github-en-el-terminal/","title":"Old way (deprecated and unsecure)"},{"location":"cli_tools/git/#git-basics","text":"Undo local changes: git checkout . # Revert modified files (in this . directory) git clean -fd # Remove new untracked files (-f) and new directories (-d):","title":"Git basics"},{"location":"cli_tools/git/#github-actions","text":"Archivo YAML ubicado en: .github/workflows/mi_nombre.yml","title":"Github Actions"},{"location":"cli_tools/git/#basic-syntax","text":"Minimal action example: name: Simple workflow # 1) Nombre de la acci\u00f3n/workflow [OPTIONAL] on: [push] # 2) Cuando se ejecutar\u00e1 (el trigger) [REQUIRED] jobs: # 3) Que har\u00e1 example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\"","title":"Basic syntax"},{"location":"cli_tools/git/#ejemplos-de-triggers-disponibles","text":"on: # MANUALMENTE (desde la interfaz de github) workflow_dispatch: # PERIODICAMENTE ( with delay :( ) # Generally, the delay time is about 3 to 10 minutes. # Sometimes, it may be more, even dozens of minutes, or more than one hour. schedule: # * is a special character in YAML so you have to quote this string - cron: '30 5,17 * * *' # Cuando haces un push al repo [push] # Cuando haces un push en la rama master push: branches: - master # Cuando te hacen crean un pull request o un issue [pull_request_target, issues]","title":"Ejemplos de triggers disponibles"},{"location":"cli_tools/git/#ejemplos-de-acciones-disponibles","text":"run : Acciones propias para ejecutar comandos uses : Acciones de terceros disponibles el github actions marketplace. sintaxis: user/repo@version . # ACCION QUE TE CLONA EL REPO EN LA MAQUINA VIRTUAL - name: \u2b07\ufe0f Checkout the repo uses: actions/checkout@master with: fetch-depth: 1 ####################### # ACCION QUE PONE EL PYTHON EN LA MAQUINA VIRTUAL - name: \ud83d\udc0d Set up Python 3.8 uses: actions/setup-python@v2 with: python-version: '3.8' # ACCION QUE TE INSTALA ALGUN PAQUETE DE PYTHON - name: \ud83d\udcbf Install Zotero2Readwise Python package run: pip install zotero2readwise # ACCION QUE EJECUTA ALGUN SCRIPT DE PYTHON - name: \ud83d\ude80 Run Automation run: python run.py ${{ secrets.READWISE_TOKEN }} ${{ secrets.ZOTERO_KEY }} ${{ secrets.ZOTERO_ID }} ################## - name: Give permision to some script run: chmod +x my_script - name: Run script run: ./permision ################## - name: Commit and push changes run: | git config --global user.name \"your username\" git config --global user.email \"your email\" git add -A git commit -m \"commit message\" git push","title":"Ejemplos de acciones disponibles"},{"location":"cli_tools/git/#ejecucion-de-trabajos-en-paralelo","text":"name: Simple workflow # Nombre de la acci\u00f3n/workflow on: [push] # Cuando se ejecuta (el trigger) jobs: example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\" example-job-1: # Trabajo 2 (se ejecuta en paralelo al trabajo 1) runs-on: windows-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 2 was automatically triggered!\"","title":"Ejecucion de trabajos en paralelo"},{"location":"cli_tools/git/#ejecucion-condicional","text":"name: Simple workflow # Nombre de la acci\u00f3n/workflow on: [push] # Cuando se ejecuta (el trigger) jobs: example-job-1: # Trabajo 1 runs-on: ubuntu-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 1 was automatically triggered!\" example-job-1: # Trabajo 2 (se ejecuta despues del trabajo 1) needs: example-job-1 runs-on: windows-latest # Maquina virtual donde se ejecuta steps: - run: echo \"The job 2 was automatically triggered!\"","title":"Ejecucion condicional"},{"location":"cli_tools/git/#references","text":"Using Github Actions & Pages to Publish Static Pages Based on Dynamic Data (Oct 2, 2021) CI/CD for Machine Learning: Test and Deploy Your ML Model with GitHub Actions (Jun 08, 2022)","title":"References"},{"location":"cli_tools/jupyter/","text":"Jupyter Start jupyter when conected with SSH jupyter notebook --no-browser Jupyter extensions sudo pip install jupyter_contrib_nbextensions sudo jupyter contrib nbextension install Jupyter Lab On the Remote Server Get the IP address of your server: $ hostname -I # 192.168.0.120 Configure Jupyter Lab Password $ jupyter notebook --generate-config $ jupyter notebook password Enter password: **** Verify password: **** Starting Jupyter Lab $ jupyter-lab --ip 0.0.0.0 --port 8888 --no-browser On client Navigate to http://<your-routers-public-ip>:8888 Enter password","title":"Jupyter"},{"location":"cli_tools/jupyter/#jupyter","text":"","title":"Jupyter"},{"location":"cli_tools/jupyter/#start-jupyter-when-conected-with-ssh","text":"jupyter notebook --no-browser","title":"Start jupyter when conected with SSH"},{"location":"cli_tools/jupyter/#jupyter-extensions","text":"sudo pip install jupyter_contrib_nbextensions sudo jupyter contrib nbextension install","title":"Jupyter extensions"},{"location":"cli_tools/jupyter/#jupyter-lab","text":"","title":"Jupyter Lab"},{"location":"cli_tools/jupyter/#on-the-remote-server","text":"Get the IP address of your server: $ hostname -I # 192.168.0.120 Configure Jupyter Lab Password $ jupyter notebook --generate-config $ jupyter notebook password Enter password: **** Verify password: **** Starting Jupyter Lab $ jupyter-lab --ip 0.0.0.0 --port 8888 --no-browser","title":"On the Remote Server"},{"location":"cli_tools/jupyter/#on-client","text":"Navigate to http://<your-routers-public-ip>:8888 Enter password","title":"On client"},{"location":"cli_tools/overthewire/","text":"Over the wire Bandit ssh bandit0@bandit.labs.overthewire.org -p 2220 Level Entry SSH password Answer command bandit0 bandit0 cat readme bandit1 NH2SXQwcBdpmTEzi3bvBHMM9H66vVXjL cat ./- bandit2 rRGizSaX8Mk1RTb1CNQoXTcYZWU6lgzi cat spaces\\ in\\ this\\ filename bandit3 aBZ0W5EmUfAf7kHTQeOwd8bauFJ2lAiG cat inhere/.hidden bandit4 2EW7BBsr6aMMoJ2HjW067dm8EgX26xNe file inhere/* o ls inhere/* | xargs file bandit5 lrIWWI6bB37kxfiCQZqUdOIYfr6eEeqR find . -readable ! -executable -size 1033c bandit6 P4L4vucdmLnm8I7Vl7jG1ApGSfjYKqJU find / -user bandit7 -group bandit6 -size 33c 2> /dev/null bandit7 z7WtoNQU2XfjmMtWA8u5rN4vzqu4v99S grep millionth data.txt bandit8 TESKZC0XvTetK0S9xNwm25STk5iWrBvP sort data.txt | uniq -u bandit9 EN632PlfYiZbn3PhVK3XOGSlNInNE00t strings data.txt | grep = bandit10 G7w8LIi6J3kTb8A7j9LgrywtEUlyyp6s base64 -d data.txt bandit11 6zPeziLdR2RKNdNYFNb6nVCKzphlXHBM cat data.txt | tr a-zA-Z n-za-mN-ZA-M bandit12 JVNBBFSmZwKKOP0XbFXOoW8chDz5yVRv cat data.txt | xxd -r | gzip -d - | ..... bandit13 wbWdlBxEir4CaE8LaPhauuOo6pwRmrDw ssh -i sshkey.private bandit14@localhost -p 2220 bandit14 fGrHPx402xGC7U7rXKDaxiWFTOiF0ENq telnet localhost 30000 then enter pass. Or cat /etc/bandit_pass/bandit14 | nc localhost 30000 bandit15 jN2kgmIXJ6fShzhT2avhotn4Zcka6tnt openssl s_client -connect localhost:30001 then enter pass bandit16 JQttfApK4SeyHwDlI9SXGR50qclOAil1 nmap --open -T5 -v -n -p31000-32000 127.0.0.1 openssl s_client -connect localhost:31790 e introducir contenido de /etc/bandit_pass/bandit16 bandit17 VwOSWtCA7lRKkTfbr2IDh6awj9RNZM5e diff passwords.new passwords.old bandit18 hga5tuuCLF6fFzUpnagiMN8ssu9LFrdg ssh bandit18@bandit.labs.overthewire.org -p 2220 cat readme bandit19 awhqfNnAbc1naukrpqDYcF95h7HoMTrC ./bandit20-do cat /etc/bandit_pass/bandit20 bandit20 VxCazJaVykI6W36BkBU0mJTCM8rR95XT window 1: listen on nc -l -p 5757 window 2: ./suconnect 5757 window 1: paste currnt level password on nc bandit21 NvEJF7oVjkddltPSrdKEFOllh9V1IBcq cat cronjob_bandit22 cat /usr/bin/cronjob_bandit22.sh bandit22 WdDozAdTM2z9DiFEQ2mGlwngMfj4EZff echo I am user bandit23 | md5sum bandir23 QYw0Y2aiA672PsMmh9puTQuhoz8SyR2G","title":"Over the wire"},{"location":"cli_tools/overthewire/#over-the-wire","text":"","title":"Over the wire"},{"location":"cli_tools/overthewire/#bandit","text":"ssh bandit0@bandit.labs.overthewire.org -p 2220 Level Entry SSH password Answer command bandit0 bandit0 cat readme bandit1 NH2SXQwcBdpmTEzi3bvBHMM9H66vVXjL cat ./- bandit2 rRGizSaX8Mk1RTb1CNQoXTcYZWU6lgzi cat spaces\\ in\\ this\\ filename bandit3 aBZ0W5EmUfAf7kHTQeOwd8bauFJ2lAiG cat inhere/.hidden bandit4 2EW7BBsr6aMMoJ2HjW067dm8EgX26xNe file inhere/* o ls inhere/* | xargs file bandit5 lrIWWI6bB37kxfiCQZqUdOIYfr6eEeqR find . -readable ! -executable -size 1033c bandit6 P4L4vucdmLnm8I7Vl7jG1ApGSfjYKqJU find / -user bandit7 -group bandit6 -size 33c 2> /dev/null bandit7 z7WtoNQU2XfjmMtWA8u5rN4vzqu4v99S grep millionth data.txt bandit8 TESKZC0XvTetK0S9xNwm25STk5iWrBvP sort data.txt | uniq -u bandit9 EN632PlfYiZbn3PhVK3XOGSlNInNE00t strings data.txt | grep = bandit10 G7w8LIi6J3kTb8A7j9LgrywtEUlyyp6s base64 -d data.txt bandit11 6zPeziLdR2RKNdNYFNb6nVCKzphlXHBM cat data.txt | tr a-zA-Z n-za-mN-ZA-M bandit12 JVNBBFSmZwKKOP0XbFXOoW8chDz5yVRv cat data.txt | xxd -r | gzip -d - | ..... bandit13 wbWdlBxEir4CaE8LaPhauuOo6pwRmrDw ssh -i sshkey.private bandit14@localhost -p 2220 bandit14 fGrHPx402xGC7U7rXKDaxiWFTOiF0ENq telnet localhost 30000 then enter pass. Or cat /etc/bandit_pass/bandit14 | nc localhost 30000 bandit15 jN2kgmIXJ6fShzhT2avhotn4Zcka6tnt openssl s_client -connect localhost:30001 then enter pass bandit16 JQttfApK4SeyHwDlI9SXGR50qclOAil1 nmap --open -T5 -v -n -p31000-32000 127.0.0.1 openssl s_client -connect localhost:31790 e introducir contenido de /etc/bandit_pass/bandit16 bandit17 VwOSWtCA7lRKkTfbr2IDh6awj9RNZM5e diff passwords.new passwords.old bandit18 hga5tuuCLF6fFzUpnagiMN8ssu9LFrdg ssh bandit18@bandit.labs.overthewire.org -p 2220 cat readme bandit19 awhqfNnAbc1naukrpqDYcF95h7HoMTrC ./bandit20-do cat /etc/bandit_pass/bandit20 bandit20 VxCazJaVykI6W36BkBU0mJTCM8rR95XT window 1: listen on nc -l -p 5757 window 2: ./suconnect 5757 window 1: paste currnt level password on nc bandit21 NvEJF7oVjkddltPSrdKEFOllh9V1IBcq cat cronjob_bandit22 cat /usr/bin/cronjob_bandit22.sh bandit22 WdDozAdTM2z9DiFEQ2mGlwngMfj4EZff echo I am user bandit23 | md5sum bandir23 QYw0Y2aiA672PsMmh9puTQuhoz8SyR2G","title":"Bandit"},{"location":"cli_tools/pacman/","text":"Pacman pacman -S {pkg} # Install package pacman -Syu # Update packages. Update database (-y) and upgrade packages (-u) pacman -Ss {pkg} # Search for a new package pacman -Q # Display all installed packages pacman -Qe # Display only packages explicitly installed pacman -Qn # Display only packages installed from main repositories pacman -Qm # Display only packages installed from AUR pacman -Qdt # Display orphaned dependencies pacman -Qs {pkg} # Search local repository for package pacman -R {pkg} # Remove package {pkg} pacman -Rs {pkg} # Remove package as well as unneeded dependencies (-s) pacman -Rns {pkg} # Remove package, dependencies (-s), and system config files (-n) Arch User Repository (AUR) Manually yay (AUR Helper) pamac (AUR Helper) Preparation (install yay) sudo pacman -S --needed base-devel git git clone https://aur.archlinux.org/yay.git cd yay makepkg -si Default in manjaro Install some package (chrome) git clone https://aur.archlinux.org/google-chrome.git cd google-chrome makepkg -si yay -S google-chrome pamac install google-chrome Upgrade some package (chrome) cd google-chrome git pull makepkg -si yay -Syu pamac upgrade -a YAY https://www.chrisatmachine.com/Linux/03-AUR-yay/ PARU git clone https://aur.archlinux.org/paru-bin.git cd paru-bin makepkg -si Create pacman packege Templates: Single package (with specific vesion): /usr/share/pacman/PKGBUILD.proto Single package (with latest vesion, suffix -git ): /usr/share/pacman/PKGBUILD-vcs.proto Multiple package: /usr/share/pacman/PKGBUILD-split.proto Python PIP: pip install --user package Note we\u2019ve installed here using the user flag to install this Python package only for the current user. However, you might prefer to use a tool like pipx to install Python applications in an isolated environment. Conda Conda is SLOOOOOOOW. If you really need to use conda you can use Mamba","title":"\ud83d\udce6 Software (pacman,aur,pip)"},{"location":"cli_tools/pacman/#pacman","text":"pacman -S {pkg} # Install package pacman -Syu # Update packages. Update database (-y) and upgrade packages (-u) pacman -Ss {pkg} # Search for a new package pacman -Q # Display all installed packages pacman -Qe # Display only packages explicitly installed pacman -Qn # Display only packages installed from main repositories pacman -Qm # Display only packages installed from AUR pacman -Qdt # Display orphaned dependencies pacman -Qs {pkg} # Search local repository for package pacman -R {pkg} # Remove package {pkg} pacman -Rs {pkg} # Remove package as well as unneeded dependencies (-s) pacman -Rns {pkg} # Remove package, dependencies (-s), and system config files (-n)","title":"Pacman"},{"location":"cli_tools/pacman/#arch-user-repository-aur","text":"Manually yay (AUR Helper) pamac (AUR Helper) Preparation (install yay) sudo pacman -S --needed base-devel git git clone https://aur.archlinux.org/yay.git cd yay makepkg -si Default in manjaro Install some package (chrome) git clone https://aur.archlinux.org/google-chrome.git cd google-chrome makepkg -si yay -S google-chrome pamac install google-chrome Upgrade some package (chrome) cd google-chrome git pull makepkg -si yay -Syu pamac upgrade -a","title":"Arch User Repository (AUR)"},{"location":"cli_tools/pacman/#yay","text":"https://www.chrisatmachine.com/Linux/03-AUR-yay/","title":"YAY"},{"location":"cli_tools/pacman/#paru","text":"git clone https://aur.archlinux.org/paru-bin.git cd paru-bin makepkg -si","title":"PARU"},{"location":"cli_tools/pacman/#create-pacman-packege","text":"Templates: Single package (with specific vesion): /usr/share/pacman/PKGBUILD.proto Single package (with latest vesion, suffix -git ): /usr/share/pacman/PKGBUILD-vcs.proto Multiple package: /usr/share/pacman/PKGBUILD-split.proto","title":"Create pacman packege"},{"location":"cli_tools/pacman/#python","text":"","title":"Python"},{"location":"cli_tools/pacman/#pip-pip-install-user-package","text":"Note we\u2019ve installed here using the user flag to install this Python package only for the current user. However, you might prefer to use a tool like pipx to install Python applications in an isolated environment.","title":"PIP: pip install --user package"},{"location":"cli_tools/pacman/#conda","text":"Conda is SLOOOOOOOW. If you really need to use conda you can use Mamba","title":"Conda"},{"location":"cli_tools/parallel/","text":"GNU Parallel https://www.baeldung.com/linux/processing-commands-in-parallel cat photos.txt | sed 's/,/ /' > photosTAB.txt # Option 1 (sequential with for loop) cat ../photosTAB.txt | while read id url; do wget -O \"$id\" \"$url\"; done # Option 2 (sequential with for loop) wget --input-file=<(tail ../photosTAB.txt | cut -d \",\" -f 2) # Option 3 (parallel with xargs) echo $URL_LIST | xargs -n 1 -P 8 wget -q # Option 4 (parallel with gnu parallel) cat ../photosTAB.txt | parallel --jobs 100 --colsep '\\t' wget -O {1} {2} # this code for i in *gz; do zcat $i > $(basename $i .gz).unpacked done # Can be remplazed with parallel 'zcat {} > {.}.unpacked' ::: *.gz Real world examples ### Download files cat ../photosTAB.txt | parallel --jobs 100 --colsep '\\t' wget -O {1} {2} ### Find files that doenst't exists cut -d, -f5 main.csv | parallel --progress '[ -f {} ] || echo {} >> bad_imgs' ### Check if images are corrupted cut -d, -f5 main.csv | parallel --progress 'identify {} > /dev/null || echo {} >> bad_imgs' {} Input line {.} Input line without extension. {/} Basename of input line {//} Dirname of input line {/.} Basename of input line without extension. {0} 1st culumn of input_line {1} 2nd culumn of input_line","title":"GNU Parallel"},{"location":"cli_tools/parallel/#gnu-parallel","text":"https://www.baeldung.com/linux/processing-commands-in-parallel cat photos.txt | sed 's/,/ /' > photosTAB.txt","title":"GNU Parallel"},{"location":"cli_tools/parallel/#option-1-sequential-with-for-loop","text":"cat ../photosTAB.txt | while read id url; do wget -O \"$id\" \"$url\"; done","title":"# Option 1 (sequential with for loop)"},{"location":"cli_tools/parallel/#option-2-sequential-with-for-loop","text":"wget --input-file=<(tail ../photosTAB.txt | cut -d \",\" -f 2)","title":"# Option 2 (sequential with for loop)"},{"location":"cli_tools/parallel/#option-3-parallel-with-xargs","text":"echo $URL_LIST | xargs -n 1 -P 8 wget -q","title":"# Option 3 (parallel with xargs)"},{"location":"cli_tools/parallel/#option-4-parallel-with-gnu-parallel","text":"cat ../photosTAB.txt | parallel --jobs 100 --colsep '\\t' wget -O {1} {2} # this code for i in *gz; do zcat $i > $(basename $i .gz).unpacked done # Can be remplazed with parallel 'zcat {} > {.}.unpacked' ::: *.gz","title":"# Option 4 (parallel with gnu parallel)"},{"location":"cli_tools/parallel/#real-world-examples","text":"### Download files cat ../photosTAB.txt | parallel --jobs 100 --colsep '\\t' wget -O {1} {2} ### Find files that doenst't exists cut -d, -f5 main.csv | parallel --progress '[ -f {} ] || echo {} >> bad_imgs' ### Check if images are corrupted cut -d, -f5 main.csv | parallel --progress 'identify {} > /dev/null || echo {} >> bad_imgs' {} Input line {.} Input line without extension. {/} Basename of input line {//} Dirname of input line {/.} Basename of input line without extension. {0} 1st culumn of input_line {1} 2nd culumn of input_line","title":"Real world examples"},{"location":"cli_tools/plotting/","text":"Plotting gnuplot gnuplot -e \"set terminal jpeg; plot [-5:5] sin(x)\" | display gnuplot -e \"set terminal jpeg; plot [-5:5] sin(x)\" > sin.jpg primes 1 100 | gnuplot -p -e 'plot \"/dev/stdin\"' feedgnuplot https://github.com/dkogan/feedgnuplot/blob/master/guide/guide.org uplot https://github.com/red-data-tools/YouPlot","title":"\ud83d\udcca Plotting (gnuplot)"},{"location":"cli_tools/plotting/#plotting","text":"","title":"Plotting"},{"location":"cli_tools/plotting/#gnuplot","text":"gnuplot -e \"set terminal jpeg; plot [-5:5] sin(x)\" | display gnuplot -e \"set terminal jpeg; plot [-5:5] sin(x)\" > sin.jpg primes 1 100 | gnuplot -p -e 'plot \"/dev/stdin\"'","title":"gnuplot"},{"location":"cli_tools/plotting/#feedgnuplot","text":"https://github.com/dkogan/feedgnuplot/blob/master/guide/guide.org","title":"feedgnuplot"},{"location":"cli_tools/plotting/#uplot","text":"https://github.com/red-data-tools/YouPlot","title":"uplot"},{"location":"cli_tools/process_vs_threads/","text":"Process virtual memory VIRTUAL MEMORY OF A PROCESS 0x00000000 \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557 \u2551 \u2551 \u2551 \u2551 0x08048000 \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562 \u2551 TEXT \u2551\\ \u2551 (Binary code) \u2551 | \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562 | Initiali filled \u2551 DATA \u2551 | with content of \u2551 Initialized data \u2551 | my_program.out \u2551 (global and static variables) \u2551/ \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562 \u2551 BSS \u2551\\ \u2551 Uninitialized data \u2551 | \u2551 (global and static variables) \u2551 | Initiali filled \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562 | with zeros \u2551 HEAP \u2551 | \u2551 Dynamic memory \u2551 | \u2551 malloc/free in C \u2551 | \u2551 new/delete in C++ \u2551/ \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562-> brk (program break) \u2551 \u25bc \u2551 \u2551 \u2551 \u2551 ... \u2551 \u2551 \u2551 \u2551 \u25b2 \u2551 \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562 \u2551 MEMORY MAPPING \u2551\\ \u2551 - Included shared libraries (printf...) \u2551 | For #include libraries \u2551 - Shared file for IPC mmap(SHARED, FILE) \u2551 | Initiali filled \u2551 - Shared mem. for IPC mmap(SHARED, ANON) \u2551 | Initiali filled \u2551 - Read file fast mmap(PRIVATE, FILE) \u2551 | with content of \u2551 - Subthreads stack \u2551 | libc.so, ... \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562/ \u2551 \u25bc \u2551 \u2551 \u2551 \u2551 ... \u2551 \u2551 \u2551 \u2551 \u25b2 \u2551 \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562\\ \u2551 Main thread STACK \u2551 | Initiali filled \u2551 \u2551 | with zeros 3GB \u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563/ \u2551 KERNEL SPACE \u2551 \u2551 User can not read/write here \u2551 4GB \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d A Process owns: PID: Process Identifier PPID: Parent PID UID: User Identifier (the person who initiated) GID: Group identifier (the person who initiated) TEXT segment (binary code instructions) DATA segment (static and global data) Global variables: int myglobalint = 5; Static variables: static char* mystaticstr = \"hello\"; BSS segment (uninitialized data) static char* my_uninitialized_str HEAP segment (Dynamically-allocated memory) malloc / free in C new / delete in C++ MEMORY MAPPING segment FILE OR ANONYMOUS FILE mappings (code of included libraries, eg printf ) ANONYMOUS mappping SHARED vs PRIVATE MAIN STACK segment Space for the stack of the main thread Page table (maps virtual adresses into physical addrs) Open files descriptors (every open file has an offset) Signal handlers Current working directory Enviroment variables ( $ env A=val ./program ) Command line arguments (see them in /proc/PID/cmdline ) Main Thread --> ALWAYS Sub Threads --> OPTIONAL A Thread owns: Thread ID Stack (called functions, local variables, return addresses) Stack space for a new thread is created by the parent thread with mmap(). So they're in the \"memory map segment\" Saved Registers General purpose registers PC (program counter) SP (stack pointer) Priority (scheduling information) thread-thread switching Thread take less time to create process-process switching Much slower than thread-thread switching Refenrences Jacob Sorber: How processes get more memory. (mmap, brk) Jacob Sorber: How to Map Files into Memory in C Jacob Sorber: Virtual Memory Jacob Sorber: The Heap ByteByteGo: Process vs Thread Chris Kanich: Process vs Thread Chris Kanich: when to use processes, when to use threads Chris Kanich: understanding mmap Julia Evans: Bit size Linux https://stackoverflow.com/questions/44858528/where-are-the-stacks-for-the-other-threads-located-in-a-process-virtual-address https://people.cs.rutgers.edu/~pxk/416/notes/05-threads.html","title":"Process vs threads"},{"location":"cli_tools/process_vs_threads/#a-process-owns","text":"PID: Process Identifier PPID: Parent PID UID: User Identifier (the person who initiated) GID: Group identifier (the person who initiated) TEXT segment (binary code instructions) DATA segment (static and global data) Global variables: int myglobalint = 5; Static variables: static char* mystaticstr = \"hello\"; BSS segment (uninitialized data) static char* my_uninitialized_str HEAP segment (Dynamically-allocated memory) malloc / free in C new / delete in C++ MEMORY MAPPING segment FILE OR ANONYMOUS FILE mappings (code of included libraries, eg printf ) ANONYMOUS mappping SHARED vs PRIVATE MAIN STACK segment Space for the stack of the main thread Page table (maps virtual adresses into physical addrs) Open files descriptors (every open file has an offset) Signal handlers Current working directory Enviroment variables ( $ env A=val ./program ) Command line arguments (see them in /proc/PID/cmdline ) Main Thread --> ALWAYS Sub Threads --> OPTIONAL","title":"A Process owns:"},{"location":"cli_tools/process_vs_threads/#a-thread-owns","text":"Thread ID Stack (called functions, local variables, return addresses) Stack space for a new thread is created by the parent thread with mmap(). So they're in the \"memory map segment\" Saved Registers General purpose registers PC (program counter) SP (stack pointer) Priority (scheduling information)","title":"A Thread owns:"},{"location":"cli_tools/process_vs_threads/#thread-thread-switching","text":"Thread take less time to create","title":"thread-thread switching"},{"location":"cli_tools/process_vs_threads/#process-process-switching","text":"Much slower than thread-thread switching","title":"process-process switching"},{"location":"cli_tools/process_vs_threads/#refenrences","text":"Jacob Sorber: How processes get more memory. (mmap, brk) Jacob Sorber: How to Map Files into Memory in C Jacob Sorber: Virtual Memory Jacob Sorber: The Heap ByteByteGo: Process vs Thread Chris Kanich: Process vs Thread Chris Kanich: when to use processes, when to use threads Chris Kanich: understanding mmap Julia Evans: Bit size Linux https://stackoverflow.com/questions/44858528/where-are-the-stacks-for-the-other-threads-located-in-a-process-virtual-address https://people.cs.rutgers.edu/~pxk/416/notes/05-threads.html","title":"Refenrences"},{"location":"cli_tools/ssh/","text":"SSH En el servidor: sudo systemctl status sshd # Ver si esta encendido sudo systemctl start sshd # Encender sudo systemctl restart sshd # Reiniciar sudo systemctl stop sshd # Apagar sudo systemctl enable sshd # Al arrancar por defecto: encendido sudo systemctl disable sshd # Al arrancar por defecto: apagado Common flags ssh javi@192.168.0.1 -L 8888:localhost:8888 : Redirect port ssh javi@192.168.0.1 -p 2222 : Conct over a specific port (Defualt port is 22) En el cliente. Conectar y redirigir puerto 8888 (juypter) ssh javi@192.168.0.103 -L 8888:localhost:8888 # Conectar jupyter notebook --no-browser # Abrir Jupyter exit # Desconectar o CTL+ Key generation # Gerenar claves publica y privada ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 # Llevar la clave publica al cliente cat .ssh/id_ed25519.pub | ssh foobar@remote 'cat >> ~/.ssh/authorized_keys' -o : Save the private-key using the new OpenSSH format rather than the PEM format. Actually, this option is implied when you specify the key type as ed25519. -a : It\u2019s the numbers of KDF (Key Derivation Function) rounds. Higher numbers result in slower passphrase verification, increasing the resistance to brute-force password cracking should the private-key be stolen. -t : Specifies the type of key to create, in our case the Ed25519. -f : Specify the filename of the generated key file. If you want it to be discovered automatically by the SSH agent, it must be stored in the default .ssh directory within your home directory. Dejar un programa largo en ejecucion Simple option ( nohup ) nohup COMMAND # Run a command immune to hangups nohup COMMAND > FILE # Ademas puede guardar su salida estandar en un fichero Session programs option ( screen or tmux ) Son programas que mantienen la sesion activa. ssh log in into your remote machine. tmux or screen Start the long process you want. Leave/detach tmux or screen session, but leave your processes running. Ctrl+A then Ctrl+D (para salir de screen) Ctrl+B then Ctrl+D (para salir de tmux) exit ssh ...One eternity later... ssh log in again into your remote machine. Return back to see the output of your process. screen -r : \"resume\" your screen session tmux a : \"atach\" to the last tmux session","title":"SSH"},{"location":"cli_tools/ssh/#ssh","text":"","title":"SSH"},{"location":"cli_tools/ssh/#en-el-servidor","text":"sudo systemctl status sshd # Ver si esta encendido sudo systemctl start sshd # Encender sudo systemctl restart sshd # Reiniciar sudo systemctl stop sshd # Apagar sudo systemctl enable sshd # Al arrancar por defecto: encendido sudo systemctl disable sshd # Al arrancar por defecto: apagado","title":"En el servidor:"},{"location":"cli_tools/ssh/#common-flags","text":"ssh javi@192.168.0.1 -L 8888:localhost:8888 : Redirect port ssh javi@192.168.0.1 -p 2222 : Conct over a specific port (Defualt port is 22)","title":"Common flags"},{"location":"cli_tools/ssh/#en-el-cliente-conectar-y-redirigir-puerto-8888-juypter","text":"ssh javi@192.168.0.103 -L 8888:localhost:8888 # Conectar jupyter notebook --no-browser # Abrir Jupyter exit # Desconectar o CTL+","title":"En el cliente. Conectar y redirigir puerto 8888 (juypter)"},{"location":"cli_tools/ssh/#key-generation","text":"# Gerenar claves publica y privada ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 # Llevar la clave publica al cliente cat .ssh/id_ed25519.pub | ssh foobar@remote 'cat >> ~/.ssh/authorized_keys' -o : Save the private-key using the new OpenSSH format rather than the PEM format. Actually, this option is implied when you specify the key type as ed25519. -a : It\u2019s the numbers of KDF (Key Derivation Function) rounds. Higher numbers result in slower passphrase verification, increasing the resistance to brute-force password cracking should the private-key be stolen. -t : Specifies the type of key to create, in our case the Ed25519. -f : Specify the filename of the generated key file. If you want it to be discovered automatically by the SSH agent, it must be stored in the default .ssh directory within your home directory.","title":"Key generation"},{"location":"cli_tools/ssh/#dejar-un-programa-largo-en-ejecucion","text":"","title":"Dejar un programa largo en ejecucion"},{"location":"cli_tools/ssh/#simple-option-nohup","text":"nohup COMMAND # Run a command immune to hangups nohup COMMAND > FILE # Ademas puede guardar su salida estandar en un fichero","title":"Simple option (nohup)"},{"location":"cli_tools/ssh/#session-programs-option-screen-or-tmux","text":"Son programas que mantienen la sesion activa. ssh log in into your remote machine. tmux or screen Start the long process you want. Leave/detach tmux or screen session, but leave your processes running. Ctrl+A then Ctrl+D (para salir de screen) Ctrl+B then Ctrl+D (para salir de tmux) exit ssh ...One eternity later... ssh log in again into your remote machine. Return back to see the output of your process. screen -r : \"resume\" your screen session tmux a : \"atach\" to the last tmux session","title":"Session programs option (screen or tmux)"},{"location":"cli_tools/tmux/","text":"TMUX The most popular terminal multiplexer these days is tmux . - tmux can have several sessions . - a session can have several windows (like tabs) - a window can have several panes (like a divided terminal) Commands Outside tmux tmux : starts a new session. tmux new -s NAME : starts it with that name. tmux ls : lists the current sessions. tmux a : attaches the last session. tmux -t sesName : attaches to specific session. tmux kill-server : Removes all sessions and kill tmux server Inside tmux : [Ctrl+b] c : Creates a new window. To close it you can just terminate the shells doing <C-d> [Ctrl+b] , : Rename the current window [Ctrl+b] 0 : Go to window 0 [Ctrl+b] 1 : Go to window 1 [Ctrl+b] 2 : Go to window 2 [Ctrl+d] x : Kill the current pane/window(if1pane)/sesion(if1window) [Ctrl+b] d : Detaches the current session (remains active in background) Less common [Ctrl+b] w : List current windows [Ctrl+b] p : Go to the previous window [Ctrl+b] n : Go to the next window Panes : Like vim splits, panes let you have multiple shells in the same visual display. [Ctrl+b] \" Split the current pane horizontally [Ctrl+b] % Split the current pane vertically [Ctrl+b] <direction> Move to the pane in the specified direction . Direction here means arrow keys. [Ctrl+b] z Toggle zoom for the current pane [Ctrl+b] [ Start scrollback. You can then press <space> to start a selection and <enter> to copy that selection. [Ctrl+b] <space> Cycle through pane arrangements. iTerm2 TMUX Integration Each TMUX window will be a real window . tmux -CC : Create a new session tmux -CC attach Attach to Reference: https://stackoverflow.com/questions/35421819/tmux-in-multiple-terminal-app-windows TMUX Server ( Autostart with systemd ) Put this file in /etc/systemd/system/tmux.service : cd /etc/systemd/system sudo nano tmux.service [Unit] Description=Tmux server [Service] Type=forking User=javi ExecStart=/usr/bin/tmux new -s 0 -d ExecStop=/usr/bin/tmux kill-server [Install] WantedBy=multi-user.target Enable service with: sudo systemctl enable tmux.service Learn more Video de s4vitar: Aprendiendo a usar tmux desde 0 Practical Tmux https://hackernoon.com/using-tmux-to-improve-your-terminal-experience-jt4932zv","title":"TMUX"},{"location":"cli_tools/tmux/#tmux","text":"The most popular terminal multiplexer these days is tmux . - tmux can have several sessions . - a session can have several windows (like tabs) - a window can have several panes (like a divided terminal)","title":"TMUX"},{"location":"cli_tools/tmux/#commands","text":"Outside tmux tmux : starts a new session. tmux new -s NAME : starts it with that name. tmux ls : lists the current sessions. tmux a : attaches the last session. tmux -t sesName : attaches to specific session. tmux kill-server : Removes all sessions and kill tmux server Inside tmux : [Ctrl+b] c : Creates a new window. To close it you can just terminate the shells doing <C-d> [Ctrl+b] , : Rename the current window [Ctrl+b] 0 : Go to window 0 [Ctrl+b] 1 : Go to window 1 [Ctrl+b] 2 : Go to window 2 [Ctrl+d] x : Kill the current pane/window(if1pane)/sesion(if1window) [Ctrl+b] d : Detaches the current session (remains active in background) Less common [Ctrl+b] w : List current windows [Ctrl+b] p : Go to the previous window [Ctrl+b] n : Go to the next window Panes : Like vim splits, panes let you have multiple shells in the same visual display. [Ctrl+b] \" Split the current pane horizontally [Ctrl+b] % Split the current pane vertically [Ctrl+b] <direction> Move to the pane in the specified direction . Direction here means arrow keys. [Ctrl+b] z Toggle zoom for the current pane [Ctrl+b] [ Start scrollback. You can then press <space> to start a selection and <enter> to copy that selection. [Ctrl+b] <space> Cycle through pane arrangements.","title":"Commands"},{"location":"cli_tools/tmux/#iterm2-tmux-integration","text":"Each TMUX window will be a real window . tmux -CC : Create a new session tmux -CC attach Attach to Reference: https://stackoverflow.com/questions/35421819/tmux-in-multiple-terminal-app-windows","title":"iTerm2 TMUX Integration"},{"location":"cli_tools/tmux/#tmux-server-autostart-with-systemd","text":"Put this file in /etc/systemd/system/tmux.service : cd /etc/systemd/system sudo nano tmux.service [Unit] Description=Tmux server [Service] Type=forking User=javi ExecStart=/usr/bin/tmux new -s 0 -d ExecStop=/usr/bin/tmux kill-server [Install] WantedBy=multi-user.target Enable service with: sudo systemctl enable tmux.service","title":"TMUX Server (Autostart with systemd)"},{"location":"cli_tools/tmux/#learn-more","text":"Video de s4vitar: Aprendiendo a usar tmux desde 0 Practical Tmux https://hackernoon.com/using-tmux-to-improve-your-terminal-experience-jt4932zv","title":"Learn more"},{"location":"cli_tools/vim/","text":"Vim Modes ESC : Normal mode. For moving around a file; reading; going to file to file i : Insert mode. For inserting text : : Command-line mode. For running a command r : Replace mode. For replacing text v : Visual mode. For selecting blocks of text SHIFT + v : Visual line mode Ctrl + v : Visual block mode Command-line Command mode can be entered by typing : in Normal mode. Your cursor will jump to the command line at the bottom of the screen upon pressing : . This mode has many functionalities, including opening, saving, and closing files, and quitting Vim . :q quit (close window) :w save (\"write\") :wq save and quit :e {name of file} open file for editing :ls show open buffers :help {topic} open help :help :w opens help for the :w command :help w opens help for the w movement NeoVIM NvimTreeToogle: left tree panel nvchad","title":"Vim"},{"location":"cli_tools/vim/#vim","text":"","title":"Vim"},{"location":"cli_tools/vim/#modes","text":"ESC : Normal mode. For moving around a file; reading; going to file to file i : Insert mode. For inserting text : : Command-line mode. For running a command r : Replace mode. For replacing text v : Visual mode. For selecting blocks of text SHIFT + v : Visual line mode Ctrl + v : Visual block mode","title":"Modes"},{"location":"cli_tools/vim/#command-line","text":"Command mode can be entered by typing : in Normal mode. Your cursor will jump to the command line at the bottom of the screen upon pressing : . This mode has many functionalities, including opening, saving, and closing files, and quitting Vim . :q quit (close window) :w save (\"write\") :wq save and quit :e {name of file} open file for editing :ls show open buffers :help {topic} open help :help :w opens help for the :w command :help w opens help for the w movement","title":"Command-line"},{"location":"cli_tools/vim/#neovim","text":"NvimTreeToogle: left tree panel nvchad","title":"NeoVIM"},{"location":"cli_tools_data/csv/","text":"Text data sort Sorting Soring options [bdfgiMhnRrV]: sort -r : Reverse order sort -n : Numerically sort -rn : Numerically reversed sort -R : Randomly (each time is different). Similar to shuf Sorting by fields: sort -t ',' -k 2 file.csv : Sort a CSV file by 2nd column (until the end of line). sort -t ',' -k 2,2 file.csv : Sort a CSV file by 2nd column. sort -t ',' -k 2n,2 file.csv : Sort NUMERICALLY a CSV file by 2nd column. sort -t, -k 3n,3 -k 1n,1 file.csv : Sort NUMERICALLY a CSV file by 3rd column, then by 1st column uniq See uniq ues. need to sort first . sort | uniq : Display uniques sort | uniq -c : Count uniques sort | uniq -d : Display duplicates sort | uniq -u : Show non repeated lines wc Count lines, words and chars wc -l : count only lines wc -w : count only words wc -c : count only chars/bytes (useful for getting size of stdin) column Display in column s | column -t : Pretty print TSV file column iris.csv -t -s , column file.csv -s \",\" -t | less -#2 -N -S : CSV viewer cut Selecting fields (columns) (default is to delimit by tab). cut -d',' -f1 : Delimiter=\",\" Field (col)=1st cut -d, -f 2 : Delimit by coma (CSV). Select 2nd field. cut -d, -f 2,3 : Delimit by coma (CSV). Select 2nd and 3rd fields. cut -d, -f-4,6- : Delimit by coma (CSV). Select all except 5th field. cut -c 5- : skip the first 4 characters of each line (start on the 5th char). paste Join 2 (or more) files line by line pase file_a file_b pase <(cut -d, -f1,2,3 some.csv) other_file join Join 2 files line by its sorted id column. If the the column separator is not specified, it will be the space by default If the id column position is not specified, it will be the 1st column by default. join file1 file2 Join two files on the first (default) field. join -t, file1 file2 Join two files using a comma (instead of a space) as the field separator. join -t, <(sort -t, -k 1,1 file1.csv) <(sort file2_ids.txt) : Sort ids of input files to work ok. join -1 3 -2 1 file1 file2 Join field3 of file1 with field1 of file2. join -a 1 file1 file2 Produce a line for each unpairable line for file1. cat path/to/file1 | join - path/to/file2 Join a file from stdin . split Split a file into pieces (less useful) nl Prepend line numbers tr Translate (replace) patterns. - tr '\\t' , Replace tabs with commas (TSV to CSV) - tr '[:upper:]' '[:lower:]' tr anslate from upper to lower characters - tr -d \" \" D elete some pattern - tr -s \" \" S queeze multiple occurrences (convert a consecutive repeated character into a single one) grep Print lines matching a pattern egrep San handle extended regular expressions (EREs) sed S tream ed itor for filtering, transforming and replace text (and much more). Useful for search and replace. Convinient for free-form text data. sed '' file View content of file sed 's/old_word/new_word/' file Substituting Text sed 's/old_word/new_word/i' file Substituting Text (case insensitive) awk Pattern scanning and text processing language Convinient for tabular data (table with columns) Default input field separator is the blank/space: Default output field separator is the blank/space: Default record separator is the new_line: \\n Syntax: awk FLAG_OPTIONS 'PATTERN {ACTION} PATTERN {ACTION} PATTERN {ACTION}' INPUT_FILE(S) AWK FLAG OPTIONS awk -F \"|\" '........' : Set | as the input field separator AWK VARIABLES $1 : Field 1 $2 : Field 2 $3 : Field 3 $0 : The entire line NR : Number of the current record/line AWK PATTERNS Keywords awk 'BEGIN {...}' : Do this before iterating the file Logical operators: awk '$3 > 1000 || $4 < 300 {...}' awk 'NR<3 {...}' awk toupper($3 == \"TEXAS\")' awk toupper($3 != \"TEXAS\")' Regular expresions: awk '/D6.jpg/ {...}' awk '! /D6.jpg/ {...}' awk '$4 ~ /D6.jpg/ {...}' : Field match a regex awk '$4 !~ /D6.jpg/ {...}' : Field do not match a regex awk '/(TEXAS|Texas).*[Oo]il.*extraction/ {...}' : Complex regex Regular expresions with logical operators: awk '( /TEXAS/ || /Texas/ ) && /*[Oo]il.*extraction/ {...}' AWK ACTIONS awk '{print $0}' : Print the entire line. awk '{print $1}' : Print fisrt column. awk '{print \"First column \" $1 \" second column \" $2}' awk 'BEGIN {FS=\"\\t\";OFS=\"\\t\"} ... : Set the tab as the input and output separators awk 'BEGIN {FS=OFS=\"\\t\"} ... : Same of above AWK REFERENCE https://stackoverflow.com/tags/awk/info https://ferd.ca/awk-in-20-minutes.html https://www.youtube.com/watch?v=WaNIi0ZJMu0 Q SQL over CSVs","title":"\ud83d\udfe2 Excel,csv,tsv (cut,paste,awk)"},{"location":"cli_tools_data/csv/#text-data","text":"","title":"Text data"},{"location":"cli_tools_data/csv/#sortsorting","text":"","title":"sortSorting"},{"location":"cli_tools_data/csv/#soring-options-bdfgimhnrrv","text":"sort -r : Reverse order sort -n : Numerically sort -rn : Numerically reversed sort -R : Randomly (each time is different). Similar to shuf","title":"Soring options [bdfgiMhnRrV]:"},{"location":"cli_tools_data/csv/#sorting-by-fields","text":"sort -t ',' -k 2 file.csv : Sort a CSV file by 2nd column (until the end of line). sort -t ',' -k 2,2 file.csv : Sort a CSV file by 2nd column. sort -t ',' -k 2n,2 file.csv : Sort NUMERICALLY a CSV file by 2nd column. sort -t, -k 3n,3 -k 1n,1 file.csv : Sort NUMERICALLY a CSV file by 3rd column, then by 1st column","title":"Sorting by fields:"},{"location":"cli_tools_data/csv/#uniq","text":"See uniq ues. need to sort first . sort | uniq : Display uniques sort | uniq -c : Count uniques sort | uniq -d : Display duplicates sort | uniq -u : Show non repeated lines","title":"uniq"},{"location":"cli_tools_data/csv/#wc","text":"Count lines, words and chars wc -l : count only lines wc -w : count only words wc -c : count only chars/bytes (useful for getting size of stdin)","title":"wc"},{"location":"cli_tools_data/csv/#column","text":"Display in column s | column -t : Pretty print TSV file column iris.csv -t -s , column file.csv -s \",\" -t | less -#2 -N -S : CSV viewer","title":"column"},{"location":"cli_tools_data/csv/#cut","text":"Selecting fields (columns) (default is to delimit by tab). cut -d',' -f1 : Delimiter=\",\" Field (col)=1st cut -d, -f 2 : Delimit by coma (CSV). Select 2nd field. cut -d, -f 2,3 : Delimit by coma (CSV). Select 2nd and 3rd fields. cut -d, -f-4,6- : Delimit by coma (CSV). Select all except 5th field. cut -c 5- : skip the first 4 characters of each line (start on the 5th char).","title":"cut"},{"location":"cli_tools_data/csv/#paste","text":"Join 2 (or more) files line by line pase file_a file_b pase <(cut -d, -f1,2,3 some.csv) other_file","title":"paste"},{"location":"cli_tools_data/csv/#join","text":"Join 2 files line by its sorted id column. If the the column separator is not specified, it will be the space by default If the id column position is not specified, it will be the 1st column by default. join file1 file2 Join two files on the first (default) field. join -t, file1 file2 Join two files using a comma (instead of a space) as the field separator. join -t, <(sort -t, -k 1,1 file1.csv) <(sort file2_ids.txt) : Sort ids of input files to work ok. join -1 3 -2 1 file1 file2 Join field3 of file1 with field1 of file2. join -a 1 file1 file2 Produce a line for each unpairable line for file1. cat path/to/file1 | join - path/to/file2 Join a file from stdin .","title":"join"},{"location":"cli_tools_data/csv/#split","text":"Split a file into pieces (less useful)","title":"split"},{"location":"cli_tools_data/csv/#nl","text":"Prepend line numbers","title":"nl"},{"location":"cli_tools_data/csv/#tr","text":"Translate (replace) patterns. - tr '\\t' , Replace tabs with commas (TSV to CSV) - tr '[:upper:]' '[:lower:]' tr anslate from upper to lower characters - tr -d \" \" D elete some pattern - tr -s \" \" S queeze multiple occurrences (convert a consecutive repeated character into a single one)","title":"tr"},{"location":"cli_tools_data/csv/#grep","text":"Print lines matching a pattern","title":"grep"},{"location":"cli_tools_data/csv/#egrep","text":"San handle extended regular expressions (EREs)","title":"egrep"},{"location":"cli_tools_data/csv/#sed","text":"S tream ed itor for filtering, transforming and replace text (and much more). Useful for search and replace. Convinient for free-form text data. sed '' file View content of file sed 's/old_word/new_word/' file Substituting Text sed 's/old_word/new_word/i' file Substituting Text (case insensitive)","title":"sed"},{"location":"cli_tools_data/csv/#awk","text":"Pattern scanning and text processing language Convinient for tabular data (table with columns) Default input field separator is the blank/space: Default output field separator is the blank/space: Default record separator is the new_line: \\n Syntax: awk FLAG_OPTIONS 'PATTERN {ACTION} PATTERN {ACTION} PATTERN {ACTION}' INPUT_FILE(S)","title":"awk"},{"location":"cli_tools_data/csv/#awk-flag-options","text":"awk -F \"|\" '........' : Set | as the input field separator","title":"AWK FLAG OPTIONS"},{"location":"cli_tools_data/csv/#awk-variables","text":"$1 : Field 1 $2 : Field 2 $3 : Field 3 $0 : The entire line NR : Number of the current record/line","title":"AWK VARIABLES"},{"location":"cli_tools_data/csv/#awk-patterns","text":"Keywords awk 'BEGIN {...}' : Do this before iterating the file Logical operators: awk '$3 > 1000 || $4 < 300 {...}' awk 'NR<3 {...}' awk toupper($3 == \"TEXAS\")' awk toupper($3 != \"TEXAS\")' Regular expresions: awk '/D6.jpg/ {...}' awk '! /D6.jpg/ {...}' awk '$4 ~ /D6.jpg/ {...}' : Field match a regex awk '$4 !~ /D6.jpg/ {...}' : Field do not match a regex awk '/(TEXAS|Texas).*[Oo]il.*extraction/ {...}' : Complex regex Regular expresions with logical operators: awk '( /TEXAS/ || /Texas/ ) && /*[Oo]il.*extraction/ {...}'","title":"AWK PATTERNS"},{"location":"cli_tools_data/csv/#awk-actions","text":"awk '{print $0}' : Print the entire line. awk '{print $1}' : Print fisrt column. awk '{print \"First column \" $1 \" second column \" $2}' awk 'BEGIN {FS=\"\\t\";OFS=\"\\t\"} ... : Set the tab as the input and output separators awk 'BEGIN {FS=OFS=\"\\t\"} ... : Same of above","title":"AWK ACTIONS"},{"location":"cli_tools_data/csv/#awk-reference","text":"https://stackoverflow.com/tags/awk/info https://ferd.ca/awk-in-20-minutes.html https://www.youtube.com/watch?v=WaNIi0ZJMu0","title":"AWK REFERENCE"},{"location":"cli_tools_data/csv/#q","text":"SQL over CSVs","title":"Q"},{"location":"cli_tools_data/free_text/","text":"Regular Expressions Basic REs grep sed Extended REs grep -E , egrep sed -E , awk Pearl/Python REs grep -P Python's re CHARACTERS Any char (except newline) . . . a,b,c characters [abc] [abc] [abc] Any chars except a,b,c [^abc] [^abc] [^abc] Any digit [0-9] [0-9] [0-9] \\d Any chars except digits [^0-9] [^0-9] [^0-9] \\D Any letter [a-zA-Z] [a-zA-Z] [a-zA-Z] Any letter even with \u00b4\u00a8~ [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] Any letter, digit or \"_\" \\w \\w \\w Not letter, digit or \"_\" \\W Whitespace char \\s \\s Whitespace char & newline \\s QUANTIFIERS 0 or More * * * 1 or More \\+ + + 0 or 1 \\? ? ? Exact Number \\{3\\} {3} {3} Range min max \\{3,4\\} {3,4} {3,4} 2 or More \\{2,}\\ {2,} {2,} 3 or Less \\{,3}\\ {,3} {,3} LIMITS Beginning of line ^ ^ ^ End of line $ $ $ Word boundary \\b \\b \\b Not word boundary \\B \\B \\B ALTERNATION a or b \\(a|b\\) (a|b) (a|b) a or b [ab] [ab] [ab] GROUPING Capturing a group \\(...\\) (...) (...) Backreference a group \\1 \\1 \\1 LOOK-AROUND Positive look-behind (?<=prefijo)mi_patron Negative look-behind (?<!prefijo)mi_patron Positive look-ahead mi_patron(?=sufijo) Positive look-ahead mi_patron(?!sufijo) Pseudo look-around in sed # Remove something behind sed 's/pattern2remove\\(pattern2keep\\)/\\1/g' file.txt sed -E 's/pattern2remove(pattern2keep)/\\1/g' file.txt # Remove something ahead sed 's/\\(pattern2keep\\)pattern2remove/\\1/g' file.txt sed -E 's/(pattern2keep)pattern2remove/\\1/g' file.txt Flags /.../g : Global. Several matches per line can occur /.../i : Case insensitive Examples .+ Selececcionar cada linea \\b[A-Z]+\\b palabras solo en mayyscula (cada palabra es un match) ([A-Z]+[ \\t]+)+ frases solo en mayyscula (cada frase es un match) \\.(png|jpg|gif)$ DOS to UNIX file Remove carriage return (\\r\\r\\n) sed 's/\\r//' in.txt > out.txt --> Bad (only first \\r of line is removed) sed 's/\\r$//' in.txt > out.txt --> Bad (only last \\r of line is removed) sed 's/\\r//g' in.txt > out.txt --> Good: Remove all the \\r Remove the BOM sed '1s/^\\xEF\\xBB\\xBF//' in.txt > out.txt Conclusion cat input_file | sed '1s/^\\xEF\\xBB\\xBF//' | sed 's/\\r//g' > output_file Pseudo-regex in terminal * : Matches zero or more. {a,b,c} : Brace Expansion . Examples: ls some_dir/{subdir_A,subdir_B} mkdir {old,new,dist,bugs} Pattern Matching ?(pattern-list) : Matches zero or one occurrence of the given patterns. *(pattern-list) : Matches zero or more occurrences of the given patterns. +(pattern-list) : Matches one or more occurrences of the given patterns. @(pattern-list) : Matches one of the given patterns. !(pattern-list) : Matches anything except one of the given patterns. ASCII 0-31 32-63 64-95 96-127 128-159 160-191 192-223 224.255 0 \\0 32 64 @ 96 128 \u0080 160 192 \u00c0 224 \u00e0 1 SOH 33 ! 65 A 97 a 129 \u0081 161 \u00a1 193 \u00c1 225 \u00e1 2 STX 34 \" 66 B 98 b 130 \u0082 162 \u00a2 194 \u00c2 226 \u00e2 3 ETX 35 # 67 C 99 c 131 \u0083 163 \u00a3 195 \u00c3 227 \u00e3 4 EOT 36 $ 68 D 100 d 132 \u0084 164 \u00a4 196 \u00c4 228 \u00e4 5 ENQ 37 % 69 E 101 e 133 165 \u00a5 197 \u00c5 229 \u00e5 6 ACK 38 & 70 F 102 f 134 \u0086 166 \u00a6 198 \u00c6 230 \u00e6 7 BEL 39 ' 71 G 103 g 135 \u0087 167 \u00a7 199 \u00c7 231 \u00e7 8 BS 40 ( 72 H 104 h 136 \u0088 168 \u00a8 200 \u00c8 232 \u00e8 9 \\t 41 ) 73 I 105 i 137 \u0089 169 \u00a9 201 \u00c9 233 \u00e9 10 \\n 42 * 74 J 106 j 138 \u008a 170 \u00aa 202 \u00ca 234 \u00ea 11 \\v 43 + 75 K 107 k 139 \u008b 171 \u00ab 203 \u00cb 235 \u00eb 12 FF 44 , 76 L 108 l 140 \u008c 172 \u00ac 204 \u00cc 236 \u00ec 13 \\r 45 - 77 M 109 m 141 \u008d 173 \u00a1 205 \u00cd 237 \u00ed 14 SO 46 . 78 N 110 n 142 \u008e 174 \u00ae 206 \u00ce 238 \u00ee 15 SI 47 / 79 O 111 o 143 \u008f 175 \u00af 207 \u00cf 239 \u00ef 16 DLE 48 0 80 P 112 p 144 \u0090 176 \u00b0 208 \u00d0 240 \u00f0 17 DC1 49 1 81 Q 113 q 145 \u0091 177 \u00b1 209 \u00d1 241 \u00f1 18 DC2 50 2 82 R 114 r 146 \u0092 178 \u00b2 210 \u00d2 242 \u00f2 19 DC3 51 3 83 S 115 s 147 \u0093 179 \u00b3 211 \u00d3 243 \u00f3 20 DC4 52 4 84 T 116 t 148 \u0094 180 \u00b4 212 \u00d4 244 \u00f4 21 NAK 53 5 85 U 117 u 149 \u0095 181 \u00b5 213 \u00d5 245 \u00f5 22 SYN 54 6 86 V 118 v 150 \u0096 182 \u00b6 214 \u00d6 246 \u00f6 23 ETB 55 7 87 W 119 w 151 \u0097 183 \u00b7 215 \u00d7 247 \u00f7 24 CAN 56 8 88 X 120 x 152 \u0098 184 \u00b8 216 \u00d8 248 \u00f8 25 EM 57 9 89 Y 121 y 153 \u0099 185 \u00b9 217 \u00d9 249 \u00f9 26 SUB 58 : 90 Z 122 z 154 \u009a 186 \u00ba 218 \u00da 250 \u00fa 27 ESC 59 ; 91 [ 123 { 155 \u009b 187 \u00bb 219 \u00db 251 \u00fb 28 FS 60 < 92 \\ 124 \\| 156 \u009c 188 \u00bc 220 \u00dc 252 \u00fc 29 GS 61 = 93 ] 125 } 157 \u009d 189 \u00bd 221 \u00dd 253 \u00fd 30 RS 62 > 94 ^ 126 ~ 158 \u009e 190 \u00be 222 \u00de 254 \u00fe 31 US 63 ? 95 _ 127 DEL 159 \u009f 191 \u00bf 223 \u00df 255 \u00ff Reference https://regexr.com/ https://regex101.com/ man re_format Char ranges https://www.youtube.com/playlist?list=PLp31D6HATKfdc5PSJTx7rIvlTLCSM5nDi https://www.youtube.com/watch?v=w61mxJcUV-o https://remram44.github.io/regex-cheatsheet/regex.html https://linuxize.com/post/regular-expressions-in-grep http://mywiki.wooledge.org/RegularExpression grep : print lines matching a pattern egrep : can handle extended regular expressions (EREs)","title":"\u26aa\ufe0f Free text (regex,grep,tr,sed)"},{"location":"cli_tools_data/free_text/#regular-expressions","text":"Basic REs grep sed Extended REs grep -E , egrep sed -E , awk Pearl/Python REs grep -P Python's re CHARACTERS Any char (except newline) . . . a,b,c characters [abc] [abc] [abc] Any chars except a,b,c [^abc] [^abc] [^abc] Any digit [0-9] [0-9] [0-9] \\d Any chars except digits [^0-9] [^0-9] [^0-9] \\D Any letter [a-zA-Z] [a-zA-Z] [a-zA-Z] Any letter even with \u00b4\u00a8~ [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] [a-zA-Z\u00e0-\u00fcA-Z\u00c0-\u00dc] Any letter, digit or \"_\" \\w \\w \\w Not letter, digit or \"_\" \\W Whitespace char \\s \\s Whitespace char & newline \\s QUANTIFIERS 0 or More * * * 1 or More \\+ + + 0 or 1 \\? ? ? Exact Number \\{3\\} {3} {3} Range min max \\{3,4\\} {3,4} {3,4} 2 or More \\{2,}\\ {2,} {2,} 3 or Less \\{,3}\\ {,3} {,3} LIMITS Beginning of line ^ ^ ^ End of line $ $ $ Word boundary \\b \\b \\b Not word boundary \\B \\B \\B ALTERNATION a or b \\(a|b\\) (a|b) (a|b) a or b [ab] [ab] [ab] GROUPING Capturing a group \\(...\\) (...) (...) Backreference a group \\1 \\1 \\1 LOOK-AROUND Positive look-behind (?<=prefijo)mi_patron Negative look-behind (?<!prefijo)mi_patron Positive look-ahead mi_patron(?=sufijo) Positive look-ahead mi_patron(?!sufijo)","title":"Regular Expressions"},{"location":"cli_tools_data/free_text/#pseudo-look-around-in-sed","text":"# Remove something behind sed 's/pattern2remove\\(pattern2keep\\)/\\1/g' file.txt sed -E 's/pattern2remove(pattern2keep)/\\1/g' file.txt # Remove something ahead sed 's/\\(pattern2keep\\)pattern2remove/\\1/g' file.txt sed -E 's/(pattern2keep)pattern2remove/\\1/g' file.txt","title":"Pseudo look-around in sed"},{"location":"cli_tools_data/free_text/#flags","text":"/.../g : Global. Several matches per line can occur /.../i : Case insensitive","title":"Flags"},{"location":"cli_tools_data/free_text/#examples","text":".+ Selececcionar cada linea \\b[A-Z]+\\b palabras solo en mayyscula (cada palabra es un match) ([A-Z]+[ \\t]+)+ frases solo en mayyscula (cada frase es un match) \\.(png|jpg|gif)$","title":"Examples"},{"location":"cli_tools_data/free_text/#dos-to-unix-file","text":"","title":"DOS to UNIX file"},{"location":"cli_tools_data/free_text/#remove-carriage-return-rrn","text":"sed 's/\\r//' in.txt > out.txt --> Bad (only first \\r of line is removed) sed 's/\\r$//' in.txt > out.txt --> Bad (only last \\r of line is removed) sed 's/\\r//g' in.txt > out.txt --> Good: Remove all the \\r","title":"Remove carriage return (\\r\\r\\n)"},{"location":"cli_tools_data/free_text/#remove-the-bom","text":"sed '1s/^\\xEF\\xBB\\xBF//' in.txt > out.txt","title":"Remove the BOM"},{"location":"cli_tools_data/free_text/#conclusion","text":"cat input_file | sed '1s/^\\xEF\\xBB\\xBF//' | sed 's/\\r//g' > output_file","title":"Conclusion"},{"location":"cli_tools_data/free_text/#pseudo-regex-in-terminal","text":"* : Matches zero or more. {a,b,c} : Brace Expansion . Examples: ls some_dir/{subdir_A,subdir_B} mkdir {old,new,dist,bugs} Pattern Matching ?(pattern-list) : Matches zero or one occurrence of the given patterns. *(pattern-list) : Matches zero or more occurrences of the given patterns. +(pattern-list) : Matches one or more occurrences of the given patterns. @(pattern-list) : Matches one of the given patterns. !(pattern-list) : Matches anything except one of the given patterns.","title":"Pseudo-regex in terminal"},{"location":"cli_tools_data/free_text/#ascii","text":"0-31 32-63 64-95 96-127 128-159 160-191 192-223 224.255 0 \\0 32 64 @ 96 128 \u0080 160 192 \u00c0 224 \u00e0 1 SOH 33 ! 65 A 97 a 129 \u0081 161 \u00a1 193 \u00c1 225 \u00e1 2 STX 34 \" 66 B 98 b 130 \u0082 162 \u00a2 194 \u00c2 226 \u00e2 3 ETX 35 # 67 C 99 c 131 \u0083 163 \u00a3 195 \u00c3 227 \u00e3 4 EOT 36 $ 68 D 100 d 132 \u0084 164 \u00a4 196 \u00c4 228 \u00e4 5 ENQ 37 % 69 E 101 e 133 165 \u00a5 197 \u00c5 229 \u00e5 6 ACK 38 & 70 F 102 f 134 \u0086 166 \u00a6 198 \u00c6 230 \u00e6 7 BEL 39 ' 71 G 103 g 135 \u0087 167 \u00a7 199 \u00c7 231 \u00e7 8 BS 40 ( 72 H 104 h 136 \u0088 168 \u00a8 200 \u00c8 232 \u00e8 9 \\t 41 ) 73 I 105 i 137 \u0089 169 \u00a9 201 \u00c9 233 \u00e9 10 \\n 42 * 74 J 106 j 138 \u008a 170 \u00aa 202 \u00ca 234 \u00ea 11 \\v 43 + 75 K 107 k 139 \u008b 171 \u00ab 203 \u00cb 235 \u00eb 12 FF 44 , 76 L 108 l 140 \u008c 172 \u00ac 204 \u00cc 236 \u00ec 13 \\r 45 - 77 M 109 m 141 \u008d 173 \u00a1 205 \u00cd 237 \u00ed 14 SO 46 . 78 N 110 n 142 \u008e 174 \u00ae 206 \u00ce 238 \u00ee 15 SI 47 / 79 O 111 o 143 \u008f 175 \u00af 207 \u00cf 239 \u00ef 16 DLE 48 0 80 P 112 p 144 \u0090 176 \u00b0 208 \u00d0 240 \u00f0 17 DC1 49 1 81 Q 113 q 145 \u0091 177 \u00b1 209 \u00d1 241 \u00f1 18 DC2 50 2 82 R 114 r 146 \u0092 178 \u00b2 210 \u00d2 242 \u00f2 19 DC3 51 3 83 S 115 s 147 \u0093 179 \u00b3 211 \u00d3 243 \u00f3 20 DC4 52 4 84 T 116 t 148 \u0094 180 \u00b4 212 \u00d4 244 \u00f4 21 NAK 53 5 85 U 117 u 149 \u0095 181 \u00b5 213 \u00d5 245 \u00f5 22 SYN 54 6 86 V 118 v 150 \u0096 182 \u00b6 214 \u00d6 246 \u00f6 23 ETB 55 7 87 W 119 w 151 \u0097 183 \u00b7 215 \u00d7 247 \u00f7 24 CAN 56 8 88 X 120 x 152 \u0098 184 \u00b8 216 \u00d8 248 \u00f8 25 EM 57 9 89 Y 121 y 153 \u0099 185 \u00b9 217 \u00d9 249 \u00f9 26 SUB 58 : 90 Z 122 z 154 \u009a 186 \u00ba 218 \u00da 250 \u00fa 27 ESC 59 ; 91 [ 123 { 155 \u009b 187 \u00bb 219 \u00db 251 \u00fb 28 FS 60 < 92 \\ 124 \\| 156 \u009c 188 \u00bc 220 \u00dc 252 \u00fc 29 GS 61 = 93 ] 125 } 157 \u009d 189 \u00bd 221 \u00dd 253 \u00fd 30 RS 62 > 94 ^ 126 ~ 158 \u009e 190 \u00be 222 \u00de 254 \u00fe 31 US 63 ? 95 _ 127 DEL 159 \u009f 191 \u00bf 223 \u00df 255 \u00ff","title":"ASCII"},{"location":"cli_tools_data/free_text/#reference","text":"https://regexr.com/ https://regex101.com/ man re_format Char ranges https://www.youtube.com/playlist?list=PLp31D6HATKfdc5PSJTx7rIvlTLCSM5nDi https://www.youtube.com/watch?v=w61mxJcUV-o https://remram44.github.io/regex-cheatsheet/regex.html https://linuxize.com/post/regular-expressions-in-grep http://mywiki.wooledge.org/RegularExpression grep : print lines matching a pattern egrep : can handle extended regular expressions (EREs)","title":"Reference"},{"location":"cli_tools_data/html/","text":"Parsing HTML: pup Filter by tag : cat robots.html | pup 'title' Filter by tag with id : cat robots.html | pup 'span#See_also' Filter by tag with class : cat robots.html | pup 'table.someClass' Filter by tag with attribute : cat robots.html | pup 'th[scope=\"row\"]'","title":"\ud83d\udfe1 HTML (pup) XML"},{"location":"cli_tools_data/html/#parsing-html-pup","text":"Filter by tag : cat robots.html | pup 'title' Filter by tag with id : cat robots.html | pup 'span#See_also' Filter by tag with class : cat robots.html | pup 'table.someClass' Filter by tag with attribute : cat robots.html | pup 'th[scope=\"row\"]'","title":"Parsing HTML: pup"},{"location":"cli_tools_data/image/","text":"Image Resize options Filter Downscaling quality Upscaling quality Performance Pillow: NEAREST \u2b50\u2b50\u2b50\u2b50\u2b50 Pillow: BOX \u2b50 \u2b50\u2b50\u2b50\u2b50 Pillow: BILINEAR \u2b50 \u2b50 \u2b50\u2b50\u2b50 Pillow: HAMMING \u2b50\u2b50 \u2b50\u2b50\u2b50 Pillow: BICUBIC \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50 Pillow: LANCZOS \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 \u2b50 Refencece Display images in terminal (iTerm2) iTerm2 has a protocol to display images: ESC ] 1337 ; key = value ^G printf \"\\033]1337;File=\" In practice, iTerm2 has the imgcat command to display images. imgcat path/to/image cat path/to/image | imgcat Another option is using the kitty terminal with the icat command. Display images inside a python script (source link1 , link2 ): # if you have iterm2 for osx (www.iterm2.com) this is a like print(...) for images in the console import base64 import io import numpngw import numpy as np def show_image(img): if img.dtype != np.uint8: print(\"ERROR: Should be an uint8 numpy array\") png_array = io.BytesIO() numpngw.write_png(png_array, img) encoded_png_array = base64.b64encode(png_array.getvalue()).decode(\"utf-8\", \"strict\") png_array.close() image_seq = '\\033]1337;File=[width=auto;height=auto;inline=1]:'+encoded_png_array+'\\007' print(image_seq, end='') LibJPEG-Turbo Decode JPEG (very fast): djpeg filename.jpg ImageMagick Command Description convert convert and modify images identify Output information about this image mogrify in-place batch processing composite overlaying images in special ways montage generate grid of images display Slideshows of Images animate Show GIF Animations compare Look for Differences stream Pipelined Image Processor import Read Images from On-screen Display conjure Experimental IM Scripting Language ImageMagick convert Synopsis: convert [input-options] input-file [output-options] output-file # Specify 'file' as '-' for standard input or output. Conversion between formats convert imagen.jpg imagen.png : Convertir una imagen de png a jpg convert imagen.{png,jpg} : Same of before using Expansion. Resizing convert -resize convert IN_IMG -resize 64x64 OUT_IMG Resize image (set larger to 64px) convert IN_IMG -resize 64x64\\! OUT_IMG Resize image (Ignore Aspect Ratio) Cropping convert -crop convert IN_IMG -crop 703x470+3+5 OUT_IMG Crop image with width x height + left + top format Generate grid of images: montage # Sytntax: montage INPUT_IMGS [OPTIONS] OUTPUT_IMG # Examples: montage imgs/* grid.png # Generate and save grid montage imgs/* - | imgcat # Generate grid to stdout and display it with imgcat montage imgs/* -geometry 100x100\\>+2+2 - | imgcat # Define size (100x100pxs) & margin (2px) of images","title":"\ud83d\udd35 Image (ImageMagick)"},{"location":"cli_tools_data/image/#image","text":"","title":"Image"},{"location":"cli_tools_data/image/#resize-options","text":"Filter Downscaling quality Upscaling quality Performance Pillow: NEAREST \u2b50\u2b50\u2b50\u2b50\u2b50 Pillow: BOX \u2b50 \u2b50\u2b50\u2b50\u2b50 Pillow: BILINEAR \u2b50 \u2b50 \u2b50\u2b50\u2b50 Pillow: HAMMING \u2b50\u2b50 \u2b50\u2b50\u2b50 Pillow: BICUBIC \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50 Pillow: LANCZOS \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 \u2b50 Refencece","title":"Resize options"},{"location":"cli_tools_data/image/#display-images-in-terminal-iterm2","text":"iTerm2 has a protocol to display images: ESC ] 1337 ; key = value ^G printf \"\\033]1337;File=\" In practice, iTerm2 has the imgcat command to display images. imgcat path/to/image cat path/to/image | imgcat Another option is using the kitty terminal with the icat command. Display images inside a python script (source link1 , link2 ): # if you have iterm2 for osx (www.iterm2.com) this is a like print(...) for images in the console import base64 import io import numpngw import numpy as np def show_image(img): if img.dtype != np.uint8: print(\"ERROR: Should be an uint8 numpy array\") png_array = io.BytesIO() numpngw.write_png(png_array, img) encoded_png_array = base64.b64encode(png_array.getvalue()).decode(\"utf-8\", \"strict\") png_array.close() image_seq = '\\033]1337;File=[width=auto;height=auto;inline=1]:'+encoded_png_array+'\\007' print(image_seq, end='')","title":"Display images in terminal (iTerm2)"},{"location":"cli_tools_data/image/#libjpeg-turbo","text":"Decode JPEG (very fast): djpeg filename.jpg","title":"LibJPEG-Turbo"},{"location":"cli_tools_data/image/#imagemagick","text":"Command Description convert convert and modify images identify Output information about this image mogrify in-place batch processing composite overlaying images in special ways montage generate grid of images display Slideshows of Images animate Show GIF Animations compare Look for Differences stream Pipelined Image Processor import Read Images from On-screen Display conjure Experimental IM Scripting Language","title":"ImageMagick"},{"location":"cli_tools_data/image/#imagemagick-convert","text":"Synopsis: convert [input-options] input-file [output-options] output-file # Specify 'file' as '-' for standard input or output.","title":"ImageMagick convert"},{"location":"cli_tools_data/image/#conversion-between-formats","text":"convert imagen.jpg imagen.png : Convertir una imagen de png a jpg convert imagen.{png,jpg} : Same of before using Expansion.","title":"Conversion between formats"},{"location":"cli_tools_data/image/#resizing-convert-resize","text":"convert IN_IMG -resize 64x64 OUT_IMG Resize image (set larger to 64px) convert IN_IMG -resize 64x64\\! OUT_IMG Resize image (Ignore Aspect Ratio)","title":"Resizing convert -resize"},{"location":"cli_tools_data/image/#cropping-convert-crop","text":"convert IN_IMG -crop 703x470+3+5 OUT_IMG Crop image with width x height + left + top format","title":"Cropping convert -crop"},{"location":"cli_tools_data/image/#generate-grid-of-images-montage","text":"# Sytntax: montage INPUT_IMGS [OPTIONS] OUTPUT_IMG # Examples: montage imgs/* grid.png # Generate and save grid montage imgs/* - | imgcat # Generate grid to stdout and display it with imgcat montage imgs/* -geometry 100x100\\>+2+2 - | imgcat # Define size (100x100pxs) & margin (2px) of images","title":"Generate grid of images: montage"},{"location":"cli_tools_data/json/","text":"Parsing JSON: jq HTML table to csv : cat wiki.html | pup \"table.wikitable tbody tr json{}\" | jq '.[] | .children | \"\\(.[0].text),\\(.[1].text),\\(.[2].text)\"' -r table.json jq -r '.tbody.tr[1:][] | [.td[][\"$t\"]] | @csv' https://programminghistorian.org/en/lessons/json-and-jq https://www.datascienceatthecommandline.com/2e/chapter-5-scrubbing-data.html CSV to JSON jq --slurp --raw-input --raw-output ' split(\"\\n\") | ( .[0] | split(\",\") ) as $header | ( .[1:] | map(split(\",\")) ) as $body | $body | map( [$header, .] | transpose | map( {(.[0]): .[1]} ) | add)' sample_upload.csv","title":"\ud83d\udfe0 JSON (jq)"},{"location":"cli_tools_data/json/#parsing-json-jq","text":"HTML table to csv : cat wiki.html | pup \"table.wikitable tbody tr json{}\" | jq '.[] | .children | \"\\(.[0].text),\\(.[1].text),\\(.[2].text)\"' -r table.json jq -r '.tbody.tr[1:][] | [.td[][\"$t\"]] | @csv' https://programminghistorian.org/en/lessons/json-and-jq https://www.datascienceatthecommandline.com/2e/chapter-5-scrubbing-data.html","title":"Parsing JSON: jq"},{"location":"cli_tools_data/json/#csv-to-json","text":"jq --slurp --raw-input --raw-output ' split(\"\\n\") | ( .[0] | split(\",\") ) as $header | ( .[1:] | map(split(\",\")) ) as $body | $body | map( [$header, .] | transpose | map( {(.[0]): .[1]} ) | add)' sample_upload.csv","title":"CSV to JSON"},{"location":"cli_tools_data/pdf/","text":"Parsing PDF: Xpdf or poppler Xpdf : Viewer for Portable Document Format (PDF) files xpdf : PDF viewer (click for a screenshot) pdftotext : converts PDF to text pdftops : converts PDF to PostScript pdftoppm : converts PDF pages to netpbm (PPM/PGM/PBM) image files pdftopng : converts PDF pages to PNG image files pdftohtml : converts PDF to HTML pdfinfo : extracts PDF metadata pdfimages : extracts raw images from PDF files pdffonts : lists fonts used in PDF files pdfdetach : extracts attached files from PDF files Poppler : PDF rendering library based on xpdf pdfattach pdfdetach pdffonts pdfimages pdfinfo pdfseparate pdfsig pdftocairo pdftohtml pdftoppm pdftops pdftotext : Portable Document Format (PDF) to text converter pdftotext [options] someFile.pdf pdfunite MuPDF textutil : Only in MacOS (Usado por Pascual Perez) textutil -convert txt ~/Desktop/DrectorioDeArchivosEnPDF/*.pdf Xpdf Poppler MuPDF Installation sudo pacman -S xpdf sudo pacman -S poppler sudo pacman -S mupdf-tools PDF to text pdftotext -layout in.pdf out.txt mutool convert -o out.txt in.pdf for file in *.pdf; do pdftotext -layout \"$file\"; done for file in *.pdf; do mutool convert -o $file.txt $file; done Parse with OCR!: ocrmypdf Documents pandoc : Conversion between markup formats aspell : A spell checker designed to eventually replace Ispell https://programminghistorian.org/en/lessons/working-with-batches-of-pdf-files","title":"\ud83d\udd34 PDF (Xpdf,poppler)"},{"location":"cli_tools_data/pdf/#parsing-pdf-xpdf-or-poppler","text":"Xpdf : Viewer for Portable Document Format (PDF) files xpdf : PDF viewer (click for a screenshot) pdftotext : converts PDF to text pdftops : converts PDF to PostScript pdftoppm : converts PDF pages to netpbm (PPM/PGM/PBM) image files pdftopng : converts PDF pages to PNG image files pdftohtml : converts PDF to HTML pdfinfo : extracts PDF metadata pdfimages : extracts raw images from PDF files pdffonts : lists fonts used in PDF files pdfdetach : extracts attached files from PDF files Poppler : PDF rendering library based on xpdf pdfattach pdfdetach pdffonts pdfimages pdfinfo pdfseparate pdfsig pdftocairo pdftohtml pdftoppm pdftops pdftotext : Portable Document Format (PDF) to text converter pdftotext [options] someFile.pdf pdfunite MuPDF textutil : Only in MacOS (Usado por Pascual Perez) textutil -convert txt ~/Desktop/DrectorioDeArchivosEnPDF/*.pdf Xpdf Poppler MuPDF Installation sudo pacman -S xpdf sudo pacman -S poppler sudo pacman -S mupdf-tools PDF to text pdftotext -layout in.pdf out.txt mutool convert -o out.txt in.pdf for file in *.pdf; do pdftotext -layout \"$file\"; done for file in *.pdf; do mutool convert -o $file.txt $file; done","title":"Parsing PDF: Xpdf or poppler"},{"location":"cli_tools_data/pdf/#parse-with-ocr-ocrmypdf","text":"","title":"Parse with OCR!: ocrmypdf"},{"location":"cli_tools_data/pdf/#documents","text":"pandoc : Conversion between markup formats aspell : A spell checker designed to eventually replace Ispell https://programminghistorian.org/en/lessons/working-with-batches-of-pdf-files","title":"Documents"},{"location":"cli_tools_data/sound_video/","text":"Sound ffmepg Video and audio ffmpeg -i input.mp4 output.avi Convert audio format [FFmpeg: The Ultimate Guide](https://img.ly/blog/ultimate-guide-to-ffmpeg sox so und e x change, the Swiss Army knife of audio manipulation. play -n synth sin 1270 0.2 sin 1300 sin 1337 0.2 remix 1-3 repeat 0 vol 0.8 chorus 0.5 0.9 42 0.5 5 0.8 -t bandpass -c 1300 0.5q # You can use sox to try to replicate the sound of the BroodX Cicadas using a mix of 3 tones around 1300 Hz. Python OpenCV import cv2 cap = cv2.VideoCapture(0) while(True): ret, frame = cap.read() # Capture frame-by-frame. frame es nu nparray de 3 dims # Our operations on the frame come here... # Display the resulting frame cv2.imshow('frame',frame) if cv2.waitKey(1) & 0xFF == ord('q'): cv2.destroyAllWindows() break cap.release() # When everything done, release the capture (apagar la camara) cv2.destroyAllWindows()","title":"\ud83d\udfe3 Sound,Video (ffmepg,sox)"},{"location":"cli_tools_data/sound_video/#sound","text":"","title":"Sound"},{"location":"cli_tools_data/sound_video/#ffmepg","text":"Video and audio ffmpeg -i input.mp4 output.avi Convert audio format [FFmpeg: The Ultimate Guide](https://img.ly/blog/ultimate-guide-to-ffmpeg","title":"ffmepg"},{"location":"cli_tools_data/sound_video/#sox","text":"so und e x change, the Swiss Army knife of audio manipulation. play -n synth sin 1270 0.2 sin 1300 sin 1337 0.2 remix 1-3 repeat 0 vol 0.8 chorus 0.5 0.9 42 0.5 5 0.8 -t bandpass -c 1300 0.5q # You can use sox to try to replicate the sound of the BroodX Cicadas using a mix of 3 tones around 1300 Hz.","title":"sox"},{"location":"cli_tools_data/sound_video/#python-opencv","text":"import cv2 cap = cv2.VideoCapture(0) while(True): ret, frame = cap.read() # Capture frame-by-frame. frame es nu nparray de 3 dims # Our operations on the frame come here... # Display the resulting frame cv2.imshow('frame',frame) if cv2.waitKey(1) & 0xFF == ord('q'): cv2.destroyAllWindows() break cap.release() # When everything done, release the capture (apagar la camara) cv2.destroyAllWindows()","title":"Python OpenCV"},{"location":"cli_tools_net/basics/","text":"Old commands ( net-tools ) New commands ( iproute2 ) ifconfig ip address, ip link arp ip neighbor route ip route netstat ss [Deprecation of net-tools (2011)](https://archlinux.org/news/deprecation-of-net-tools] https://wiki.archlinux.org/title/Network_configuration Packets ngrep: grep for your network tcdump: show me all packets on port 80! wireshark: look at those packets in a GUI tshark: wireshark at th comman line tcpflow: capture assemble TCP streams ping are these computers even connected ssh scp rsync ifconfig route ip arp mitmproxy nmap zenmap p0f openvpn wireguard nc socat telnet ftp/sftp netstat ss lsof fuser iptables nftables hping3 traceroute/mtr tcptraceroute ethtool iw/iwconfig sysctl","title":"Basics"},{"location":"cli_tools_net/basics/#packets","text":"ngrep: grep for your network tcdump: show me all packets on port 80! wireshark: look at those packets in a GUI tshark: wireshark at th comman line tcpflow: capture assemble TCP streams","title":"Packets"},{"location":"cli_tools_net/basics/#ping-are-these-computers-even-connected","text":"ssh scp rsync ifconfig route ip arp","title":"ping    are these computers even connected"},{"location":"cli_tools_net/basics/#mitmproxy","text":"nmap zenmap p0f openvpn wireguard nc socat telnet","title":"mitmproxy"},{"location":"cli_tools_net/basics/#ftpsftp","text":"netstat ss lsof fuser iptables nftables hping3 traceroute/mtr tcptraceroute ethtool iw/iwconfig sysctl","title":"ftp/sftp"},{"location":"cli_tools_net/deffensive/","text":"Cybersecurity Blackarch repos in Arch linux curl -O https://blackarch.org/strap.sh # Download script echo 8bfe5a569ba7d3b055077a4e5ceada94119cccef strap.sh | sha1sum -c # Verify the SHA1 sum chmod +x strap.sh # Set execute bit sudo ./strap.sh # Run strap.sh sudo pacman -Syu # Enable multilib Prevent attacks and uses Encryption in communication SSL TLS Basic Auth (user y password) Restrict by IP","title":"\ud83d\udee1\ufe0f Deffensive"},{"location":"cli_tools_net/deffensive/#cybersecurity","text":"","title":"Cybersecurity"},{"location":"cli_tools_net/deffensive/#blackarch-repos-in-arch-linux","text":"curl -O https://blackarch.org/strap.sh # Download script echo 8bfe5a569ba7d3b055077a4e5ceada94119cccef strap.sh | sha1sum -c # Verify the SHA1 sum chmod +x strap.sh # Set execute bit sudo ./strap.sh # Run strap.sh sudo pacman -Syu # Enable multilib Prevent attacks and uses","title":"Blackarch repos in Arch linux"},{"location":"cli_tools_net/deffensive/#encryption-in-communication","text":"SSL TLS","title":"Encryption in communication"},{"location":"cli_tools_net/deffensive/#basic-auth-user-y-password","text":"","title":"Basic Auth (user y password)"},{"location":"cli_tools_net/deffensive/#restrict-by-ip","text":"","title":"Restrict by IP"},{"location":"cli_tools_net/firewall/","text":"Firewall # iptables is already installed. I like ufw. pacman -S ufw # Install ufw ufw enable # Enable it only once, when package is installed ufw status verbose # Check its status systemctl start ufw # Start the firewall systemctl enable ufw # Enable the start-up with the system [option a] systemctl enable ufw.service # Enable the start-up with the system [option b]","title":"\ud83d\udcdb Firewall"},{"location":"cli_tools_net/firewall/#firewall","text":"# iptables is already installed. I like ufw. pacman -S ufw # Install ufw ufw enable # Enable it only once, when package is installed ufw status verbose # Check its status systemctl start ufw # Start the firewall systemctl enable ufw # Enable the start-up with the system [option a] systemctl enable ufw.service # Enable the start-up with the system [option b]","title":"Firewall"},{"location":"cli_tools_net/pentesting/","text":"Pentesting Pentesting is a short for penetration testing 1 Ver la maqina con Ping -c 1 : Solo hace 1 ping para ver si la maqina esta encencida -R : Pone las ips intermedias por dnde pasa ( traceroute is usually better) Pin muestrea el TTL de la m\u00e1quina - TTL<=64 es Linux - TTL<=128 es Windows Por cada nodo intermediaro se resta 1 al TLL 2 Escanear puertos con NMAP nmap --open # Listar puertos abiertos -T5 # Es el modo mas agresivo -v # A medida que encuentre puertos me los reporte por pantalla -n # Quitar la resolucion DNS (para ganar velocidad) -p40-80 # Rango de puertos 40 a 80 https://www.cyberciti.biz/security/nmap-command-examples-tutorials/ 2.1 Escanear todos los puertos de forma r\u00e1pida 2.2 Escanar los puertos abiertos de forma exhaustiva Ataque a servidor web (puertos 22,443) Ataque fuerza bruta Programas de fuerza bruta: wfuzz feroxbuster Listas de tokens a probar: https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/directory-list-2.3-medium.txt Reference Gente S4vitar Canal de YouTube primario de S4vitar (En Espa\u00f1ol) Canal de YouTube secundario de S4vitar (En Espa\u00f1ol) M\u00e1quinas HackTheBox realizadas Twitch de S4vitar con directos todos los d\u00edas a las 21 horas (Espa\u00f1a peninsular!) S4vitar en Odysee (En Espa\u00f1ol) 0xdf Canal de YouTube Blog (principalmente soluciones de m\u00e1quinas de HackTheBox) Otros canales de Youtube en ingl\u00e9s: Canal de YouTube de CyberMentor Canal de YouTube de Ippsec Canal de YouTube de John Hammond Canal de YouTube de HackerSploit George Hotz george hotz archive geohot @ overthewire vortex part 1 geohot @ overthewire vortex part 2 geohot @ overthewire vortex part 3 geohot @ overthewire vortex part 4 geohot @ overthewire vortex level 12->13 geohot @ overthewire vortex level 12->13 Plataformas para practicar HackTheBox VulnHub OverTheWire gf0s Labs Root-Me HackThisSite PicoCTF DefendTheWeb GoogleGruyere bWapp OffensiveSecurity Crybary HackRocks Atenea HackMyVM TryHackMe warning Con cuidado! https://www.sothis.tech/capture-the-flag-aprende-hacking-jugando","title":"\ud83d\udde1\ufe0f Pentesting (nmap)"},{"location":"cli_tools_net/pentesting/#pentesting","text":"Pentesting is a short for penetration testing","title":"Pentesting"},{"location":"cli_tools_net/pentesting/#1-ver-la-maqina-con-ping","text":"-c 1 : Solo hace 1 ping para ver si la maqina esta encencida -R : Pone las ips intermedias por dnde pasa ( traceroute is usually better) Pin muestrea el TTL de la m\u00e1quina - TTL<=64 es Linux - TTL<=128 es Windows Por cada nodo intermediaro se resta 1 al TLL","title":"1 Ver la maqina con Ping"},{"location":"cli_tools_net/pentesting/#2-escanear-puertos-con-nmap","text":"nmap --open # Listar puertos abiertos -T5 # Es el modo mas agresivo -v # A medida que encuentre puertos me los reporte por pantalla -n # Quitar la resolucion DNS (para ganar velocidad) -p40-80 # Rango de puertos 40 a 80 https://www.cyberciti.biz/security/nmap-command-examples-tutorials/","title":"2 Escanear puertos con NMAP"},{"location":"cli_tools_net/pentesting/#21-escanear-todos-los-puertos-de-forma-rapida","text":"","title":"2.1 Escanear todos los puertos de forma r\u00e1pida"},{"location":"cli_tools_net/pentesting/#22-escanar-los-puertos-abiertos-de-forma-exhaustiva","text":"","title":"2.2 Escanar los puertos abiertos de forma exhaustiva"},{"location":"cli_tools_net/pentesting/#ataque-a-servidor-web-puertos-22443","text":"","title":"Ataque a servidor web (puertos 22,443)"},{"location":"cli_tools_net/pentesting/#ataque-fuerza-bruta","text":"Programas de fuerza bruta: wfuzz feroxbuster Listas de tokens a probar: https://raw.githubusercontent.com/danielmiessler/SecLists/master/Discovery/Web-Content/directory-list-2.3-medium.txt","title":"Ataque fuerza bruta"},{"location":"cli_tools_net/pentesting/#reference","text":"","title":"Reference"},{"location":"cli_tools_net/pentesting/#gente","text":"S4vitar Canal de YouTube primario de S4vitar (En Espa\u00f1ol) Canal de YouTube secundario de S4vitar (En Espa\u00f1ol) M\u00e1quinas HackTheBox realizadas Twitch de S4vitar con directos todos los d\u00edas a las 21 horas (Espa\u00f1a peninsular!) S4vitar en Odysee (En Espa\u00f1ol) 0xdf Canal de YouTube Blog (principalmente soluciones de m\u00e1quinas de HackTheBox) Otros canales de Youtube en ingl\u00e9s: Canal de YouTube de CyberMentor Canal de YouTube de Ippsec Canal de YouTube de John Hammond Canal de YouTube de HackerSploit George Hotz george hotz archive geohot @ overthewire vortex part 1 geohot @ overthewire vortex part 2 geohot @ overthewire vortex part 3 geohot @ overthewire vortex part 4 geohot @ overthewire vortex level 12->13 geohot @ overthewire vortex level 12->13","title":"Gente"},{"location":"cli_tools_net/pentesting/#plataformas-para-practicar","text":"HackTheBox VulnHub OverTheWire gf0s Labs Root-Me HackThisSite PicoCTF DefendTheWeb GoogleGruyere bWapp OffensiveSecurity Crybary HackRocks Atenea HackMyVM TryHackMe warning Con cuidado! https://www.sothis.tech/capture-the-flag-aprende-hacking-jugando","title":"Plataformas para practicar"},{"location":"cli_tools_net/server_web/","text":"HTTP server https://atareao.es/software/utilidades/httpie-un-cliente-http-para-la-linea-de-comandos/ Python HTTP server python3 -m http.server 9000 Now, create the simple index.html file inside that server directory where you have started the server. go to http://localhost:9000 Netcat HTTP server while true do echo -e \"HTTP/1.1 200 OK\\r\\n\\r\\n$(date)\" | nc -l localhost 8888 done # ncat -lk -p 8080 --exec $(server_response) # --listen --keep-open # https://www.youtube.com/watch?v=pYjoqsFjzgQ function response { echo -en \"HTTP/1.1 200 OK\\r\\n\\r\\n\" echo '<!DOCTYPE html>' echo '<html lang=\"es\">' echo ' <head>' echo ' <title>HTML</title>' echo ' <meta charset=\"utf-8\">' echo ' <meta http-equiv=\"refresh\" content=\"5\">' # Update frontend every 5 seconds echo ' </head>' echo ' <body>' echo \" $(date)\" echo ' </body>' echo '</html>' } while true; do response | nc -l localhost 8888 # here netcat waits for 1 connection, # When the user concet to http://localhost:8888 # The program flow continues echo \"================================================\" done HTTP protocol HTTP request GET / HTTP/1.1 -> request line Host: localhost:8000 \\ User-Agent: curl/7.54.0 | Request headers Accept: */* / HTTP response HTTP/1.1 200 OK Content-Type: text/html Content-Lenght: 11 Hello world INTERNET --http--> WEB SERVER --http--> APPLICATION SERVER --wsgi--> WEB FRAMEWORK ========== ================== ============= apache gunicorn Django ngixn uWSGI Flask FastAPI https://www.youtube.com/watch?v=UklcIDgHtwQ https://www.youtube.com/watch?v=WqrCnVAkLIo CGI: Common Gateway Interface (1997) WSGI: Web Server Gateway Interface (2003) caching mechanism: Reverse proxy: a system that forwards all requests from the web to our web server and back Que pasa si alguien sube una imagen (o imagenens) muy pesada? Relentiza el servidor? gunicorn bloquearia la petici\u00f3n Pero ngixn haria offloading buffering Load balancing \"failover\" or \"load balancing\", which is where two servers provide the same service but allow for distribution in the event of problems. Services like NGINX, Cloudflare, Apigee, AWS ELB, HAProxy Existen distintos criterios para balancear: Por tama\u00f1o de paquete Por numero de peticiones ...","title":"HTTP server"},{"location":"cli_tools_net/server_web/#http-server","text":"https://atareao.es/software/utilidades/httpie-un-cliente-http-para-la-linea-de-comandos/","title":"HTTP server"},{"location":"cli_tools_net/server_web/#python-http-server","text":"python3 -m http.server 9000 Now, create the simple index.html file inside that server directory where you have started the server. go to http://localhost:9000","title":"Python HTTP server"},{"location":"cli_tools_net/server_web/#netcat-http-server","text":"while true do echo -e \"HTTP/1.1 200 OK\\r\\n\\r\\n$(date)\" | nc -l localhost 8888 done # ncat -lk -p 8080 --exec $(server_response) # --listen --keep-open # https://www.youtube.com/watch?v=pYjoqsFjzgQ function response { echo -en \"HTTP/1.1 200 OK\\r\\n\\r\\n\" echo '<!DOCTYPE html>' echo '<html lang=\"es\">' echo ' <head>' echo ' <title>HTML</title>' echo ' <meta charset=\"utf-8\">' echo ' <meta http-equiv=\"refresh\" content=\"5\">' # Update frontend every 5 seconds echo ' </head>' echo ' <body>' echo \" $(date)\" echo ' </body>' echo '</html>' } while true; do response | nc -l localhost 8888 # here netcat waits for 1 connection, # When the user concet to http://localhost:8888 # The program flow continues echo \"================================================\" done","title":"Netcat HTTP server"},{"location":"cli_tools_net/server_web/#http-protocol","text":"","title":"HTTP protocol"},{"location":"cli_tools_net/server_web/#http-request","text":"GET / HTTP/1.1 -> request line Host: localhost:8000 \\ User-Agent: curl/7.54.0 | Request headers Accept: */* /","title":"HTTP request"},{"location":"cli_tools_net/server_web/#http-response","text":"HTTP/1.1 200 OK Content-Type: text/html Content-Lenght: 11 Hello world INTERNET --http--> WEB SERVER --http--> APPLICATION SERVER --wsgi--> WEB FRAMEWORK ========== ================== ============= apache gunicorn Django ngixn uWSGI Flask FastAPI https://www.youtube.com/watch?v=UklcIDgHtwQ https://www.youtube.com/watch?v=WqrCnVAkLIo CGI: Common Gateway Interface (1997) WSGI: Web Server Gateway Interface (2003) caching mechanism: Reverse proxy: a system that forwards all requests from the web to our web server and back Que pasa si alguien sube una imagen (o imagenens) muy pesada? Relentiza el servidor? gunicorn bloquearia la petici\u00f3n Pero ngixn haria offloading buffering","title":"HTTP response"},{"location":"cli_tools_net/server_web/#load-balancing","text":"\"failover\" or \"load balancing\", which is where two servers provide the same service but allow for distribution in the event of problems. Services like NGINX, Cloudflare, Apigee, AWS ELB, HAProxy Existen distintos criterios para balancear: Por tama\u00f1o de paquete Por numero de peticiones ...","title":"Load balancing"},{"location":"cli_tools_net/ssl/","text":"openssl stunnel: Make a SSL proxie for an insecure server","title":"Ssl"},{"location":"cli_tools_net/vpn/","text":"openvpn wireguard","title":"\ud83d\udd12 VPN"},{"location":"cli_tools_net/web_scraping/","text":"Web Scraping curl : make any HTTP you want httpie : like curl but easier (http get) wget : Download files aria2c : a fancier wget curl -d, --data <data> : (HTTP) Sends the specified data in a POST request to the HTTP server. -i, --include : Show HTTP response headers. -s, --silent : Silent or quiet mode. Don't show progress meter or error messages. -v, --verbose : Verbose. Show request headers (>) and response headers (<). HTTP Content-Type Curl client Flask server params in URL curl https://ip:port/endpoint?name=Javi flask.request.args.get('name') multipart/form-data curl -F name=Javi flask.request.form[\"name\"] multipart/form-data curl -F img=@myimg.jpg flask.request.files['img'] application/json curl -d \"{\\\"name\\\": \\\"Javi\\\"}\" json = flask.request.json httpie wget wget URL # Download and store in the current directory. wget -O CUSTOM_FILENAME URL # Download and store in the current directory with a different file name. wget -O - URL # Download and redirects to stdout wget --limit-rate=200k URL # Specify download speed. Here speed is limited to 200k. wget -c URL # Continue the Incomplete Download wget -b URL # Download in the Background wget --spider URL # Not download the webpage, just check that it is there. wget --tries=75 URL # Increase Total Number of Retry Attempts wget -i FILE_WITH_URLS.txt # Download multiple URLs. Each line in the txt document is a URL. -m --mirror # Turns on infinite recursion and time-stamping, and keeps FTP directory listings. -r --recursive # Turn on recursive retrieving. The default maximum depth is 5. -l depth --level=depth # Set the maximum number of subdirectories that Wget will recurse into to depth. inf means infinite -N --timestamping # Turn on time-stamping. --no-remove-listing # Don't remove the .listing files generated by FTP retrievals. -p --page-requisites # Downloads all files that are necessary to properly display a given HTML page. -k --convert-links # After the download, convert the external links to make the work. -P ./LOCAL-DIR # saves all the files and directories to the specified directory. wget --mirror --page-requisites --convert-links -P ./LOCAL_DIR URL # Download a Full Website wget -Q5m -i FILE_WITH_URLS.txt # Quit Downloading When it Exceeds Certain Size wget --ftp-user=USERNAME --ftp-password=PASSWORD URL # FTP Download With wget wget --reject=gif URL # Reject Certain File Types while Downloading wget -o download.log URL # Log messages to a log file instead of stderr Using wget -o Reference https://www.queryhome.com/tech/54364/overview-about-wget-command https://www.linuxtechi.com/wget-command-practical-examples/ https://www.youtube.com/watch?v=GJum2O2JM6M https://www.youtube.com/watch?v=-GCDJ26B4Ho Login/Session/Cookie Hide yoir IP with proxy servers BAD : you ---------> request to target GOOD : you ---------> requets to proxy server -------> request to target 1. gimmeproxy Make the following request: https://gimmeproxy.com/api/getProxy 2. They will provide JSON response with all proxy data which you can use later as needed: { \"supportsHttps\": true, \"protocol\": \"socks5\", \"ip\": \"179.162.22.82\", \"port\": \"36915\", ... } 3. Use the proxy with curl # -x [protocol://]host[:port] # --proxy [protocol://]host[:port] curl -x socks5://179.162.22.82:36915 http://example.com Web Scraping methods There are many approaches of web scrapping: Text browser ( lynx ) + parse text ( grep ) Download HTML ( cURL ) + to text ( html2text ) + parse text ( grep ) Download HTML ( cURL ) + parse HTML ( pup ) Do API reverse engineering + parse JSON ( jq ) Use Selenium or Headless browser Text browser ( lynx ) + parse text ( grep ) lynx -dump \"$the_url\" | grep \"$the_str\") Reference: https://funprojects.blog/2022/04/07/web-scraping-with-1-line-of-bash/ 1. Static webpages Get a simple static page (server side rendered) with curl or wget and parse them Example: page_html=$(curl -s $URL) title=$(echo $page_html | pup 'title' text{}) echo $title col_A=$(echo $page_html | pup 'a.bb1c_ attr{href}') col_B=$(echo $page_html | pup 'span.price-sale text{}') table=$(paste col_A col_B) https://www.youtube.com/watch?v=GJum2O2JM6M 2. API reverse engineering Useful for dynamic websites. Find the hidden api that makes XHR requests to fullfill the webpage. XMLHttpRequest is used heavily in AJAX programming. Step 1: See the requests that the web is doing: Chrome or Firefox dev tools > Network > XHR requests Step 2: Copy the target request as cURL (right click) Step 3: Paste the target request in Postman or Insomnia Step 4: Elaborate your own script using curl + jq 3. Headless browser & Selenium Use Selenium or Headless browser for automate the interaction with the web. Selenium Google Chrome cli lynx lynx -dump -listonly http://aligajani.com google-chrome-stable --headless --disable-gpu --dump-dom 'URL' > ~/file.html Refenrences https://www.youtube.com/c/JohnWatsonRooney https://www.youtube.com/channel/UCBGkweoKCtSBx6GEXRYIWLg/videos https://www.youtube.com/playlist?list=PLcUid3OP_4OU0zHx1qlCMdB6pEP1zeaY3 https://www.youtube.com/watch?v=kmlYp8I1MJs&list=PLISuMnTdVU-xOHf3jEtiK1B_g5HFgXCb-","title":"\u2b07\ufe0f Web Scraping (curl,wget)"},{"location":"cli_tools_net/web_scraping/#web-scraping","text":"curl : make any HTTP you want httpie : like curl but easier (http get) wget : Download files aria2c : a fancier wget","title":"Web Scraping"},{"location":"cli_tools_net/web_scraping/#curl","text":"-d, --data <data> : (HTTP) Sends the specified data in a POST request to the HTTP server. -i, --include : Show HTTP response headers. -s, --silent : Silent or quiet mode. Don't show progress meter or error messages. -v, --verbose : Verbose. Show request headers (>) and response headers (<). HTTP Content-Type Curl client Flask server params in URL curl https://ip:port/endpoint?name=Javi flask.request.args.get('name') multipart/form-data curl -F name=Javi flask.request.form[\"name\"] multipart/form-data curl -F img=@myimg.jpg flask.request.files['img'] application/json curl -d \"{\\\"name\\\": \\\"Javi\\\"}\" json = flask.request.json","title":"curl"},{"location":"cli_tools_net/web_scraping/#httpie","text":"","title":"httpie"},{"location":"cli_tools_net/web_scraping/#wget","text":"wget URL # Download and store in the current directory. wget -O CUSTOM_FILENAME URL # Download and store in the current directory with a different file name. wget -O - URL # Download and redirects to stdout wget --limit-rate=200k URL # Specify download speed. Here speed is limited to 200k. wget -c URL # Continue the Incomplete Download wget -b URL # Download in the Background wget --spider URL # Not download the webpage, just check that it is there. wget --tries=75 URL # Increase Total Number of Retry Attempts wget -i FILE_WITH_URLS.txt # Download multiple URLs. Each line in the txt document is a URL. -m --mirror # Turns on infinite recursion and time-stamping, and keeps FTP directory listings. -r --recursive # Turn on recursive retrieving. The default maximum depth is 5. -l depth --level=depth # Set the maximum number of subdirectories that Wget will recurse into to depth. inf means infinite -N --timestamping # Turn on time-stamping. --no-remove-listing # Don't remove the .listing files generated by FTP retrievals. -p --page-requisites # Downloads all files that are necessary to properly display a given HTML page. -k --convert-links # After the download, convert the external links to make the work. -P ./LOCAL-DIR # saves all the files and directories to the specified directory. wget --mirror --page-requisites --convert-links -P ./LOCAL_DIR URL # Download a Full Website wget -Q5m -i FILE_WITH_URLS.txt # Quit Downloading When it Exceeds Certain Size wget --ftp-user=USERNAME --ftp-password=PASSWORD URL # FTP Download With wget wget --reject=gif URL # Reject Certain File Types while Downloading wget -o download.log URL # Log messages to a log file instead of stderr Using wget -o","title":"wget"},{"location":"cli_tools_net/web_scraping/#reference","text":"https://www.queryhome.com/tech/54364/overview-about-wget-command https://www.linuxtechi.com/wget-command-practical-examples/ https://www.youtube.com/watch?v=GJum2O2JM6M https://www.youtube.com/watch?v=-GCDJ26B4Ho","title":"Reference"},{"location":"cli_tools_net/web_scraping/#loginsessioncookie","text":"","title":"Login/Session/Cookie"},{"location":"cli_tools_net/web_scraping/#hide-yoir-ip-with-proxy-servers","text":"BAD : you ---------> request to target GOOD : you ---------> requets to proxy server -------> request to target","title":"Hide yoir IP with proxy servers"},{"location":"cli_tools_net/web_scraping/#1-gimmeproxy","text":"Make the following request: https://gimmeproxy.com/api/getProxy","title":"1. gimmeproxy"},{"location":"cli_tools_net/web_scraping/#2-they-will-provide-json-response-with-all-proxy-data-which-you-can-use-later-as-needed","text":"{ \"supportsHttps\": true, \"protocol\": \"socks5\", \"ip\": \"179.162.22.82\", \"port\": \"36915\", ... }","title":"2. They will provide JSON response with all proxy data which you can use later as needed:"},{"location":"cli_tools_net/web_scraping/#3-use-the-proxy-with-curl","text":"# -x [protocol://]host[:port] # --proxy [protocol://]host[:port] curl -x socks5://179.162.22.82:36915 http://example.com","title":"3. Use the proxy with curl"},{"location":"cli_tools_net/web_scraping/#web-scraping-methods","text":"There are many approaches of web scrapping: Text browser ( lynx ) + parse text ( grep ) Download HTML ( cURL ) + to text ( html2text ) + parse text ( grep ) Download HTML ( cURL ) + parse HTML ( pup ) Do API reverse engineering + parse JSON ( jq ) Use Selenium or Headless browser","title":"Web Scraping methods"},{"location":"cli_tools_net/web_scraping/#text-browser-lynx-parse-text-grep","text":"lynx -dump \"$the_url\" | grep \"$the_str\") Reference: https://funprojects.blog/2022/04/07/web-scraping-with-1-line-of-bash/","title":"Text browser (lynx) + parse text (grep)"},{"location":"cli_tools_net/web_scraping/#1-static-webpages","text":"Get a simple static page (server side rendered) with curl or wget and parse them Example: page_html=$(curl -s $URL) title=$(echo $page_html | pup 'title' text{}) echo $title col_A=$(echo $page_html | pup 'a.bb1c_ attr{href}') col_B=$(echo $page_html | pup 'span.price-sale text{}') table=$(paste col_A col_B) https://www.youtube.com/watch?v=GJum2O2JM6M","title":"1. Static webpages"},{"location":"cli_tools_net/web_scraping/#2-api-reverse-engineering","text":"Useful for dynamic websites. Find the hidden api that makes XHR requests to fullfill the webpage. XMLHttpRequest is used heavily in AJAX programming. Step 1: See the requests that the web is doing: Chrome or Firefox dev tools > Network > XHR requests Step 2: Copy the target request as cURL (right click) Step 3: Paste the target request in Postman or Insomnia Step 4: Elaborate your own script using curl + jq","title":"2. API reverse engineering"},{"location":"cli_tools_net/web_scraping/#3-headless-browser-selenium","text":"Use Selenium or Headless browser for automate the interaction with the web. Selenium Google Chrome cli lynx lynx -dump -listonly http://aligajani.com google-chrome-stable --headless --disable-gpu --dump-dom 'URL' > ~/file.html","title":"3. Headless browser &amp; Selenium"},{"location":"cli_tools_net/web_scraping/#refenrences","text":"https://www.youtube.com/c/JohnWatsonRooney https://www.youtube.com/channel/UCBGkweoKCtSBx6GEXRYIWLg/videos https://www.youtube.com/playlist?list=PLcUid3OP_4OU0zHx1qlCMdB6pEP1zeaY3 https://www.youtube.com/watch?v=kmlYp8I1MJs&list=PLISuMnTdVU-xOHf3jEtiK1B_g5HFgXCb-","title":"Refenrences"},{"location":"cli_tools_net/DNS/readme/","text":"DNS Under the hood when you run curl: 1. Consult your DNS servers (stored in /etc/resolv.conf ) - 8.8.8.8 is Google DNS server! 2. curl call getaddrinfo is a 3. getaddrinfo makes a \"DNS request\" to 8.8.8.8 4. Finally the IP is obtained dig , nslookup : what's the IP for that domain? (DNS query) whois : is this domain registered? dig dig makes DNS queries! dig google.com nslookup whois DNS Server (static and dynamic, as dyndns)","title":"DNS"},{"location":"cli_tools_net/DNS/readme/#dns","text":"Under the hood when you run curl: 1. Consult your DNS servers (stored in /etc/resolv.conf ) - 8.8.8.8 is Google DNS server! 2. curl call getaddrinfo is a 3. getaddrinfo makes a \"DNS request\" to 8.8.8.8 4. Finally the IP is obtained dig , nslookup : what's the IP for that domain? (DNS query) whois : is this domain registered?","title":"DNS"},{"location":"cli_tools_net/DNS/readme/#dig","text":"dig makes DNS queries! dig google.com","title":"dig"},{"location":"cli_tools_net/DNS/readme/#nslookup","text":"","title":"nslookup"},{"location":"cli_tools_net/DNS/readme/#whois","text":"","title":"whois"},{"location":"cli_tools_net/DNS/readme/#dns-server","text":"(static and dynamic, as dyndns)","title":"DNS Server"},{"location":"cli_tools_net/DNS/server_dns/","text":"","title":"Server dns"},{"location":"desktop/i3blocks/","text":"i3 Poner en .config/i3/config en bar status_command i3blocks status_command i3blocks -c /home/javi/.i3/.i3blocks height 18 Editar configuraci\u00f3n: subl /etc/i3blocks.conf Scrips en /usr/lib/i3blocks Config ######################################################## VARIABLES # Mod key # set $mod Mod1 (alt) set $mod Mod4 # Apps set $browser firefox set $music spotify set $term urxvt ######################################################## i3-gaps # Gaps set $inner 32 set $outer 16 gaps inner $inner gaps outer $outer bindsym $mod+plus gaps inner current minus 8 bindsym $mod+minus gaps inner current plus 8 # Hide window top bar for_window [class=\"^.*\"] border pixel 3 #hide_edge_borders both ######################################################## FONT # Font for window titles. # Will also be used by the bar unless a different font is used in the bar {} block below. #font pango:monospace 8 font pango:monaco 8 # This font is widely installed, provides lots of unicode glyphs, right-to-left # text rendering and scalability on retina/hidpi displays (thanks to pango). #font pango:DejaVu Sans Mono 8 # Before i3 v4.8, we used to recommend this one as the default: # font -misc-fixed-medium-r-normal--13-120-75-75-C-70-iso10646-1 # The font above is very space-efficient, that is, it looks good, sharp and # clear in small sizes. However, its unicode glyph coverage is limited, the old # X core fonts rendering does not support right-to-left and this being a bitmap # font, it doesn\u2019t scale on retina/hidpi displays. ######################################################## FLOATING # Use Mouse+$mod to drag floating windows to their wanted position floating_modifier $mod ######################################################## SHORTCUTS # start a terminal bindsym $mod+Return exec i3-sensible-terminal # kill focused window bindsym $mod+q kill bindsym $mod+Shift+q kill # Menu # start dmenu (a program launcher) #bindsym $mod+d exec dmenu_run #bindsym $mod+m exec dmenu_run bindsym $mod+space exec rofi -show run # There also is the (new) i3-dmenu-desktop which only displays applications # shipping a .desktop file. It is a wrapper around dmenu, so you need that # installed. # bindsym $mod+d exec --no-startup-id i3-dmenu-desktop bindsym $mod+Tab workspace back_and_forth ######################################################## MOVEMENT # FOCUS #bindsym $mod+j focus left #bindsym $mod+k focus down #bindsym $mod+l focus up #bindsym $mod+ntilde focus right bindsym $mod+Left focus left bindsym $mod+Down focus down bindsym $mod+Up focus up bindsym $mod+Right focus right # MOVE FOCUSED #bindsym $mod+Shift+j move left #bindsym $mod+Shift+k move down #bindsym $mod+Shift+l move up #bindsym $mod+Shift+ntilde move right bindsym $mod+Shift+Left move left bindsym $mod+Shift+Down move down bindsym $mod+Shift+Up move up bindsym $mod+Shift+Right move right # HORIZONTAL SPLIT bindsym $mod+h split h # VERTICAL SPLIT bindsym $mod+v split v # FULLSCREEN bindsym $mod+f fullscreen toggle # change container layout (stacked, tabbed, toggle split) bindsym $mod+s layout stacking bindsym $mod+w layout tabbed bindsym $mod+e layout toggle split # toggle tiling / floating bindsym $mod+Shift+space floating toggle # change focus between tiling / floating windows # bindsym $mod+space focus mode_toggle # focus the parent container bindsym $mod+a focus parent # focus the child container #bindsym $mod+d focus child ################################################################ WORKSPACES # Workspaces set $ws1 \"1: Terminals\" set $ws2 \"2: Internet\" set $ws3 \"3\" set $ws4 \"4\" set $ws5 \"5\" set $ws6 \"6\" set $ws7 \"7\" set $ws8 \"8\" set $ws9 \"9\" set $ws10 \"10: Music\" # switch to workspace bindsym $mod+1 workspace $ws1 bindsym $mod+2 workspace $ws2 bindsym $mod+3 workspace $ws3 bindsym $mod+4 workspace $ws4 bindsym $mod+5 workspace $ws5 bindsym $mod+6 workspace $ws6 bindsym $mod+7 workspace $ws7 bindsym $mod+8 workspace $ws8 bindsym $mod+9 workspace $ws9 bindsym $mod+0 workspace $ws10 # move focused container to workspace bindsym $mod+Shift+1 move container to workspace $ws1 bindsym $mod+Shift+2 move container to workspace $ws2 bindsym $mod+Shift+3 move container to workspace $ws3 bindsym $mod+Shift+4 move container to workspace $ws4 bindsym $mod+Shift+5 move container to workspace $ws5 bindsym $mod+Shift+6 move container to workspace $ws6 bindsym $mod+Shift+7 move container to workspace $ws7 bindsym $mod+Shift+8 move container to workspace $ws8 bindsym $mod+Shift+9 move container to workspace $ws9 bindsym $mod+Shift+0 move container to workspace $ws10 ################################################################ COLORS # class border backgr. text indicator child_border client.focused #4c7899 #285577 #ffffff #2e9ef4 #285577 client.focused_inactive #333333 #5f676a #ffffff #484e50 #5f676a client.unfocused #333333 #222222 #888888 #292d2e #222222 client.urgent #2f343a #900000 #ffffff #900000 #900000 client.placeholder #000000 #0c0c0c #ffffff #000000 #0c0c0c client.background #ffffff # reload the configuration file bindsym $mod+Shift+c reload # restart i3 inplace (preserves your layout/session, can be used to upgrade i3) bindsym $mod+Shift+r restart # exit i3 (logs you out of your X session) bindsym $mod+Shift+e exec \"i3-nagbar -t warning -m 'You pressed the exit shortcut. Do you really want to exit i3? This will end your X session.' -b 'Yes, exit i3' 'i3-msg exit'\" # resize window (you can also use the mouse for that) mode \"resize\" { # These bindings trigger as soon as you enter the resize mode # Pressing left will shrink the window\u2019s width. # Pressing right will grow the window\u2019s width. # Pressing up will shrink the window\u2019s height. # Pressing down will grow the window\u2019s height. bindsym j resize shrink width 10 px or 10 ppt bindsym k resize grow height 10 px or 10 ppt bindsym l resize shrink height 10 px or 10 ppt bindsym ntilde resize grow width 10 px or 10 ppt # same bindings, but for the arrow keys bindsym Left resize shrink width 10 px or 10 ppt bindsym Down resize grow height 10 px or 10 ppt bindsym Up resize shrink height 10 px or 10 ppt bindsym Right resize grow width 10 px or 10 ppt # back to normal: Enter or Escape bindsym Return mode \"default\" bindsym Escape mode \"default\" } bindsym $mod+r mode \"resize\" ################################################################ i3bar bar { # STATUS # DEFUALT: i3status #status_command i3status status_command i3blocks # Show on top position top mode dock modifier None } ################################################################ CUSTOM # lock bindsym $mod+l exec i3lock ################################################################ INIT APPS assign [class=\"Navigator\"] $ws2 exec firefox # only on restart and login # exec firefox # # every time that i3 is loaded # exec_always # background exec_always --no-startup-id feh --bg-scale /home/javi/Im\u00e1genes/fondos/space1.jpg ################################################################ MULTIMEDIA KEYS # Pulse Audio controls bindsym XF86AudioRaiseVolume exec --no-startup-id pactl set-sink-volume 0 +5% #increase sound volume bindsym XF86AudioLowerVolume exec --no-startup-id pactl set-sink-volume 0 -5% #decrease sound volume bindsym XF86AudioMute exec --no-startup-id pactl set-sink-mute 0 toggle # mute sound # Sreen brightness controls # bindsym XF86MonBrightnessUp exec xbacklight -inc 20 # increase screen brightness # bindsym XF86MonBrightnessDown exec xbacklight -dec 20 # decrease screen brightness # Touchpad controls # bindsym XF86TouchpadToggle exec /some/path/toggletouchpad.sh # toggle touchpad # Media player controls bindsym XF86AudioPlay exec playerctl play bindsym XF86AudioPause exec playerctl pause bindsym XF86AudioNext exec playerctl next bindsym XF86AudioPrev exec playerctl previous","title":"i3"},{"location":"desktop/i3blocks/#i3","text":"Poner en .config/i3/config en bar status_command i3blocks status_command i3blocks -c /home/javi/.i3/.i3blocks height 18 Editar configuraci\u00f3n: subl /etc/i3blocks.conf Scrips en /usr/lib/i3blocks","title":"i3"},{"location":"desktop/i3blocks/#config","text":"######################################################## VARIABLES # Mod key # set $mod Mod1 (alt) set $mod Mod4 # Apps set $browser firefox set $music spotify set $term urxvt ######################################################## i3-gaps # Gaps set $inner 32 set $outer 16 gaps inner $inner gaps outer $outer bindsym $mod+plus gaps inner current minus 8 bindsym $mod+minus gaps inner current plus 8 # Hide window top bar for_window [class=\"^.*\"] border pixel 3 #hide_edge_borders both ######################################################## FONT # Font for window titles. # Will also be used by the bar unless a different font is used in the bar {} block below. #font pango:monospace 8 font pango:monaco 8 # This font is widely installed, provides lots of unicode glyphs, right-to-left # text rendering and scalability on retina/hidpi displays (thanks to pango). #font pango:DejaVu Sans Mono 8 # Before i3 v4.8, we used to recommend this one as the default: # font -misc-fixed-medium-r-normal--13-120-75-75-C-70-iso10646-1 # The font above is very space-efficient, that is, it looks good, sharp and # clear in small sizes. However, its unicode glyph coverage is limited, the old # X core fonts rendering does not support right-to-left and this being a bitmap # font, it doesn\u2019t scale on retina/hidpi displays. ######################################################## FLOATING # Use Mouse+$mod to drag floating windows to their wanted position floating_modifier $mod ######################################################## SHORTCUTS # start a terminal bindsym $mod+Return exec i3-sensible-terminal # kill focused window bindsym $mod+q kill bindsym $mod+Shift+q kill # Menu # start dmenu (a program launcher) #bindsym $mod+d exec dmenu_run #bindsym $mod+m exec dmenu_run bindsym $mod+space exec rofi -show run # There also is the (new) i3-dmenu-desktop which only displays applications # shipping a .desktop file. It is a wrapper around dmenu, so you need that # installed. # bindsym $mod+d exec --no-startup-id i3-dmenu-desktop bindsym $mod+Tab workspace back_and_forth ######################################################## MOVEMENT # FOCUS #bindsym $mod+j focus left #bindsym $mod+k focus down #bindsym $mod+l focus up #bindsym $mod+ntilde focus right bindsym $mod+Left focus left bindsym $mod+Down focus down bindsym $mod+Up focus up bindsym $mod+Right focus right # MOVE FOCUSED #bindsym $mod+Shift+j move left #bindsym $mod+Shift+k move down #bindsym $mod+Shift+l move up #bindsym $mod+Shift+ntilde move right bindsym $mod+Shift+Left move left bindsym $mod+Shift+Down move down bindsym $mod+Shift+Up move up bindsym $mod+Shift+Right move right # HORIZONTAL SPLIT bindsym $mod+h split h # VERTICAL SPLIT bindsym $mod+v split v # FULLSCREEN bindsym $mod+f fullscreen toggle # change container layout (stacked, tabbed, toggle split) bindsym $mod+s layout stacking bindsym $mod+w layout tabbed bindsym $mod+e layout toggle split # toggle tiling / floating bindsym $mod+Shift+space floating toggle # change focus between tiling / floating windows # bindsym $mod+space focus mode_toggle # focus the parent container bindsym $mod+a focus parent # focus the child container #bindsym $mod+d focus child ################################################################ WORKSPACES # Workspaces set $ws1 \"1: Terminals\" set $ws2 \"2: Internet\" set $ws3 \"3\" set $ws4 \"4\" set $ws5 \"5\" set $ws6 \"6\" set $ws7 \"7\" set $ws8 \"8\" set $ws9 \"9\" set $ws10 \"10: Music\" # switch to workspace bindsym $mod+1 workspace $ws1 bindsym $mod+2 workspace $ws2 bindsym $mod+3 workspace $ws3 bindsym $mod+4 workspace $ws4 bindsym $mod+5 workspace $ws5 bindsym $mod+6 workspace $ws6 bindsym $mod+7 workspace $ws7 bindsym $mod+8 workspace $ws8 bindsym $mod+9 workspace $ws9 bindsym $mod+0 workspace $ws10 # move focused container to workspace bindsym $mod+Shift+1 move container to workspace $ws1 bindsym $mod+Shift+2 move container to workspace $ws2 bindsym $mod+Shift+3 move container to workspace $ws3 bindsym $mod+Shift+4 move container to workspace $ws4 bindsym $mod+Shift+5 move container to workspace $ws5 bindsym $mod+Shift+6 move container to workspace $ws6 bindsym $mod+Shift+7 move container to workspace $ws7 bindsym $mod+Shift+8 move container to workspace $ws8 bindsym $mod+Shift+9 move container to workspace $ws9 bindsym $mod+Shift+0 move container to workspace $ws10 ################################################################ COLORS # class border backgr. text indicator child_border client.focused #4c7899 #285577 #ffffff #2e9ef4 #285577 client.focused_inactive #333333 #5f676a #ffffff #484e50 #5f676a client.unfocused #333333 #222222 #888888 #292d2e #222222 client.urgent #2f343a #900000 #ffffff #900000 #900000 client.placeholder #000000 #0c0c0c #ffffff #000000 #0c0c0c client.background #ffffff # reload the configuration file bindsym $mod+Shift+c reload # restart i3 inplace (preserves your layout/session, can be used to upgrade i3) bindsym $mod+Shift+r restart # exit i3 (logs you out of your X session) bindsym $mod+Shift+e exec \"i3-nagbar -t warning -m 'You pressed the exit shortcut. Do you really want to exit i3? This will end your X session.' -b 'Yes, exit i3' 'i3-msg exit'\" # resize window (you can also use the mouse for that) mode \"resize\" { # These bindings trigger as soon as you enter the resize mode # Pressing left will shrink the window\u2019s width. # Pressing right will grow the window\u2019s width. # Pressing up will shrink the window\u2019s height. # Pressing down will grow the window\u2019s height. bindsym j resize shrink width 10 px or 10 ppt bindsym k resize grow height 10 px or 10 ppt bindsym l resize shrink height 10 px or 10 ppt bindsym ntilde resize grow width 10 px or 10 ppt # same bindings, but for the arrow keys bindsym Left resize shrink width 10 px or 10 ppt bindsym Down resize grow height 10 px or 10 ppt bindsym Up resize shrink height 10 px or 10 ppt bindsym Right resize grow width 10 px or 10 ppt # back to normal: Enter or Escape bindsym Return mode \"default\" bindsym Escape mode \"default\" } bindsym $mod+r mode \"resize\" ################################################################ i3bar bar { # STATUS # DEFUALT: i3status #status_command i3status status_command i3blocks # Show on top position top mode dock modifier None } ################################################################ CUSTOM # lock bindsym $mod+l exec i3lock ################################################################ INIT APPS assign [class=\"Navigator\"] $ws2 exec firefox # only on restart and login # exec firefox # # every time that i3 is loaded # exec_always # background exec_always --no-startup-id feh --bg-scale /home/javi/Im\u00e1genes/fondos/space1.jpg ################################################################ MULTIMEDIA KEYS # Pulse Audio controls bindsym XF86AudioRaiseVolume exec --no-startup-id pactl set-sink-volume 0 +5% #increase sound volume bindsym XF86AudioLowerVolume exec --no-startup-id pactl set-sink-volume 0 -5% #decrease sound volume bindsym XF86AudioMute exec --no-startup-id pactl set-sink-mute 0 toggle # mute sound # Sreen brightness controls # bindsym XF86MonBrightnessUp exec xbacklight -inc 20 # increase screen brightness # bindsym XF86MonBrightnessDown exec xbacklight -dec 20 # decrease screen brightness # Touchpad controls # bindsym XF86TouchpadToggle exec /some/path/toggletouchpad.sh # toggle touchpad # Media player controls bindsym XF86AudioPlay exec playerctl play bindsym XF86AudioPause exec playerctl pause bindsym XF86AudioNext exec playerctl next bindsym XF86AudioPrev exec playerctl previous","title":"Config"},{"location":"hardware/hardware/","text":"Hardware Mother board 1*1030\u20ac = 1030\u20ac https://www.pccomponentes.com/asus-pro-ws-wrx80e-sage-se-wifi CPU 32 cores 1*3500\u20ac = 3500\u20ac 6 x GPU 3090 6*2200\u20ac = 13000\u20ac 256GB RAM (8 x 32GB) 8*225\u20ac = 1800\u20ac 16TB NVMe (8 x 2TB) 8*320\u20ac = 2650\u20ac 128TB HHD (8 x 8TB) 8*320\u20ac = 2650\u20ac ======================================= 25000\u20ac Componente Precio Inic. Mej 1 Mej 2 Mej 3 Mej 4 Mej 5 Mej 6 Mother board (ASUS PRO WS WRX80E) 1030\u20ac x1 CPU (AMD thradripper 5975WX) 3500\u20ac x1 GPU (Nvidia RTX 3090) 2200\u20ac x1 x1 x1 x1 x1 x1 x1 256GB RAM (8 x 32GB) 1800\u20ac Almacenamineto SSD M2 Almacenamineto SSD SATA Almacenamineto HDD Fuente Total 8530\u20ac Motherboard 128 PCIe 4.0 lines Opcion 1 7 GPUS 4 nvmes M.2 (con capacidad raid 0) Opcion 8 6 GPUS 8 nvmes M.2 (con capacidad raid 0) 8 ranuras de ram (con ECC) CPU: Threadripper Pro (gama 3000 o 5000) 8 sata ports https://www.youtube.com/watch?v=m5xd2ZizMOA MSI WS WRX80 CPU AMD | | | | PISTAS | | | | CORES | RAM MEMORY | PCIe4.0 | PRICE | SOCKET |-------------------------|-------|---------------------|---------|-------|------- | Ryzen 9 5900X | 12 | 128GB (2ch) | 20 | 500\u20ac | | Ryzen 9 5950X | 16 | 128GB (2ch) | 20 | 670\u20ac | | | | | | | | Threadripper 3960X | 24 | 512GB (4ch) 95 GB/s | 64 | 1700\u20ac | sTRX4 | Threadripper 3970X | 32 | 512GB (4ch) 95 GB/s | 64 | | sTRX4 | Threadripper 3990X | 64 | 512GB (4ch) 95 GB/s | 64 | | sTRX4 | | | | | | | Marzo 2021 | | | | | | Threadripper Pro 3945WX | 12 | 2TB (8ch) 205 GB/s | 128 | | WRX80 | Threadripper Pro 3955WX | 16 | 2TB (8ch) 205 GB/s | 128 | | | Threadripper Pro 3965WX | 24 | 2TB (8ch) 205 GB/s | 128 | | | Threadripper Pro 3975WX | 32 | 2TB (8ch) 205 GB/s | 128 | 3500\u20ac | ESTE ES EL DE ANDRES | Threadripper Pro 3995WX | 64 | 2TB (8ch) 205 GB/s | 128 | 6000..8000\u20ac | | | | | | | | Marzo 2022 | | | | | | Threadripper Pro 5945WX | 12 | 8 sWRX8 | Threadripper Pro 5955WX | 16 | 8 | Threadripper Pro 5965WX | 24 | 8 | Threadripper Pro 5975WX | 32 | 8 | Threadripper Pro 5995WX | 64 | 8 | | | Gama de servidores | | | EPYC 7001 | EPYC 7002 | EPYC 7003 https://gadgetversus.com/processor/amd-ryzen-threadripper-pro-3955wx-specs/ MAL: pero no lo recomineda pq tine contencion de memoria pq tiene 4 canales Andres recomienda la gama Threadripper antes que la Epyc pq caundo usas porcesoso de 1 solo hilo con 1 solo nueclo va mas r\u00e1pido. la serie pro de los thradriper (acaba en 5) tiene soporte para 8 canales en memoria PCIe PCIe Bits x1 x4 (Nvme) x8 x16 (GPU) 1.0 8b/10b 250 MB/s 1 GB/s 2 GB/s 4 GB/s 2.0 8b/10b 500 MB/s 2 GB/s 4 GB/s 8 GB/s 3.0 128b/130b 984.6 MB/s 3.938 GB/s 7.877 GB/s 15.754 GB/s 4.0 128b/130b 1.969 GB/s 7.877 GB/s 15.754 GB/s 31.508 GB/s GPU CUDA Tensor FP64 GPU Realese cores cores Memory Watts Price tFPLOS A2 Nov 2021 1280 24GB GDDR6 50 A10 Apr 2021 9216 24GB GDDR6 150 3090 (24GB) A6000 A16 Apr 2021 10240 4x16GB GDDR6 250 A30 Apr 2021 3584 24GB HBM2 165 5.000\u20ac (5,2) 10,3 A40 Oct 2020 10752 336 48GB GDDR6 300 5.000\u20ac A100 May 2020 6912 40GB HBM2 250 10.000\u20ac A100 May 2020 6912 40GB HBM2BULK250 10.000\u20ac A100 May 2020 6912 80GB HBM2 250 20.000\u20ac Discos duros lectura seq escritura seq HDD 80..150 MB/s 80..150 MB/s SSD SATA 500..550 MB/s 450..500 MB/s SSD M.2 NVMe PCIe 3.0 3000.3500 MB/s 3000.3500 MB/s SSD M.2 NVMe PCIe 4.0 5000.7000 MB/s 5000.7000 MB/s ojo! no todos los SSD M.2 del mercado son NVMe, tambi\u00e9n hay unidades M.2 SATA . Loss M.2 NVMe PCIe tienen un problema denominado Thermal Throttling: el rendimiento cae dr\u00e1sticamente cuando se da una temperatura muy elevada. Por lo tanto hay que refrigerarlos bien. | Que hace | Cuando usar --------|----------------------------------------------------------------------------------------------- RAID 0 | Todos los dicos actuan como 1 solo (se lee y escribe en paralelo en todos) | Cuando se busca velocidad RAID 1 | La inforacion se duplica | Cuando se busca fualt tolerance RAID 5 | caca RAID 6 | caca RAID 10 | Cuando se busca fualt tolerance con velocidad RAID 0: lass velocidades de lectura y escritura. Normalmente es la suma de las velocidades de las unidades menos un 10-15%. Maxiama prestaciones (velocidad de escritura y lectura): 1 SSD NVME M2 Varios SSD NVME M2 en RAID 0 Maxima seguridad a posibles fallos (fault tolerance) RAID 1 or RAID 5 (LVM) Logical Volume Management Hardware for servers disks -> RAID (mean time to failure (MTTF) of about 10 to 50 years) dual power supplies batteries and diesel generators for backup power hot-swappable CPUs When one component dies, the redundant component can take its place while the broken component is replaced. ECC RAM: Good for servers HDBaseT Protocolo para dejar el ordenador lejos (hasta 100 metros de distancia) y conetar todo (video, USB) por un cable Ethernet (categor\u00eda 5E para distancias cortas o categoria 6 o 7 para distancias largas).","title":"Hardware"},{"location":"hardware/hardware/#hardware","text":"Mother board 1*1030\u20ac = 1030\u20ac https://www.pccomponentes.com/asus-pro-ws-wrx80e-sage-se-wifi CPU 32 cores 1*3500\u20ac = 3500\u20ac 6 x GPU 3090 6*2200\u20ac = 13000\u20ac 256GB RAM (8 x 32GB) 8*225\u20ac = 1800\u20ac 16TB NVMe (8 x 2TB) 8*320\u20ac = 2650\u20ac 128TB HHD (8 x 8TB) 8*320\u20ac = 2650\u20ac ======================================= 25000\u20ac Componente Precio Inic. Mej 1 Mej 2 Mej 3 Mej 4 Mej 5 Mej 6 Mother board (ASUS PRO WS WRX80E) 1030\u20ac x1 CPU (AMD thradripper 5975WX) 3500\u20ac x1 GPU (Nvidia RTX 3090) 2200\u20ac x1 x1 x1 x1 x1 x1 x1 256GB RAM (8 x 32GB) 1800\u20ac Almacenamineto SSD M2 Almacenamineto SSD SATA Almacenamineto HDD Fuente Total 8530\u20ac","title":"Hardware"},{"location":"hardware/hardware/#motherboard","text":"128 PCIe 4.0 lines Opcion 1 7 GPUS 4 nvmes M.2 (con capacidad raid 0) Opcion 8 6 GPUS 8 nvmes M.2 (con capacidad raid 0) 8 ranuras de ram (con ECC) CPU: Threadripper Pro (gama 3000 o 5000) 8 sata ports https://www.youtube.com/watch?v=m5xd2ZizMOA MSI WS WRX80","title":"Motherboard"},{"location":"hardware/hardware/#cpu-amd","text":"| | | | PISTAS | | | | CORES | RAM MEMORY | PCIe4.0 | PRICE | SOCKET |-------------------------|-------|---------------------|---------|-------|------- | Ryzen 9 5900X | 12 | 128GB (2ch) | 20 | 500\u20ac | | Ryzen 9 5950X | 16 | 128GB (2ch) | 20 | 670\u20ac | | | | | | | | Threadripper 3960X | 24 | 512GB (4ch) 95 GB/s | 64 | 1700\u20ac | sTRX4 | Threadripper 3970X | 32 | 512GB (4ch) 95 GB/s | 64 | | sTRX4 | Threadripper 3990X | 64 | 512GB (4ch) 95 GB/s | 64 | | sTRX4 | | | | | | | Marzo 2021 | | | | | | Threadripper Pro 3945WX | 12 | 2TB (8ch) 205 GB/s | 128 | | WRX80 | Threadripper Pro 3955WX | 16 | 2TB (8ch) 205 GB/s | 128 | | | Threadripper Pro 3965WX | 24 | 2TB (8ch) 205 GB/s | 128 | | | Threadripper Pro 3975WX | 32 | 2TB (8ch) 205 GB/s | 128 | 3500\u20ac | ESTE ES EL DE ANDRES | Threadripper Pro 3995WX | 64 | 2TB (8ch) 205 GB/s | 128 | 6000..8000\u20ac | | | | | | | | Marzo 2022 | | | | | | Threadripper Pro 5945WX | 12 | 8 sWRX8 | Threadripper Pro 5955WX | 16 | 8 | Threadripper Pro 5965WX | 24 | 8 | Threadripper Pro 5975WX | 32 | 8 | Threadripper Pro 5995WX | 64 | 8 | | | Gama de servidores | | | EPYC 7001 | EPYC 7002 | EPYC 7003 https://gadgetversus.com/processor/amd-ryzen-threadripper-pro-3955wx-specs/ MAL: pero no lo recomineda pq tine contencion de memoria pq tiene 4 canales Andres recomienda la gama Threadripper antes que la Epyc pq caundo usas porcesoso de 1 solo hilo con 1 solo nueclo va mas r\u00e1pido. la serie pro de los thradriper (acaba en 5) tiene soporte para 8 canales en memoria","title":"CPU AMD"},{"location":"hardware/hardware/#pcie","text":"PCIe Bits x1 x4 (Nvme) x8 x16 (GPU) 1.0 8b/10b 250 MB/s 1 GB/s 2 GB/s 4 GB/s 2.0 8b/10b 500 MB/s 2 GB/s 4 GB/s 8 GB/s 3.0 128b/130b 984.6 MB/s 3.938 GB/s 7.877 GB/s 15.754 GB/s 4.0 128b/130b 1.969 GB/s 7.877 GB/s 15.754 GB/s 31.508 GB/s","title":"PCIe"},{"location":"hardware/hardware/#gpu","text":"CUDA Tensor FP64","title":"GPU"},{"location":"hardware/hardware/#gpu-realese-cores-cores-memory-watts-price-tfplos","text":"A2 Nov 2021 1280 24GB GDDR6 50 A10 Apr 2021 9216 24GB GDDR6 150 3090 (24GB) A6000 A16 Apr 2021 10240 4x16GB GDDR6 250 A30 Apr 2021 3584 24GB HBM2 165 5.000\u20ac (5,2) 10,3 A40 Oct 2020 10752 336 48GB GDDR6 300 5.000\u20ac A100 May 2020 6912 40GB HBM2 250 10.000\u20ac A100 May 2020 6912 40GB HBM2BULK250 10.000\u20ac A100 May 2020 6912 80GB HBM2 250 20.000\u20ac","title":"GPU   Realese   cores   cores   Memory       Watts  Price  tFPLOS"},{"location":"hardware/hardware/#discos-duros","text":"lectura seq escritura seq HDD 80..150 MB/s 80..150 MB/s SSD SATA 500..550 MB/s 450..500 MB/s SSD M.2 NVMe PCIe 3.0 3000.3500 MB/s 3000.3500 MB/s SSD M.2 NVMe PCIe 4.0 5000.7000 MB/s 5000.7000 MB/s ojo! no todos los SSD M.2 del mercado son NVMe, tambi\u00e9n hay unidades M.2 SATA . Loss M.2 NVMe PCIe tienen un problema denominado Thermal Throttling: el rendimiento cae dr\u00e1sticamente cuando se da una temperatura muy elevada. Por lo tanto hay que refrigerarlos bien. | Que hace | Cuando usar --------|----------------------------------------------------------------------------------------------- RAID 0 | Todos los dicos actuan como 1 solo (se lee y escribe en paralelo en todos) | Cuando se busca velocidad RAID 1 | La inforacion se duplica | Cuando se busca fualt tolerance RAID 5 | caca RAID 6 | caca RAID 10 | Cuando se busca fualt tolerance con velocidad RAID 0: lass velocidades de lectura y escritura. Normalmente es la suma de las velocidades de las unidades menos un 10-15%. Maxiama prestaciones (velocidad de escritura y lectura): 1 SSD NVME M2 Varios SSD NVME M2 en RAID 0 Maxima seguridad a posibles fallos (fault tolerance) RAID 1 or RAID 5 (LVM) Logical Volume Management","title":"Discos duros"},{"location":"hardware/hardware/#hardware-for-servers","text":"disks -> RAID (mean time to failure (MTTF) of about 10 to 50 years) dual power supplies batteries and diesel generators for backup power hot-swappable CPUs When one component dies, the redundant component can take its place while the broken component is replaced. ECC RAM: Good for servers","title":"Hardware for servers"},{"location":"hardware/hardware/#hdbaset","text":"Protocolo para dejar el ordenador lejos (hasta 100 metros de distancia) y conetar todo (video, USB) por un cable Ethernet (categor\u00eda 5E para distancias cortas o categoria 6 o 7 para distancias largas).","title":"HDBaseT"},{"location":"others/algorithims/","text":"Shortest path dijkstra A* https://www.youtube.com/watch?v=A60q6dcoCjw SAT solvers Factorizaton algos Books The Art of Computer Programming","title":"Shortest path"},{"location":"others/algorithims/#shortest-path","text":"dijkstra A* https://www.youtube.com/watch?v=A60q6dcoCjw","title":"Shortest path"},{"location":"others/algorithims/#sat-solvers","text":"","title":"SAT solvers"},{"location":"others/algorithims/#factorizaton-algos","text":"","title":"Factorizaton algos"},{"location":"others/algorithims/#books","text":"The Art of Computer Programming","title":"Books"},{"location":"others/install_arch_linux/","text":"Install Manjaro Entra en la Bios (tecla ?) y detecta tu sistema | Bios (or Legacy) | UEFI | |-------------------------|----------------------------| | MRB (Master Boot Rcord) | GPT (GUID Partition Table) | | Antiguo | Nuevo | [ ] Enable UEFI [ ] Disable Secure Boot [ ] Disable Fast Boot Inserta USB de Manjaro con el PC apagado Elije partici\u00f3n de arraque al encender (tecla F12) Y elije arrancar desde USB en modo UEFI Selecciona el Driver : free : Si no tienes GPU nonfree : Si tienes GPU Nvidia (o AMD) Particiones Size Type File system Mount point Flags Partici\u00f3n de arranque 100 MB GPT fat32 /boot/efi boot, esp Partici\u00f3n SWAP (opcional) 16 GB GPT linuxswap swap Partici\u00f3n para Manjaro Resto GPT ext4 / root iso image to USB sudo fdisk -l buscar localizaci\u00f3n del USB (sdb, sdc, etc.). sudo dd bs=4M if=/path/to/downloaded/iso of=/dev/sdx status=progress oflag=sync Copiar (reemplazar sdx por la correcta ubicaci\u00f3n). # HARDWARE # Processor x86_64 # Min RAM: 512 MB RAM # Min Space: 800 MB # SOFTWARE # User: root # Shell: zsh # Editors: nano vi vim ################################################ ######## ON WORKING COMPUTER ######## ################################################ # 1. Download iso # 2. Identify USB pen lsblk fdisk -l # 3. Copy iso to pendrive dd if=Downloads/archlinux.iso of=/dev/sdb status=\"progress\" # very careful with correct \"of\" dd bs=4M if=/path/to/antergos-x86_64.iso of=/dev/sdX status=progress && sync ################################################ ######## PRE-INTALLATION ######## ################################################ ########################################## Keyboard and font ls /usr/share/kbd/keymaps/**/*.map.gz # OPTIONAL List available keyboards loadkeys es # Set spanish keyboard ls /usr/share/kbd/consolefonts/ # OPTIONAL See fonts setfont # OPTIONAL Set font ########################################## Verify Boot mode # TODO: UEFI vs BIOS # Mejor usar BIOS # UEFI activated if the directory exists. ls /sys/firmware/efi/efivars # If the directory does not exist, the system may be booted in BIOS ########################################## Connect to the Internet # dhcpcd is activated. Check connection with ping ping archlinux.org ########################################## Update the system clock # Ensure the system clock is accurate timedatectl set-ntp true ########################################## Partition # 1) Identify disks lsblk # Option 1 fdisk -l # Option 2 # 2) Particionate a disk (sda, sdb, ...) # 4 needed partitions: # sda 256G # \u251c\u2500sda1 /boot/efi 200..512 = 256M # \u251c\u2500sda2 [SWAP] 16..32 = 32G # \u251c\u2500sda3 / 25..32 = 32G # \u2514\u2500sda4 /home rest # # sda 256G # \u251c\u2500sda1 /boot 200..512 = 256M # \u251c\u2500sda2 [SWAP] 16..32 = 32G # \u251c\u2500sda3 / 25..32 = 32G # \u2514\u2500sda4 /home rest fdisk /dev/sda # Option 1 m # Help p # Print status d # Delete current partitons n # Create new partition: Boot (200MB) # type: default (primary) # number: default (1) # fisrt sector: default # last sector: +200M # Remove signature: Yes # repeat for rest w # Write changes parted /dev/sda # Option 2 mklabel gpt mkpart ESP fat32 1MiB 513MiB set 1 boot on mkpart primary linux-swap 513MiB 4.5GiB mkpart primary ext4 4.5GiB 100% # 3) Format partitions mkfs.ext4 /dev/sda1 # Boot mkswap /dev/sda2 # Swap swapon /dev/sda2 # Swap mkfs.ext4 /dev/sda3 # Root mkfs.ext4 /dev/sda4 # Home # 4) Mount mount /dev/sda3 /mnt # Mount root mkdir /mnt/boot # Mount boot mount /dev/sda1 /mnt/boot # Mount boot mkdir /mnt/home # Mount home mount /dev/sda4 /mnt/home # Mount home ################################################ ######## INTALLATION ######## ################################################ ########################################## Install base packages pacstrap /mnt base base-devel ########################################## Generate /est/fstab file genfstab -U /mnt >> /mnt/etc/fstab ########################################## Bootable # Enter the system # Command line from pendrive to my system arch-chroot /mnt ########################################## Time zone ln -sf /usr/share/zoneinfo/Europe/Madrid /etc/localtime hwclock --systohc ########################################## System language # Set the system language nano /etc/locale.gen # Uncomment en_US.UTF-8 UTF-8 locale-gen nano /etc/locale.conf # (new file) # LANG=es_ES.UTF-8 # LANG=en_US.UTF-8 ########################################## Keyboard nano /etc/vconsole.conf # KEYMAP=es ########################################## Hostname nano /etc/hostname # (new file) # pc nano /etc/hosts # (separate with tabs) # 127.0.0.1 localhost.localdomain localhost # ::1 localhost.localdomain localhost # 127.0.1.1 pc.localdomain pc ########################################## Network config pacman -S networkmanager # install systemctl enable NetworkManager # Start on boot ########################################## Root pass passwd ########################################## Boot loader pacman -S grub intel-ucode # OPTION A: Install grub (for BIOS) grub-install /dev/sda # OPTION B: Install grub (for UEFI) grub-install --target=x86_64-efi --efi-directory=boot --bootloader-id=GRUB grub-install --target=x86_64-efi --efi-directory=boot/efi --bootloader-id=GRUB # Config. (Microcode updates will be added automatically) grub-mkconfig -o /boot/grub/grub.cfg ########################################## Reboot exit umount -R /mnt reboot # login: root # enter password ################################################ ######## POST-INTALLATION ######## ################################################ Read https://wiki.archlinux.org/index.php/General_recommendations editar /etc/pacman.conf para activar el repositorio [community] ########################################## Add user #useradd -m -g wheel -s /bin/bash javi useradd --create-home --gid wheel --shell /bin/bash javi passwd javi ########################################## Trim support for SSD # https://wiki.archlinux.org/index.php/Solid_State_Drive#TRIM lsblk -D # Verify trim support # disc-gran/disc-max should not be empty if enabled # The util-linux package provides fstrim.service and fstrim.timer # Enabling the timer will activate the service weekly systemctl start fstrim.timer systemctl enable fstrim.timer ########################################## Install LTS Kernel # https://youtu.be/b-H3jURTgqk uname -r # Check your current kernel sudo pacman -S linux-lts # Install LTS kernel pacman -R linux # [OPTIONAL] Remove the standard kernel grub-mkconfig -o /boot/grub/grub.cfg # Reconfigure GRUB sudo pacman -S linux-lts-headers # Install LTS headers sudo reboot # Reboot uname -r # Check new current kernel # Note, for syslinux you'll need to edit the syslinux config file in /boot/syslinux/syslinux.cfg accordingly, # just point everything to the -lts kernel. ########################################## Install microcode (for Intel) sudo pacman -S intel-ucode # Install microcode grub-mkconfig -o /boot/grub/grub.cfg # Reconfigure GRUB ########################################## Disable GRUB delay # Add the following to /etc/default/grub: # achieve the fastest possible boot: GRUB_FORCE_HIDDEN_MENU=\"true\" # Then put file 31_hold_shift to /etc/grub.d/. # Download 31_hold_shift https://goo.gl/nac6Kp # Make it executable, and regenerate the grub configuration: sudo chmod a+x /etc/grub.d/31_hold_shift sudo grub-mkconfig -o /boot/grub/grub.cfg ########################################## Install key packages sudo pacman -S adobe-source-sans-pro-fonts aspell-en enchant gst-libav gst-plugins-good \\ hunspell-en icedtea-web jre8-openjdk languagetool libmythes mythes-en pkgstats \\ ttf-anonymous-pro ttf-bitstream-vera ttf-dejavu ttf-droid ttf-gentium ttf-liberation ttf-ubuntu-font-family ########################################## Firewall # iptables is already installed. I like ufw. pacman -S ufw # Install ufw ufw enable # Enable it only once, when package is installed ufw status verbose # Check its status systemctl start ufw # Start the firewall systemctl enable ufw # Enable the start-up with the system [option a] systemctl enable ufw.service # Enable the start-up with the system [option b] ########################################## Encrypt your home directory ########################################## Optimize pacman's database access speeds sudo pacman-optimize ########################################## Check for errors sudo systemctl --failed sudo journalctl -p 3 -xb ########################################## Backup the system sudo rsync -aAXvP --delete --exclude=/dev/* --exclude=/proc/* --exclude=/sys/* --exclude=/tmp/* --exclude=/run/* --exclude=/mnt/* --exclude=/media/* --exclude=/lost+found --exclude=/home/.ecryptfs / /mnt/backupDestination/ ################################################ ######## GRAPHICAL ENVIROMENT ######## ################################################ If you want to use the latest nvidia drivers in the official repository, you can choose libglvnd (and not nvidia-304xx-utils). ########################################## Xorg pacman -S xorg-server xorg-xinit pacman -S xterm # Necessary?? # It will read from ~/.xinitrc to know what to start nano ~/.xinitrc exec i3 # You can start X by running: xinit startx ENTER ENTER ########################################## Display manager (login screen) # Terminal login screen: # nano ~/.profile ~/.bash_profile if [[ \"$(tty)\" == '/dev/tty1' ]]; then exec startx fi # or use a Display manager (login screen) pacman -S lightdb lightdm-gtk-greeter systemctl enable lightdm.service ########################################## Colors # Colors in terminal for bash, pacman and nano # https://youtu.be/giAb4Ckh8BQ # Install i3 window manager pacman -S i3-gaps i3status rxvt-unicode dmenu # Other things needed for a wm nano ~/.xinitrc # exec i3 # Fonts pacman -S ttf-linux-libertine ttf-inconsolata # Or just pacman -S noto-fonts # Manually edit ~/.config/fontconfig/fonts.conf ################################################ ######## DEEP LEARNING SETUP ######## ################################################ # READ https://www.hackster.io/Ladvien/gpu-accelerated-deep-learning-environment-on-arch-linux-16631b dialog --backtitle \"Deep learning with Arch linux\"\\ --title \"Welcome!\"\\ --msgbox \"\\nThis is the configuration to make your perfect linux distro.\"\\ 8 40 dialog --backtitle \"CPU Selection\" \\ --radiolist \"Select CPU type:\" 10 40 4 \\ 1 386SX off \\ 2 386DX on \\ 3 486SX off \\ 4 486DX off ########################################## Nvidia drivers # Identify your card lspci | grep -i nvidia lspci | grep -e VGA -e 3D lspci -k | grep -A 2 -i \"VGA\" # Install drivers and driver's utils pacman -S nvidia # Nvidia drivers pacman -S nvidia-utils # Nvidia driver's utils reboot ######################################## GPU computation pacman -S cuda # Nvidia API for GPGPU pacman -S cudnn # Nvidia primitives for Neural Networks #Magma # Linear Algebra for OpenCL and CUDA and heteregenous many-core systems ######################################## Python It is always preferred to use pacman to install software. If you must use pip, use a virtual environment or with \"pip install --user\" to avoid conflicting with packages in /usr. pacman -S python # Install Python 3 pacman -S jupyter-notebook # Jupyter: Python notebooks pacman -S python-numpy # Numpy: Matrix manipulation pacman -S python-scipy # Scipy: Scientific library for Python. Sparse matrices support pacman -S python-pandas # Pandas: Deal with data pacman -S python-scikit-learn # Scikit-learn: Machine learning pacman -S python-matplotlib # Matplotlib: Visualization pacman -S python-seaborn # Seaborn: Visualization pacman -S python-nltk # NLTK: Natural language processing in Python pacman -S python-pip # The PyPA recommended tool for installing Python packages pacman -S gtkglext # opengl extensions for gtk2 (necesario para opencv) pacman -S opencv opencv-samples # Open Source Computer Vision Library pacman -S graphviz # Graph visualization software pacman -S hdf5 # General purpose library and file format for storing scientific data pip install --user bcolz pip install --user graphviz # Interface for python pip install --user sklearn-pandas pip install --user isoweek AUR: python-numba ######################################## Deep larining frameworks pacman -S python-pytorch-cuda # Pytorch pacman -S python-tensorflow-opt-cuda # Tensorflow pacman -S tensorflow-opt-cuda # Tensorflow pacman -S tensorboard # Tensorboard AUR: python-torchvision AUR: python-keras # Keras API for Tensorflow AUR: python-theano AUR: caffe AUR: mxnet # MXNet: Apache DL AUR: cntk # CNTK: Microsoft DL Nervana Neon, Chainer, DyNet, MinPy ######################################## Other packages # Monitoring htop - Monitor CPU, RAM, load, kill programs nvidia-smi - Monitor Nvidia GPU CSV manipulation xsv - The fastest, multi-processing CSV library. Written in Rust. Rapid Development, Research Jupyter - Code Python, R, Haskell, Julia with direct feedback in your browser jupyter_contrib_nbextensions - Extensions for jupyter (commenting code, ...)","title":"Install [Manjaro](https://manjaro.org/download)"},{"location":"others/install_arch_linux/#install-manjaro","text":"Entra en la Bios (tecla ?) y detecta tu sistema | Bios (or Legacy) | UEFI | |-------------------------|----------------------------| | MRB (Master Boot Rcord) | GPT (GUID Partition Table) | | Antiguo | Nuevo | [ ] Enable UEFI [ ] Disable Secure Boot [ ] Disable Fast Boot Inserta USB de Manjaro con el PC apagado Elije partici\u00f3n de arraque al encender (tecla F12) Y elije arrancar desde USB en modo UEFI Selecciona el Driver : free : Si no tienes GPU nonfree : Si tienes GPU Nvidia (o AMD) Particiones Size Type File system Mount point Flags Partici\u00f3n de arranque 100 MB GPT fat32 /boot/efi boot, esp Partici\u00f3n SWAP (opcional) 16 GB GPT linuxswap swap Partici\u00f3n para Manjaro Resto GPT ext4 / root","title":"Install Manjaro"},{"location":"others/install_arch_linux/#iso-image-to-usb","text":"sudo fdisk -l buscar localizaci\u00f3n del USB (sdb, sdc, etc.). sudo dd bs=4M if=/path/to/downloaded/iso of=/dev/sdx status=progress oflag=sync Copiar (reemplazar sdx por la correcta ubicaci\u00f3n). # HARDWARE # Processor x86_64 # Min RAM: 512 MB RAM # Min Space: 800 MB # SOFTWARE # User: root # Shell: zsh # Editors: nano vi vim ################################################ ######## ON WORKING COMPUTER ######## ################################################ # 1. Download iso # 2. Identify USB pen lsblk fdisk -l # 3. Copy iso to pendrive dd if=Downloads/archlinux.iso of=/dev/sdb status=\"progress\" # very careful with correct \"of\" dd bs=4M if=/path/to/antergos-x86_64.iso of=/dev/sdX status=progress && sync ################################################ ######## PRE-INTALLATION ######## ################################################ ########################################## Keyboard and font ls /usr/share/kbd/keymaps/**/*.map.gz # OPTIONAL List available keyboards loadkeys es # Set spanish keyboard ls /usr/share/kbd/consolefonts/ # OPTIONAL See fonts setfont # OPTIONAL Set font ########################################## Verify Boot mode # TODO: UEFI vs BIOS # Mejor usar BIOS # UEFI activated if the directory exists. ls /sys/firmware/efi/efivars # If the directory does not exist, the system may be booted in BIOS ########################################## Connect to the Internet # dhcpcd is activated. Check connection with ping ping archlinux.org ########################################## Update the system clock # Ensure the system clock is accurate timedatectl set-ntp true ########################################## Partition # 1) Identify disks lsblk # Option 1 fdisk -l # Option 2 # 2) Particionate a disk (sda, sdb, ...) # 4 needed partitions: # sda 256G # \u251c\u2500sda1 /boot/efi 200..512 = 256M # \u251c\u2500sda2 [SWAP] 16..32 = 32G # \u251c\u2500sda3 / 25..32 = 32G # \u2514\u2500sda4 /home rest # # sda 256G # \u251c\u2500sda1 /boot 200..512 = 256M # \u251c\u2500sda2 [SWAP] 16..32 = 32G # \u251c\u2500sda3 / 25..32 = 32G # \u2514\u2500sda4 /home rest fdisk /dev/sda # Option 1 m # Help p # Print status d # Delete current partitons n # Create new partition: Boot (200MB) # type: default (primary) # number: default (1) # fisrt sector: default # last sector: +200M # Remove signature: Yes # repeat for rest w # Write changes parted /dev/sda # Option 2 mklabel gpt mkpart ESP fat32 1MiB 513MiB set 1 boot on mkpart primary linux-swap 513MiB 4.5GiB mkpart primary ext4 4.5GiB 100% # 3) Format partitions mkfs.ext4 /dev/sda1 # Boot mkswap /dev/sda2 # Swap swapon /dev/sda2 # Swap mkfs.ext4 /dev/sda3 # Root mkfs.ext4 /dev/sda4 # Home # 4) Mount mount /dev/sda3 /mnt # Mount root mkdir /mnt/boot # Mount boot mount /dev/sda1 /mnt/boot # Mount boot mkdir /mnt/home # Mount home mount /dev/sda4 /mnt/home # Mount home ################################################ ######## INTALLATION ######## ################################################ ########################################## Install base packages pacstrap /mnt base base-devel ########################################## Generate /est/fstab file genfstab -U /mnt >> /mnt/etc/fstab ########################################## Bootable # Enter the system # Command line from pendrive to my system arch-chroot /mnt ########################################## Time zone ln -sf /usr/share/zoneinfo/Europe/Madrid /etc/localtime hwclock --systohc ########################################## System language # Set the system language nano /etc/locale.gen # Uncomment en_US.UTF-8 UTF-8 locale-gen nano /etc/locale.conf # (new file) # LANG=es_ES.UTF-8 # LANG=en_US.UTF-8 ########################################## Keyboard nano /etc/vconsole.conf # KEYMAP=es ########################################## Hostname nano /etc/hostname # (new file) # pc nano /etc/hosts # (separate with tabs) # 127.0.0.1 localhost.localdomain localhost # ::1 localhost.localdomain localhost # 127.0.1.1 pc.localdomain pc ########################################## Network config pacman -S networkmanager # install systemctl enable NetworkManager # Start on boot ########################################## Root pass passwd ########################################## Boot loader pacman -S grub intel-ucode # OPTION A: Install grub (for BIOS) grub-install /dev/sda # OPTION B: Install grub (for UEFI) grub-install --target=x86_64-efi --efi-directory=boot --bootloader-id=GRUB grub-install --target=x86_64-efi --efi-directory=boot/efi --bootloader-id=GRUB # Config. (Microcode updates will be added automatically) grub-mkconfig -o /boot/grub/grub.cfg ########################################## Reboot exit umount -R /mnt reboot # login: root # enter password ################################################ ######## POST-INTALLATION ######## ################################################ Read https://wiki.archlinux.org/index.php/General_recommendations editar /etc/pacman.conf para activar el repositorio [community] ########################################## Add user #useradd -m -g wheel -s /bin/bash javi useradd --create-home --gid wheel --shell /bin/bash javi passwd javi ########################################## Trim support for SSD # https://wiki.archlinux.org/index.php/Solid_State_Drive#TRIM lsblk -D # Verify trim support # disc-gran/disc-max should not be empty if enabled # The util-linux package provides fstrim.service and fstrim.timer # Enabling the timer will activate the service weekly systemctl start fstrim.timer systemctl enable fstrim.timer ########################################## Install LTS Kernel # https://youtu.be/b-H3jURTgqk uname -r # Check your current kernel sudo pacman -S linux-lts # Install LTS kernel pacman -R linux # [OPTIONAL] Remove the standard kernel grub-mkconfig -o /boot/grub/grub.cfg # Reconfigure GRUB sudo pacman -S linux-lts-headers # Install LTS headers sudo reboot # Reboot uname -r # Check new current kernel # Note, for syslinux you'll need to edit the syslinux config file in /boot/syslinux/syslinux.cfg accordingly, # just point everything to the -lts kernel. ########################################## Install microcode (for Intel) sudo pacman -S intel-ucode # Install microcode grub-mkconfig -o /boot/grub/grub.cfg # Reconfigure GRUB ########################################## Disable GRUB delay # Add the following to /etc/default/grub: # achieve the fastest possible boot: GRUB_FORCE_HIDDEN_MENU=\"true\" # Then put file 31_hold_shift to /etc/grub.d/. # Download 31_hold_shift https://goo.gl/nac6Kp # Make it executable, and regenerate the grub configuration: sudo chmod a+x /etc/grub.d/31_hold_shift sudo grub-mkconfig -o /boot/grub/grub.cfg ########################################## Install key packages sudo pacman -S adobe-source-sans-pro-fonts aspell-en enchant gst-libav gst-plugins-good \\ hunspell-en icedtea-web jre8-openjdk languagetool libmythes mythes-en pkgstats \\ ttf-anonymous-pro ttf-bitstream-vera ttf-dejavu ttf-droid ttf-gentium ttf-liberation ttf-ubuntu-font-family ########################################## Firewall # iptables is already installed. I like ufw. pacman -S ufw # Install ufw ufw enable # Enable it only once, when package is installed ufw status verbose # Check its status systemctl start ufw # Start the firewall systemctl enable ufw # Enable the start-up with the system [option a] systemctl enable ufw.service # Enable the start-up with the system [option b] ########################################## Encrypt your home directory ########################################## Optimize pacman's database access speeds sudo pacman-optimize ########################################## Check for errors sudo systemctl --failed sudo journalctl -p 3 -xb ########################################## Backup the system sudo rsync -aAXvP --delete --exclude=/dev/* --exclude=/proc/* --exclude=/sys/* --exclude=/tmp/* --exclude=/run/* --exclude=/mnt/* --exclude=/media/* --exclude=/lost+found --exclude=/home/.ecryptfs / /mnt/backupDestination/ ################################################ ######## GRAPHICAL ENVIROMENT ######## ################################################ If you want to use the latest nvidia drivers in the official repository, you can choose libglvnd (and not nvidia-304xx-utils). ########################################## Xorg pacman -S xorg-server xorg-xinit pacman -S xterm # Necessary?? # It will read from ~/.xinitrc to know what to start nano ~/.xinitrc exec i3 # You can start X by running: xinit startx ENTER ENTER ########################################## Display manager (login screen) # Terminal login screen: # nano ~/.profile ~/.bash_profile if [[ \"$(tty)\" == '/dev/tty1' ]]; then exec startx fi # or use a Display manager (login screen) pacman -S lightdb lightdm-gtk-greeter systemctl enable lightdm.service ########################################## Colors # Colors in terminal for bash, pacman and nano # https://youtu.be/giAb4Ckh8BQ # Install i3 window manager pacman -S i3-gaps i3status rxvt-unicode dmenu # Other things needed for a wm nano ~/.xinitrc # exec i3 # Fonts pacman -S ttf-linux-libertine ttf-inconsolata # Or just pacman -S noto-fonts # Manually edit ~/.config/fontconfig/fonts.conf ################################################ ######## DEEP LEARNING SETUP ######## ################################################ # READ https://www.hackster.io/Ladvien/gpu-accelerated-deep-learning-environment-on-arch-linux-16631b dialog --backtitle \"Deep learning with Arch linux\"\\ --title \"Welcome!\"\\ --msgbox \"\\nThis is the configuration to make your perfect linux distro.\"\\ 8 40 dialog --backtitle \"CPU Selection\" \\ --radiolist \"Select CPU type:\" 10 40 4 \\ 1 386SX off \\ 2 386DX on \\ 3 486SX off \\ 4 486DX off ########################################## Nvidia drivers # Identify your card lspci | grep -i nvidia lspci | grep -e VGA -e 3D lspci -k | grep -A 2 -i \"VGA\" # Install drivers and driver's utils pacman -S nvidia # Nvidia drivers pacman -S nvidia-utils # Nvidia driver's utils reboot ######################################## GPU computation pacman -S cuda # Nvidia API for GPGPU pacman -S cudnn # Nvidia primitives for Neural Networks #Magma # Linear Algebra for OpenCL and CUDA and heteregenous many-core systems ######################################## Python It is always preferred to use pacman to install software. If you must use pip, use a virtual environment or with \"pip install --user\" to avoid conflicting with packages in /usr. pacman -S python # Install Python 3 pacman -S jupyter-notebook # Jupyter: Python notebooks pacman -S python-numpy # Numpy: Matrix manipulation pacman -S python-scipy # Scipy: Scientific library for Python. Sparse matrices support pacman -S python-pandas # Pandas: Deal with data pacman -S python-scikit-learn # Scikit-learn: Machine learning pacman -S python-matplotlib # Matplotlib: Visualization pacman -S python-seaborn # Seaborn: Visualization pacman -S python-nltk # NLTK: Natural language processing in Python pacman -S python-pip # The PyPA recommended tool for installing Python packages pacman -S gtkglext # opengl extensions for gtk2 (necesario para opencv) pacman -S opencv opencv-samples # Open Source Computer Vision Library pacman -S graphviz # Graph visualization software pacman -S hdf5 # General purpose library and file format for storing scientific data pip install --user bcolz pip install --user graphviz # Interface for python pip install --user sklearn-pandas pip install --user isoweek AUR: python-numba ######################################## Deep larining frameworks pacman -S python-pytorch-cuda # Pytorch pacman -S python-tensorflow-opt-cuda # Tensorflow pacman -S tensorflow-opt-cuda # Tensorflow pacman -S tensorboard # Tensorboard AUR: python-torchvision AUR: python-keras # Keras API for Tensorflow AUR: python-theano AUR: caffe AUR: mxnet # MXNet: Apache DL AUR: cntk # CNTK: Microsoft DL Nervana Neon, Chainer, DyNet, MinPy ######################################## Other packages # Monitoring htop - Monitor CPU, RAM, load, kill programs nvidia-smi - Monitor Nvidia GPU CSV manipulation xsv - The fastest, multi-processing CSV library. Written in Rust. Rapid Development, Research Jupyter - Code Python, R, Haskell, Julia with direct feedback in your browser jupyter_contrib_nbextensions - Extensions for jupyter (commenting code, ...)","title":"iso image to USB"},{"location":"others/linux_insides/","text":"Linux insides Kernel Xanmod File system BTRFS Recomendado por andres torrubia... ...No por prestaciones, lo ha elegido por funcionalidad Copias autoam\u00e1ticas (equvalente a la Time Machine de apple) Con snapper que es un sofware que va por encima, tienes facilmente recuperable como estaba tu ordenador hace 1 hora, hace 1 dia, ... te salva la vida cuando borras datos por accidente sucesor natural del sistema de archivos EXT4 menos velocidad de lectura y escritura que EXT4 ZFS Recomendado por profe ASORC carrera informatica Sistema por defecto de freeBSD Puedes meter y quitar Discos ampliando o reduciendo el espacio (y el logical volume y ZFS se adapta) ASi que va bien para tener hot-swapable disks Es sin\u00f3nimo de escalabilidad Desventaja: consumo alto de memoria RAM EXT4 Mas comun en linux. Tambien es rapido (mas que btrfs) XFS Tambien es rapido copy-on-write (COW) mechanism: when you modify a file, the file system won\u2019t overwrite the existing data on the drive. Instead, the newer data is written elsewhere. Once the write operation is over, the file system simply points to the newer data blocks. - Ventaja: asegurar la integridad de los archivos en caso de corte el\u00e9ctrico. - Desventaja: una alta fragmentaci\u00f3n, journaling (mejora la integridad del sistema de archivos), por lo que no deber\u00edas tener p\u00e9rdida de datos en caso de corte de alimentaci\u00f3n Asegurar integridad How to Scalable for en caso de corte corr RAID? hot-swap disks EXT4 journaling need to format no BTRFS copy-on-write ZFS copy-on-write pool of vdevs vdevs == Virtual DEVice. A pool is made up of vdevs. A vdev is made up of physical devices. Let's say you have 12 physical disks. You might have a pool consisting of 6 mirrors. Each two disk mirror is a vdev. So your pool has 6 vdevs. Optimizacion trick 1: Desactivar el atributo atime El atributo atime (access time) es recopilado y actualizado cada vez que el usuario lee o modifica un determinado archivo. En total, se recogen 3 atributos: Access: la \u00faltima vez que el archivo fue le\u00eddo Modify: la \u00faltima vez que el archivo fue modificado (su contenido) Change: la \u00faltima vez que los meta-datos del archivo fueron modificados (permisos, nombre, propietario, etc) Mediante noatime desactivamos esta funcionalidad y ganamos algo de velocidad al leer y escribira archivos. https://markmcb.com/2020/01/07/five-years-of-btrfs/ https://carfax.org.uk/btrfs-usage/ https://www.linuxjournal.com/content/hot-swappable-filesystems-smooth-btrfs https://www.salvagedata.com/btrfs-zfs-xfs-ext4-how-are-they-different Notes on exFAT and Reliability I/O schedulers https://wiki.archlinux.org/title/improving_performance https://wiki.ubuntu.com/Kernel/Reference/IOSchedulers https://community.clearlinux.org/t/arch-linux-outperforms-clear-linux/5462 https://clearlinux.org/","title":"Linux insides"},{"location":"others/linux_insides/#linux-insides","text":"","title":"Linux insides"},{"location":"others/linux_insides/#kernel","text":"Xanmod","title":"Kernel"},{"location":"others/linux_insides/#file-system","text":"","title":"File system"},{"location":"others/linux_insides/#btrfs","text":"Recomendado por andres torrubia... ...No por prestaciones, lo ha elegido por funcionalidad Copias autoam\u00e1ticas (equvalente a la Time Machine de apple) Con snapper que es un sofware que va por encima, tienes facilmente recuperable como estaba tu ordenador hace 1 hora, hace 1 dia, ... te salva la vida cuando borras datos por accidente sucesor natural del sistema de archivos EXT4 menos velocidad de lectura y escritura que EXT4","title":"BTRFS"},{"location":"others/linux_insides/#zfs","text":"Recomendado por profe ASORC carrera informatica Sistema por defecto de freeBSD Puedes meter y quitar Discos ampliando o reduciendo el espacio (y el logical volume y ZFS se adapta) ASi que va bien para tener hot-swapable disks Es sin\u00f3nimo de escalabilidad Desventaja: consumo alto de memoria RAM","title":"ZFS"},{"location":"others/linux_insides/#ext4","text":"Mas comun en linux. Tambien es rapido (mas que btrfs)","title":"EXT4"},{"location":"others/linux_insides/#xfs","text":"Tambien es rapido copy-on-write (COW) mechanism: when you modify a file, the file system won\u2019t overwrite the existing data on the drive. Instead, the newer data is written elsewhere. Once the write operation is over, the file system simply points to the newer data blocks. - Ventaja: asegurar la integridad de los archivos en caso de corte el\u00e9ctrico. - Desventaja: una alta fragmentaci\u00f3n, journaling (mejora la integridad del sistema de archivos), por lo que no deber\u00edas tener p\u00e9rdida de datos en caso de corte de alimentaci\u00f3n Asegurar integridad How to Scalable for en caso de corte corr RAID? hot-swap disks EXT4 journaling need to format no BTRFS copy-on-write ZFS copy-on-write pool of vdevs vdevs == Virtual DEVice. A pool is made up of vdevs. A vdev is made up of physical devices. Let's say you have 12 physical disks. You might have a pool consisting of 6 mirrors. Each two disk mirror is a vdev. So your pool has 6 vdevs.","title":"XFS"},{"location":"others/linux_insides/#optimizacion-trick-1-desactivar-el-atributo-atime","text":"El atributo atime (access time) es recopilado y actualizado cada vez que el usuario lee o modifica un determinado archivo. En total, se recogen 3 atributos: Access: la \u00faltima vez que el archivo fue le\u00eddo Modify: la \u00faltima vez que el archivo fue modificado (su contenido) Change: la \u00faltima vez que los meta-datos del archivo fueron modificados (permisos, nombre, propietario, etc) Mediante noatime desactivamos esta funcionalidad y ganamos algo de velocidad al leer y escribira archivos. https://markmcb.com/2020/01/07/five-years-of-btrfs/ https://carfax.org.uk/btrfs-usage/ https://www.linuxjournal.com/content/hot-swappable-filesystems-smooth-btrfs https://www.salvagedata.com/btrfs-zfs-xfs-ext4-how-are-they-different Notes on exFAT and Reliability","title":"Optimizacion trick 1: Desactivar el atributo atime"},{"location":"others/linux_insides/#io-schedulers","text":"https://wiki.archlinux.org/title/improving_performance https://wiki.ubuntu.com/Kernel/Reference/IOSchedulers https://community.clearlinux.org/t/arch-linux-outperforms-clear-linux/5462 https://clearlinux.org/","title":"I/O schedulers"},{"location":"others/maintenance/","text":"System maintenance Check for errors sudo systemctl --failed # Check if any systemd services have entered in a failed state. sudo journalctl -p 3 -xb # Look for errors in the log files located at /var/log Backup ... Upgrading the system Check news pacman -Syu # Update packages and system If the system has packages from the AUR, carefully upgrade all of them. Clean the filesystem Disk usage display Find largest files and directories. sudo pacman -S ncdu # Intall ncdu Filelight is a GUI program Baobab is other GUI program (gnome) Disk cleaning programs Find and remove: duplicates empty files empty directories broken symlinks. sudo pacman -S rmlint # Intall rmlint BleachBit is a GUI program Package cache Remove unwanted .pkg files from /var/cache/pacman/pkg/ to free up disk space. ls /var/cache/pacman/pkg/ | less # Ver paquetes (diponibles?) du -sh /var/cache/pacman/pkg/ # Ver tama\u00f1o carpeta sudo pacman -Sc # Remove old and unused pkgs sudo pacman -Scc # Remove files from cache paccache # ??? Unused packges (orphans) sudo pacman -Qtdq # List orphans sudo pacman -Rns $(pacman -Qtdq) # Remove orphans and their configuration files Clean cache in your /home. du -sh ~/.cache/ # Ver tama\u00f1o carpeta rm -rf ~/.cache/* # Remove Old config files ~/.config/ : where apps stores their configuration ~/.cache/ : cache of some programs may grow in size ~/.local/share/ : old files may be lying there Broken symlinks find -xtype l -print # List all the broken symlinks","title":"[System maintenance](https://wiki.archlinux.org/index.php/System_maintenance)"},{"location":"others/maintenance/#system-maintenance","text":"","title":"System maintenance"},{"location":"others/maintenance/#check-for-errors","text":"sudo systemctl --failed # Check if any systemd services have entered in a failed state. sudo journalctl -p 3 -xb # Look for errors in the log files located at /var/log","title":"Check for errors"},{"location":"others/maintenance/#backup","text":"...","title":"Backup"},{"location":"others/maintenance/#upgrading-the-system","text":"Check news pacman -Syu # Update packages and system If the system has packages from the AUR, carefully upgrade all of them.","title":"Upgrading the system"},{"location":"others/maintenance/#clean-the-filesystem","text":"","title":"Clean the filesystem"},{"location":"others/maintenance/#disk-usage-display","text":"Find largest files and directories. sudo pacman -S ncdu # Intall ncdu Filelight is a GUI program Baobab is other GUI program (gnome)","title":"Disk usage display"},{"location":"others/maintenance/#disk-cleaning-programs","text":"Find and remove: duplicates empty files empty directories broken symlinks. sudo pacman -S rmlint # Intall rmlint BleachBit is a GUI program","title":"Disk cleaning programs"},{"location":"others/maintenance/#package-cache","text":"Remove unwanted .pkg files from /var/cache/pacman/pkg/ to free up disk space. ls /var/cache/pacman/pkg/ | less # Ver paquetes (diponibles?) du -sh /var/cache/pacman/pkg/ # Ver tama\u00f1o carpeta sudo pacman -Sc # Remove old and unused pkgs sudo pacman -Scc # Remove files from cache paccache # ???","title":"Package cache"},{"location":"others/maintenance/#unused-packges-orphans","text":"sudo pacman -Qtdq # List orphans sudo pacman -Rns $(pacman -Qtdq) # Remove orphans and their configuration files","title":"Unused packges (orphans)"},{"location":"others/maintenance/#clean-cache-in-your-home","text":"du -sh ~/.cache/ # Ver tama\u00f1o carpeta rm -rf ~/.cache/* # Remove","title":"Clean cache in your /home."},{"location":"others/maintenance/#old-config-files","text":"~/.config/ : where apps stores their configuration ~/.cache/ : cache of some programs may grow in size ~/.local/share/ : old files may be lying there","title":"Old config files"},{"location":"others/maintenance/#broken-symlinks","text":"find -xtype l -print # List all the broken symlinks","title":"Broken symlinks"},{"location":"others/public_ip/","text":"Public IP How to get a reachable IP on the internet. Problem 1: Static IP THere are not enough IPv4 adresses for everyone in the world so your ISP (Internet Service Provider) probably has given you a dynamic IP adress instead of an static IP adress . Solution: OPTION 1) You can ask for you ISP to give a static IP adress . OPTION 2) You can use noip which track your current ip Wen you sign up, you pick a free domain name and automaticlly detect your external IP In order to detect changes of your IOP, you need to install the noip software on the server. Problem 2: you router need to allow oustside traffic to get in to your network. Open up port 80 on the router (this is port forawrding) https://www.youtube.com/watch?v=ZlYyiuBc8Mc Ojo que el ISP tiene un servidor ACS que controla todos sus routers VPN","title":"Public IP"},{"location":"others/public_ip/#public-ip","text":"How to get a reachable IP on the internet.","title":"Public IP"},{"location":"others/public_ip/#problem-1-static-ip","text":"THere are not enough IPv4 adresses for everyone in the world so your ISP (Internet Service Provider) probably has given you a dynamic IP adress instead of an static IP adress . Solution: OPTION 1) You can ask for you ISP to give a static IP adress . OPTION 2) You can use noip which track your current ip Wen you sign up, you pick a free domain name and automaticlly detect your external IP In order to detect changes of your IOP, you need to install the noip software on the server.","title":"Problem 1: Static IP"},{"location":"others/public_ip/#problem-2-you-router-need-to-allow-oustside-traffic-to-get-in-to-your-network","text":"Open up port 80 on the router (this is port forawrding) https://www.youtube.com/watch?v=ZlYyiuBc8Mc Ojo que el ISP tiene un servidor ACS que controla todos sus routers","title":"Problem 2: you router need to allow oustside traffic to get in to your network."},{"location":"others/public_ip/#vpn","text":"","title":"VPN"},{"location":"others/remote_administration/","text":"Remote administration in-band management (OS level) (the usual network channel) SSH, sftp, scp (port 22) Telnet (port 23) Remote desktop VNC (port 5900) RDP (port 3389) FreeNX TeamViewer IPSec Out-of-band management (BIOS level) (dedicated Ethernet port) Advantages Reboot, Shutdown, Powering on Accesing the bios configuration broadcasting of video and receiving of input from remote keyboard and mouse (KVM over IP) (HDBaseT) Hardware sensor monitoring (fan speed, temeratures, voltages, chassis intrusion, etc.) Hardware inventory Hardware failure detection Reinstall the operating system Configure harware RAID Technologies IPMI: standard (a bit old) Redfish: standard (new, using HTTPS & JSON) DRAC: proprietary from Dell ILO: proprietary from HP ILOM: proprietary from Sun/Oracle IMM: proprietary from IBM Security Bear in mind that many of these built-in systems have been found to suffer from traditional security holes, such as buffer overruns. It is not wise to assume that setting a password on the OOB interface and using SSL is sufficient protection for such access to your servers. Assume that access to the OOB interface is equivalent to physical access to the machine, and establish additional security measures accordingly. For example, put OOB interfaces on a dedicated protected network. Allow access to this network only via a web proxy with certificate-based authentication, and appropriate authorization. Redfish curl https://<OOB>/redfish/v1/Systems/System.Embedded.1 --user root:password | jq .Status # { # \"Health\": \"Ok\", # \"HealthRollUp\": \"Ok\", # } curl https://<OOB>/redfish/v1/Systems/System.Embedded.1/Thermal --user root:password curl https://<OOB>/redfish/v1/Systems/System.Embedded.1/Thermal --user root:password https://www.youtube.com/watch?v=9tAXBvuyXJU Wake on LAN On the server ip link to find informatio about available network cards find the name og the ethernet enterface (eg. enp0s31f6 ) find the mac address (eg. e0:............) sudo ethtool enp0s31f6 | grep Wake-on Check that is on On the client Find the server mac address: arp -a Wake the server wakeonlan *mac address* shutdown shutdown now Reboot reboot now","title":"Remote administration"},{"location":"others/remote_administration/#remote-administration","text":"","title":"Remote administration"},{"location":"others/remote_administration/#in-band-management-os-level-the-usual-network-channel","text":"SSH, sftp, scp (port 22) Telnet (port 23) Remote desktop VNC (port 5900) RDP (port 3389) FreeNX TeamViewer IPSec","title":"in-band management (OS level) (the usual network channel)"},{"location":"others/remote_administration/#out-of-band-management-bios-level-dedicated-ethernet-port","text":"","title":"Out-of-band management (BIOS level) (dedicated Ethernet port)"},{"location":"others/remote_administration/#advantages","text":"Reboot, Shutdown, Powering on Accesing the bios configuration broadcasting of video and receiving of input from remote keyboard and mouse (KVM over IP) (HDBaseT) Hardware sensor monitoring (fan speed, temeratures, voltages, chassis intrusion, etc.) Hardware inventory Hardware failure detection Reinstall the operating system Configure harware RAID","title":"Advantages"},{"location":"others/remote_administration/#technologies","text":"IPMI: standard (a bit old) Redfish: standard (new, using HTTPS & JSON) DRAC: proprietary from Dell ILO: proprietary from HP ILOM: proprietary from Sun/Oracle IMM: proprietary from IBM","title":"Technologies"},{"location":"others/remote_administration/#security","text":"Bear in mind that many of these built-in systems have been found to suffer from traditional security holes, such as buffer overruns. It is not wise to assume that setting a password on the OOB interface and using SSL is sufficient protection for such access to your servers. Assume that access to the OOB interface is equivalent to physical access to the machine, and establish additional security measures accordingly. For example, put OOB interfaces on a dedicated protected network. Allow access to this network only via a web proxy with certificate-based authentication, and appropriate authorization.","title":"Security"},{"location":"others/remote_administration/#redfish","text":"curl https://<OOB>/redfish/v1/Systems/System.Embedded.1 --user root:password | jq .Status # { # \"Health\": \"Ok\", # \"HealthRollUp\": \"Ok\", # } curl https://<OOB>/redfish/v1/Systems/System.Embedded.1/Thermal --user root:password curl https://<OOB>/redfish/v1/Systems/System.Embedded.1/Thermal --user root:password https://www.youtube.com/watch?v=9tAXBvuyXJU","title":"Redfish"},{"location":"others/remote_administration/#wake-on-lan","text":"On the server ip link to find informatio about available network cards find the name og the ethernet enterface (eg. enp0s31f6 ) find the mac address (eg. e0:............) sudo ethtool enp0s31f6 | grep Wake-on Check that is on On the client Find the server mac address: arp -a Wake the server wakeonlan *mac address*","title":"Wake on LAN"},{"location":"others/remote_administration/#shutdown","text":"shutdown now","title":"shutdown"},{"location":"others/remote_administration/#reboot","text":"reboot now","title":"Reboot"},{"location":"others/server_db/","text":"MySQL PostgreSQL Oracle Express (data through http)","title":"Server db"},{"location":"others/server_dhcp/","text":"DHCP Server Provides IP dynamic adresses to clients in a network. (assignment by MAC)","title":"DHCP Server"},{"location":"others/server_dhcp/#dhcp-server","text":"Provides IP dynamic adresses to clients in a network. (assignment by MAC)","title":"DHCP Server"},{"location":"others/server_files/","text":"FTP (Serv-U, vsftp, proftpd) NFS SAMBA / SMB (LDAP) iSCSI FreeNAS OwnCloud With FTP and SMB (or NFS) you access files, while iSCSI is a block device protocol.","title":"Server files"},{"location":"others/server_mail/","text":"Dovecot Postfix + MySQL + amavis + spamassassin sendmail + clamav + MailScanner + spamasasin Merak WebMail","title":"Server mail"},{"location":"others/server_messaging/","text":"\u2022 Mensajer\u00eda instant\u00e1nea XMPP Jabber","title":"Server messaging"},{"location":"others/server_printer/","text":"Print server CUPS","title":"Print server"},{"location":"others/server_printer/#print-server","text":"CUPS","title":"Print server"},{"location":"others/server_users/","text":"File servers generally offer some form of system security to limit access to files to specific users or groups. In large organizations, this is a task usually delegated to directory services, such as openLDAP, Novell's eDirectory or Microsoft's Active Directory. Directory Server (user permission to directories) OpenLDAP Microsoft's Active Directory Fedora Directory Server User Management Local NIS LDAP Servidor de terminales de usuario LTSP PXE DRBL Servidor de trabajo en grupo Zimbra OpenXchange Opengroupware Microsoft Exchange Proxy Cache (Squid): Restricci\u00f3n de contenidos, p\u00e1ginas, usuarios, autenticaci\u00f3n LDAP.","title":"Server users"},{"location":"programming/debugging/","text":"Debugging Debugging in Python: print() : too simple import pdb; pdb.set_trace() : too complex import code; code.interact(local=locals()) : just right simply drops you into interpreter, perfect for 95% of debugging https://twitter.com/karpathy/status/1610822271157022720 Python debugging: ipdb Start the debugger: - python -m pdb my_program.py - python -m ipdb my_program.py Debugger commands: - s : step - c : countiue until ends or break - p var1 : print value of var1 - p var1,var2 : print value of var1 and var2 - p locals() : print value of all vars - l : list code and see lines - b 6 : create a break point at line 6 - q : Quit the debugger C/C++ debugging gdb","title":"Debugging"},{"location":"programming/debugging/#debugging","text":"","title":"Debugging"},{"location":"programming/debugging/#debugging-in-python","text":"print() : too simple import pdb; pdb.set_trace() : too complex import code; code.interact(local=locals()) : just right simply drops you into interpreter, perfect for 95% of debugging https://twitter.com/karpathy/status/1610822271157022720","title":"Debugging in Python:"},{"location":"programming/debugging/#python-debugging-ipdb","text":"Start the debugger: - python -m pdb my_program.py - python -m ipdb my_program.py Debugger commands: - s : step - c : countiue until ends or break - p var1 : print value of var1 - p var1,var2 : print value of var1 and var2 - p locals() : print value of all vars - l : list code and see lines - b 6 : create a break point at line 6 - q : Quit the debugger","title":"Python debugging: ipdb"},{"location":"programming/debugging/#cc-debugging","text":"gdb","title":"C/C++ debugging"},{"location":"programming/makefile/","text":"Makefile Makefile file: TargetFile: DepencyFile1, DepencyFile2 command1 command2 Latex example Makefile paper.pdf: paper.tex plot-data.png pdflatex paper.tex plot-%.png: %.dat plot.py ./plot.py -i $*.dat -o $@ Run it with make If the DepencyFiles has not changed, the commands for TargetFile will not be executed.","title":"Makefile"},{"location":"programming/makefile/#makefile","text":"","title":"Makefile"},{"location":"programming/makefile/#makefile-file","text":"TargetFile: DepencyFile1, DepencyFile2 command1 command2","title":"Makefile file:"},{"location":"programming/makefile/#latex-example-makefile","text":"paper.pdf: paper.tex plot-data.png pdflatex paper.tex plot-%.png: %.dat plot.py ./plot.py -i $*.dat -o $@","title":"Latex example Makefile"},{"location":"programming/makefile/#run-it-with-make","text":"If the DepencyFiles has not changed, the commands for TargetFile will not be executed.","title":"Run it with make"},{"location":"programming/profiling/","text":"Profiling The lazy way: time in python: import time start = time.time() muy_fun() # Long code here print(time.time() - start) in jupyter: %time muy_fun() %timeit -r 2 -n 5 muy_fun() # -r: number of runs, -n: number of loops On the shell: $ time some_command - real : Real time. Other programs or internet connection affect. - user : User time. Amount of time spent in the CPU running user code - sys : Syestem time. Amount of time spent in the CPU running kernel code. CPU profiler There are two main types of CPU profilers: - Tracing profilers keep a record of every function call your program makes. - No son muy fiables porque acompa\u00f1an siempre al programa y esto puede interferir en el rendimiento - Sampling profilers probe your program periodically (commonly every millisecond) and record the program\u2019s stack. Here is a good intro article if you want more detail on this topic. CPU line profilers line_profiler : pip install line-profiler pprofile : pacman -S python-pprofile import time @profile def my_fun(): time.sleep(2) for i in range(3): print(\"print\") time.sleep(1) my_fun() $ kernprof -l -v program_with_my_fun.py Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def my_fun(): 5 1 2002083.0 2002083.0 40.0 time.sleep(2) 6 4 36.0 9.0 0.0 for i in range(3): 7 3 188.0 62.7 0.0 print(\"print\") 8 3 3002333.0 1000777.7 60.0 time.sleep(1) In jupyter %load_ext line_profiler %lprun -f func_to_profile func_to_profile(params) Memory profiler Install with pip install memory-profiler or pacamn -S python-memory-profiler @profile def my_func(): a = [1] * (10 ** 6) b = [2] * (2 * 10 ** 7) del b return a my_func() $ python -m memory_profiler mem.py Line # Mem usage Increment Line Contents ================================================ 1 38.637 MiB 38.637 MiB @profile 2 def my_func(): 3 46.090 MiB 7.453 MiB a = [1] * (10 ** 6) 4 198.715 MiB 152.625 MiB b = [2] * (2 * 10 ** 7) 5 46.270 MiB 0.000 MiB del b 6 46.270 MiB 0.000 MiB return a Memray A memory profiler for Python Magic trace magic-trace collects and displays high-resolution traces of what a process is doing","title":"Profiling"},{"location":"programming/profiling/#profiling","text":"","title":"Profiling"},{"location":"programming/profiling/#the-lazy-way-time","text":"in python: import time start = time.time() muy_fun() # Long code here print(time.time() - start) in jupyter: %time muy_fun() %timeit -r 2 -n 5 muy_fun() # -r: number of runs, -n: number of loops On the shell: $ time some_command - real : Real time. Other programs or internet connection affect. - user : User time. Amount of time spent in the CPU running user code - sys : Syestem time. Amount of time spent in the CPU running kernel code.","title":"The lazy way: time"},{"location":"programming/profiling/#cpu-profiler","text":"There are two main types of CPU profilers: - Tracing profilers keep a record of every function call your program makes. - No son muy fiables porque acompa\u00f1an siempre al programa y esto puede interferir en el rendimiento - Sampling profilers probe your program periodically (commonly every millisecond) and record the program\u2019s stack. Here is a good intro article if you want more detail on this topic.","title":"CPU profiler"},{"location":"programming/profiling/#cpu-line-profilers","text":"line_profiler : pip install line-profiler pprofile : pacman -S python-pprofile import time @profile def my_fun(): time.sleep(2) for i in range(3): print(\"print\") time.sleep(1) my_fun() $ kernprof -l -v program_with_my_fun.py Line # Hits Time Per Hit % Time Line Contents ============================================================== 3 @profile 4 def my_fun(): 5 1 2002083.0 2002083.0 40.0 time.sleep(2) 6 4 36.0 9.0 0.0 for i in range(3): 7 3 188.0 62.7 0.0 print(\"print\") 8 3 3002333.0 1000777.7 60.0 time.sleep(1) In jupyter %load_ext line_profiler %lprun -f func_to_profile func_to_profile(params)","title":"CPU line profilers"},{"location":"programming/profiling/#memory-profiler","text":"Install with pip install memory-profiler or pacamn -S python-memory-profiler @profile def my_func(): a = [1] * (10 ** 6) b = [2] * (2 * 10 ** 7) del b return a my_func() $ python -m memory_profiler mem.py Line # Mem usage Increment Line Contents ================================================ 1 38.637 MiB 38.637 MiB @profile 2 def my_func(): 3 46.090 MiB 7.453 MiB a = [1] * (10 ** 6) 4 198.715 MiB 152.625 MiB b = [2] * (2 * 10 ** 7) 5 46.270 MiB 0.000 MiB del b 6 46.270 MiB 0.000 MiB return a","title":"Memory profiler"},{"location":"programming/profiling/#memray","text":"A memory profiler for Python","title":"Memray"},{"location":"programming/profiling/#magic-trace","text":"magic-trace collects and displays high-resolution traces of what a process is doing","title":"Magic trace"},{"location":"programming/python/","text":"Python Python script #!/usr/bin/python import sys for arg in reversed(sys.argv[1:]): print(arg)","title":"Python"},{"location":"programming/python/#python","text":"","title":"Python"},{"location":"programming/python/#python-script","text":"#!/usr/bin/python import sys for arg in reversed(sys.argv[1:]): print(arg)","title":"Python script"},{"location":"programming/ruby/","text":"Ruby Ruby gems are installed inside .local/share/gem/ruby/3.0.0/gems/ https://stackoverflow.com/questions/69724440/jekyll-crash-on-generation-segmentation-fault Install Jekyll (a Ruby gem) 1) On the home directory: sudo pacman -S ruby ruby-rdoc gcc make # Install the bundler gem install bundle 2) On the project directory (the one containing the Gemfile file) # install gems of the Gemfile (jekyll, ...) bundle install # Lauch page locally bundle exec jekyll serve --livereload bundle exec jekyll serve --livereload --watch --baseurl \"\" --trace`","title":"\u2666\ufe0f Ruby"},{"location":"programming/ruby/#ruby","text":"Ruby gems are installed inside .local/share/gem/ruby/3.0.0/gems/ https://stackoverflow.com/questions/69724440/jekyll-crash-on-generation-segmentation-fault","title":"Ruby"},{"location":"programming/ruby/#install-jekyll-a-ruby-gem","text":"1) On the home directory: sudo pacman -S ruby ruby-rdoc gcc make # Install the bundler gem install bundle 2) On the project directory (the one containing the Gemfile file) # install gems of the Gemfile (jekyll, ...) bundle install # Lauch page locally bundle exec jekyll serve --livereload bundle exec jekyll serve --livereload --watch --baseurl \"\" --trace`","title":"Install Jekyll (a Ruby gem)"},{"location":"programming/static_analisys/","text":"Static program analisis Python pyflakes my_program.py mypy my_program.py Bash pacman -S shellcheck shellcheck yourscript https://www.shellcheck.net","title":"Static program analisis"},{"location":"programming/static_analisys/#static-program-analisis","text":"","title":"Static program analisis"},{"location":"programming/static_analisys/#python","text":"pyflakes my_program.py mypy my_program.py","title":"Python"},{"location":"programming/static_analisys/#bash","text":"pacman -S shellcheck shellcheck yourscript https://www.shellcheck.net","title":"Bash"},{"location":"python/Instance%20Segmentation/","text":"Instance Segmentation Instance segmentation is a challenging task, as it requires instance-level and pixel-wise predictions simultaneously. 3 categories: top-down, bottom-up, and single-stage methods. Top-down methods: detect-then-segment paradigm. Mask R-CNN family follow the Bottom-up methods: label-then-cluster problem. (learn per-pixel embeddings and then cluster them into instance groups) Singlestage instance segmentation framework on the top of onestage detectors. - YOLACT (Bolya et al. 2019) - CondInst (Tian, Shen, and Chen 2020) - SOLO (Wang et al. 2020b) Queries instance segmentation frameworks (DETR style) eliminating NMS postprocessing. - QueryInst (Fang et al. 2021) - SOLQ (Dong et al. 2021) However, they still need RoI cropping to separate different instances first, which may have the same limitations of the detect-then-segment pipeline. In this paper, we go for an end-to-end instance segmentation framework that neither relies on RoI cropping nor NMS post-processing","title":"Instance Segmentation"},{"location":"python/Instance%20Segmentation/#instance-segmentation","text":"Instance segmentation is a challenging task, as it requires instance-level and pixel-wise predictions simultaneously. 3 categories: top-down, bottom-up, and single-stage methods. Top-down methods: detect-then-segment paradigm. Mask R-CNN family follow the Bottom-up methods: label-then-cluster problem. (learn per-pixel embeddings and then cluster them into instance groups) Singlestage instance segmentation framework on the top of onestage detectors. - YOLACT (Bolya et al. 2019) - CondInst (Tian, Shen, and Chen 2020) - SOLO (Wang et al. 2020b) Queries instance segmentation frameworks (DETR style) eliminating NMS postprocessing. - QueryInst (Fang et al. 2021) - SOLQ (Dong et al. 2021) However, they still need RoI cropping to separate different instances first, which may have the same limitations of the detect-then-segment pipeline. In this paper, we go for an end-to-end instance segmentation framework that neither relies on RoI cropping nor NMS post-processing","title":"Instance Segmentation"},{"location":"python/deep_learning/","text":"Deep learning PRO 1. Read data from disk fast ERROR: Slow reading PIL OpenCV GOOD: Fast file reading turbojpeg: For faster VERY GOOD: Preparsear los ficheros y cargar diercamente el tensor Numpy Memmap or Torch storage FFCV Note: Buy NVMe drives and put the dataset there 2. Fast DataAug & transfoms ERROR Torchvision tranforms (based on PIL) Albumatations (based on OpenCV) GOOD Fastai agmentations (on GPU) Kornia: agmentations (on GPU) 3. Model optimizaation Quantization aware training Float16 4. Training loop optimization Composer 5. Distributed treainng (Several GPUs) Pytorch DDP : Data parallelisom DeepSpeed : : Model parallelisom FSDP References https://pytorch.org/blog/efficient-pytorch-io-library-for-large-datasets-many-files-many-gpus/ https://towardsdatascience.com/setting-a-strong-deep-learning-baseline-in-minutes-with-pytorch-c0dfe41f7d7 https://towardsdatascience.com/gpus-are-fast-datasets-are-your-bottleneck-e5ac9bf2ad27 https://towardsdatascience.com/pytorch-lightning-vs-deepspeed-vs-fsdp-vs-ffcv-vs-e0d6b2a95719 https://neptune.ai/blog/image-segmentation-tips-and-tricks-from-kaggle-competitions AVOID CUDA OUT OF MEMORY (OOM) ERROR. 5 + 1 tricks If you get a OOM error on the first batch, try... Trick Description Disadvantage 1. Smaller batch size Use Gradient Accumulation to simultate larger BS Slower training 2. Smaller input size Decrease image resolution Lower accuracy 3. Smaller model Lower accuracy 4. Half/Mixed precision Float16 instead of Float32 Lower accuracy. Training may not converge\u2026 5. Gradient checkpointing Compute some acts again instad of store them Slower training Gradient checkpointing is also known as Buffer checkpointing Gradient checkpointing reduces the model's memory cost by 60%..70% (at the cost of 25% greater training time). Extra 6th trick: Do not store the unnecesary cuda variables in the training loop. If you get a OOM error in the middle of training, you probably has an increasingly memeory leak. Delete it after the loss computation output = model(input) loss = loss_fn(output, target) del output gc.collect() Or do comoute the loss directly: loss = loss_fn(model(input), target) Operation Pytorch code GPU memory (0) Model to GPU model.cuda() model (1) Foward pass out = model(inp) model + activations + out (1) Loss func l = loss(out, tar) model + activations + out + l (1) Backward pass l.backward() model + out + l + grads (1) Optimizer step optimizer.step() model + out + l + grads + grads_mom (2) Foward pass out = model(inp) model + activations + out (2) Loss func l = loss(out, tar) model + activations + out + l (2) Backward pass l.backward() model + out + l + grads (2) Optimizer step optimizer.step() model + out + l + grads + grads_mom FAQ Why do I need to store the activations during the foward pass? Each layer with learnable parameters will need to store its input until the backward pass due to the chain rule Reference Gradient Accumulation Gradient Checkpointing 1 Gradient Checkpointing 2 Pytorch Performance Tuning Guide 7 Tips To Maximize PyTorch Performance Memory usage in Pytorch 1 Memory usage in Pytorch 2 Layer-Wise Learning Rate in PyTorch https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2022/03/29/discriminative-lr.html","title":"Deep learning PRO"},{"location":"python/deep_learning/#deep-learning-pro","text":"","title":"Deep learning PRO"},{"location":"python/deep_learning/#1-read-data-from-disk-fast","text":"ERROR: Slow reading PIL OpenCV GOOD: Fast file reading turbojpeg: For faster VERY GOOD: Preparsear los ficheros y cargar diercamente el tensor Numpy Memmap or Torch storage FFCV Note: Buy NVMe drives and put the dataset there","title":"1. Read data from disk fast"},{"location":"python/deep_learning/#2-fast-dataaug-transfoms","text":"ERROR Torchvision tranforms (based on PIL) Albumatations (based on OpenCV) GOOD Fastai agmentations (on GPU) Kornia: agmentations (on GPU)","title":"2. Fast DataAug &amp; transfoms"},{"location":"python/deep_learning/#3-model-optimizaation","text":"Quantization aware training Float16","title":"3. Model optimizaation"},{"location":"python/deep_learning/#4-training-loop-optimization","text":"Composer","title":"4. Training loop optimization"},{"location":"python/deep_learning/#5-distributed-treainng-several-gpus","text":"Pytorch DDP : Data parallelisom DeepSpeed : : Model parallelisom FSDP","title":"5. Distributed treainng (Several GPUs)"},{"location":"python/deep_learning/#references","text":"https://pytorch.org/blog/efficient-pytorch-io-library-for-large-datasets-many-files-many-gpus/ https://towardsdatascience.com/setting-a-strong-deep-learning-baseline-in-minutes-with-pytorch-c0dfe41f7d7 https://towardsdatascience.com/gpus-are-fast-datasets-are-your-bottleneck-e5ac9bf2ad27 https://towardsdatascience.com/pytorch-lightning-vs-deepspeed-vs-fsdp-vs-ffcv-vs-e0d6b2a95719 https://neptune.ai/blog/image-segmentation-tips-and-tricks-from-kaggle-competitions","title":"References"},{"location":"python/deep_learning/#avoid-cuda-out-of-memory-oom-error-5-1-tricks","text":"If you get a OOM error on the first batch, try... Trick Description Disadvantage 1. Smaller batch size Use Gradient Accumulation to simultate larger BS Slower training 2. Smaller input size Decrease image resolution Lower accuracy 3. Smaller model Lower accuracy 4. Half/Mixed precision Float16 instead of Float32 Lower accuracy. Training may not converge\u2026 5. Gradient checkpointing Compute some acts again instad of store them Slower training Gradient checkpointing is also known as Buffer checkpointing Gradient checkpointing reduces the model's memory cost by 60%..70% (at the cost of 25% greater training time).","title":"AVOID CUDA OUT OF MEMORY (OOM) ERROR. 5 + 1 tricks"},{"location":"python/deep_learning/#extra-6th-trick-do-not-store-the-unnecesary-cuda-variables-in-the-training-loop","text":"If you get a OOM error in the middle of training, you probably has an increasingly memeory leak. Delete it after the loss computation output = model(input) loss = loss_fn(output, target) del output gc.collect() Or do comoute the loss directly: loss = loss_fn(model(input), target) Operation Pytorch code GPU memory (0) Model to GPU model.cuda() model (1) Foward pass out = model(inp) model + activations + out (1) Loss func l = loss(out, tar) model + activations + out + l (1) Backward pass l.backward() model + out + l + grads (1) Optimizer step optimizer.step() model + out + l + grads + grads_mom (2) Foward pass out = model(inp) model + activations + out (2) Loss func l = loss(out, tar) model + activations + out + l (2) Backward pass l.backward() model + out + l + grads (2) Optimizer step optimizer.step() model + out + l + grads + grads_mom","title":"Extra 6th trick: Do not store the unnecesary cuda variables in the training loop."},{"location":"python/deep_learning/#faq","text":"","title":"FAQ"},{"location":"python/deep_learning/#why-do-i-need-to-store-the-activations-during-the-foward-pass","text":"Each layer with learnable parameters will need to store its input until the backward pass due to the chain rule","title":"Why do I need to store the activations during the foward pass?"},{"location":"python/deep_learning/#reference","text":"Gradient Accumulation Gradient Checkpointing 1 Gradient Checkpointing 2 Pytorch Performance Tuning Guide 7 Tips To Maximize PyTorch Performance Memory usage in Pytorch 1 Memory usage in Pytorch 2","title":"Reference"},{"location":"python/deep_learning/#layer-wise-learning-rate-in-pytorch","text":"https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2022/03/29/discriminative-lr.html","title":"Layer-Wise Learning Rate in PyTorch"},{"location":"python/dot_prod/","text":"_ _USER _ _ _ITEM ___ _ W _B _ W _B [.1 .2 .4] [.5] [.2 .3 .6] [.2] affinity = 0,1 0,2 + 0,2 0,3 + 0,4*0,6 + 0,5 + 0,2 = 1,02 affinity = (0,1+0,5) (0,2+0,2) + (0,2+0,5) (0,3+0,2) + (0,4+0,5)*(0,6+0,2) = 1,31","title":"Dot prod"},{"location":"python/io_buffering/","text":"write bufferinf .write() por defecto, sino escribe m\u00e1s de 8KB, pytohn no escribe en disco y escribe en buffering. En estos casos solo escribe realmente en dico cuando .close() o .flush() Se puede cambiar el tam\u00f1ado del bufering al abrir un file: | Filte type | buffering=-1 (defualt) | buffering=0 | buffering=1 | buffering>1 | |-------------------------------------|-------------|----------------|---------------- | Text | io.DEFAULT_BUFFER_SIZE | - | line buffering | io.DEFAULT_BUFFER_SIZE | Binary | io.DEFAULT_BUFFER_SIZE | unbuffered | - | specified buffer size Error comun: No especificar el buffering y por defecto es=-1 Esto siginififica que solo escribirar en dicso cuando halla una escritoura mayor de 8192 bytes (8KB). Por loa tanto se va llenano la memoria del buffer con escrituras peque\u00f1as (menores de 8192 bytes) y finalemnte el OS mata el proceso. https://medium.com/@bramblexu/understand-the-buffer-policy-in-python-78e91e7759ca Numpy IO Numpy Read array np.load() --> \u274c Slow np.memmap() --> \u2705 Fast np.memmap(\"matrix_Nx512_float32\", dtype='float32', mode='r').reshape((-1,512)) Numpy Write array my_file = open(filepath, mode='wb') Open file in write binary mode Write my_arr.save(my_file) \u274c Write unncesary info (type, shape) my_arr.tofile(my_file) \u2705 Always write to disk my_file.write(my_arr.tobytes()) \u2705 Only writes to disk when buffer (8KB) is full. You can force to write by calling my_file.flush() or my_file.close() List Slicing withot copy data data = b\"abcdefgh\" data_view = memoryview(data) sub_data = data_view[1:3] https://julien.danjou.info/high-performance-in-python-with-zero-copy-and-the-buffer-protocol/","title":"Io buffering"},{"location":"python/io_buffering/#write-bufferinf","text":".write() por defecto, sino escribe m\u00e1s de 8KB, pytohn no escribe en disco y escribe en buffering. En estos casos solo escribe realmente en dico cuando .close() o .flush() Se puede cambiar el tam\u00f1ado del bufering al abrir un file: | Filte type | buffering=-1 (defualt) | buffering=0 | buffering=1 | buffering>1 | |-------------------------------------|-------------|----------------|---------------- | Text | io.DEFAULT_BUFFER_SIZE | - | line buffering | io.DEFAULT_BUFFER_SIZE | Binary | io.DEFAULT_BUFFER_SIZE | unbuffered | - | specified buffer size Error comun: No especificar el buffering y por defecto es=-1 Esto siginififica que solo escribirar en dicso cuando halla una escritoura mayor de 8192 bytes (8KB). Por loa tanto se va llenano la memoria del buffer con escrituras peque\u00f1as (menores de 8192 bytes) y finalemnte el OS mata el proceso. https://medium.com/@bramblexu/understand-the-buffer-policy-in-python-78e91e7759ca","title":"write bufferinf"},{"location":"python/io_buffering/#numpy-io","text":"","title":"Numpy IO"},{"location":"python/io_buffering/#numpy-read-array","text":"np.load() --> \u274c Slow np.memmap() --> \u2705 Fast np.memmap(\"matrix_Nx512_float32\", dtype='float32', mode='r').reshape((-1,512))","title":"Numpy Read array"},{"location":"python/io_buffering/#numpy-write-array","text":"my_file = open(filepath, mode='wb') Open file in write binary mode Write my_arr.save(my_file) \u274c Write unncesary info (type, shape) my_arr.tofile(my_file) \u2705 Always write to disk my_file.write(my_arr.tobytes()) \u2705 Only writes to disk when buffer (8KB) is full. You can force to write by calling my_file.flush() or my_file.close()","title":"Numpy Write array"},{"location":"python/io_buffering/#list-slicing-withot-copy-data","text":"data = b\"abcdefgh\" data_view = memoryview(data) sub_data = data_view[1:3] https://julien.danjou.info/high-performance-in-python-with-zero-copy-and-the-buffer-protocol/","title":"List Slicing withot copy data"},{"location":"python/numpy/","text":"Write file_imgIdPerFaces = open(dest_path+'editorial_imgIdPerFaces_uint32', mode='wb') for path in tqdm(paths_editorial): np.array(img_id, dtype=\"uint32\").tofile(file_imgIds) np.load(path + \"/emb_img.npy\").tofile(file_imgEmbs) os.rename(dest_path+'editorial_imgIds_uint32', dest_path+f'editorial_imgIds_{num_total_imgs}_uint32') Read embs_creat = np.memmap(path+\"creativo_imgEmbs_1103426x512_float32\", dtype='float32', mode='r', shape=(1103426,512)) IO Redirection < > import sys, numpy sys.stdout.buffer.write(a.data) numpy.savetxt( sys.stdout.buffer, a ) https://stackoverflow.com/questions/51086704/append-numpy-matrix-to-binary-file-without-numpy-header","title":"\ud83d\udfe6 Parallel"},{"location":"python/numpy/#write","text":"file_imgIdPerFaces = open(dest_path+'editorial_imgIdPerFaces_uint32', mode='wb') for path in tqdm(paths_editorial): np.array(img_id, dtype=\"uint32\").tofile(file_imgIds) np.load(path + \"/emb_img.npy\").tofile(file_imgEmbs) os.rename(dest_path+'editorial_imgIds_uint32', dest_path+f'editorial_imgIds_{num_total_imgs}_uint32')","title":"Write"},{"location":"python/numpy/#read","text":"embs_creat = np.memmap(path+\"creativo_imgEmbs_1103426x512_float32\", dtype='float32', mode='r', shape=(1103426,512))","title":"Read"},{"location":"python/numpy/#io-redirection","text":"import sys, numpy sys.stdout.buffer.write(a.data) numpy.savetxt( sys.stdout.buffer, a ) https://stackoverflow.com/questions/51086704/append-numpy-matrix-to-binary-file-without-numpy-header","title":"IO Redirection &lt; &gt;"},{"location":"python/onnx/","text":"import onnx # LOAD MODEL onnx_model = onnx.load(\"model.onnx\") # SAVE MODEL onnx.save(onnx_model, \"model.onnx\") # CREATE Tensors t1 = onnx.helper.make_tensor_value_info('input', onnx.TensorProto.FLOAT, [\"BS\", 3, \"H\", \"W\"]) t2 = onnx.helper.make_tensor_value_info('scalar_tensor', onnx.TensorProto.INT64, []) def get_input(model, name): for elem in model.graph.input: if elem.name == name: return elem def get_node(model, name): for elem in model.graph.node: if elem.name == name: return elem def get_output(model, name): for elem in model.graph.output: if elem.name == name: return elem","title":"\u2b1c\ufe0f ONNX"},{"location":"python/parallel/","text":"IO intensive --> Concurrent --> Use Threads Python threads are only useful when functions take a long time because of IO (releases the GIL) Python threads are real system threads but parallel execution is forbidden because of GIL. Example of functions that releases the GIL: - Downloading - requesting an URL - opening a file... Python libraries that releases the GIL: - requsets - numpy - faiss - time.sleep(3) is not equivalent to a loop running for 3 seconds, burning CPU cycles while holding the GIL lock. The thread is switched away from for 3 seconds, allowing other threads to run. https://stackoverflow.com/a/61809931 http://www.dabeaz.com/python/UnderstandingGIL.pdf CPU instensive --> Parallel --> use Multiprocessing Conclusion asyncio threading multiprocessing Great for Concurrency Concurrency Parallelism _-_-_-_- _-_-_-_- ==== Great for IO intensive IO intensive CPU instensive swithing is controled by Program OS OS Access to same objects Yes Yes No, IPC is needed https://superfastpython.com/learning-paths/ from threading import Thread def worker(): \"\"\"thread worker function\"\"\" print('Worker') t = Thread(target=worker) t.start() Producer & consumer in parallel -> queue # SuperFastPython.com # example of using the queue with processes from time import sleep from random import random from multiprocessing import Process, Queue # generate work def producer(queue): print('Producer: Running', flush=True) # generate work for i in range(10): # generate a value value = random() # block sleep(value) # add to the queue queue.put(value) # all done queue.put(None) print('Producer: Done', flush=True) # consume work def consumer(queue): print('Consumer: Running', flush=True) # consume work while True: # get a unit of work item = queue.get() # check for stop if item is None: break # report print(f'>got {item}', flush=True) # all done print('Consumer: Done', flush=True) # entry point if __name__ == '__main__': # create the shared queue queue = Queue(maxsize=50) # start the consumer consumer_process = Process(target=consumer, args=(queue,)) consumer_process.start() # start the producer producer_process = Process(target=producer, args=(queue,)) producer_process.start() # wait for all processes to finish producer_process.join() consumer_process.join()","title":"Parallel"},{"location":"python/parallel/#io-intensive-concurrent-use-threads","text":"Python threads are only useful when functions take a long time because of IO (releases the GIL) Python threads are real system threads but parallel execution is forbidden because of GIL. Example of functions that releases the GIL: - Downloading - requesting an URL - opening a file... Python libraries that releases the GIL: - requsets - numpy - faiss - time.sleep(3) is not equivalent to a loop running for 3 seconds, burning CPU cycles while holding the GIL lock. The thread is switched away from for 3 seconds, allowing other threads to run. https://stackoverflow.com/a/61809931 http://www.dabeaz.com/python/UnderstandingGIL.pdf","title":"IO intensive --&gt; Concurrent --&gt; Use Threads"},{"location":"python/parallel/#cpu-instensive-parallel-use-multiprocessing","text":"","title":"CPU instensive --&gt; Parallel --&gt; use Multiprocessing"},{"location":"python/parallel/#conclusion","text":"asyncio threading multiprocessing Great for Concurrency Concurrency Parallelism _-_-_-_- _-_-_-_- ==== Great for IO intensive IO intensive CPU instensive swithing is controled by Program OS OS Access to same objects Yes Yes No, IPC is needed https://superfastpython.com/learning-paths/ from threading import Thread def worker(): \"\"\"thread worker function\"\"\" print('Worker') t = Thread(target=worker) t.start()","title":"Conclusion"},{"location":"python/parallel/#producer-consumer-in-parallel-queue","text":"# SuperFastPython.com # example of using the queue with processes from time import sleep from random import random from multiprocessing import Process, Queue # generate work def producer(queue): print('Producer: Running', flush=True) # generate work for i in range(10): # generate a value value = random() # block sleep(value) # add to the queue queue.put(value) # all done queue.put(None) print('Producer: Done', flush=True) # consume work def consumer(queue): print('Consumer: Running', flush=True) # consume work while True: # get a unit of work item = queue.get() # check for stop if item is None: break # report print(f'>got {item}', flush=True) # all done print('Consumer: Done', flush=True) # entry point if __name__ == '__main__': # create the shared queue queue = Queue(maxsize=50) # start the consumer consumer_process = Process(target=consumer, args=(queue,)) consumer_process.start() # start the producer producer_process = Process(target=producer, args=(queue,)) producer_process.start() # wait for all processes to finish producer_process.join() consumer_process.join()","title":"Producer &amp; consumer in parallel -&gt; queue"},{"location":"python/pytorch-lightning/","text":"from pytorch_lightning.utilities.cli import LightningCLI cli = LightningCLI() fit Runs the full optimization routine. validate Perform one evaluation epoch over the validation set. test Perform one evaluation epoch over the test set. predict Run inference on your data. tune Runs routines to tune hyperparameters before training. $ python trainer.py test --trainer.limit_test_batches=10 [...] # CONFIG FILES trainer: max_epochs: 10 limit_train_batches: 100 callbacks: - class_path: pytorch_lightning.callbacks.EarlyStopping init_args: patience: 5 - class_path: pytorch_lightning.callbacks.LearningRateMonitor init_args: ... python trainer.py fit --print_config python trainer.py fit --config experiment_defaults.yaml --trainer.max_epochs 100 # python trainer.py --config config1.yaml \\ --config config2.yaml test --config config3.yaml [...] ## TRAIN # python trainer.py fit \\ # --optimizer=Adam \\ # --optimizer.lr=0.01 \\ # --lr_scheduler=ExponentialLR \\ # --lr_scheduler.gamma=0.1 \\ # --trainer.callbacks=EarlyStopping \\ # --trainer.callbacks.patience=5 \\ # --trainer.callbacks=LearningRateMonitor \\ --trainer.callbacks.logging_interval=epoch --trainer.accelerator: null --trainer.accumulate_grad_batches: 1 --trainer.amp_backend: native --trainer.amp_level: O2 --model=MyModel --model.feat_dim=64 --data=MyData python trainer.py test chpt_path=\"ypur_best_model.ckpt\" python trainer.py test --trainer.limit_test_batches=10","title":"Pytorch lightning"},{"location":"python/pytorch-lightning/#fit-runs-the-full-optimization-routine","text":"","title":"fit         Runs the full optimization routine."},{"location":"python/pytorch-lightning/#validate-perform-one-evaluation-epoch-over-the-validation-set","text":"","title":"validate    Perform one evaluation epoch over the validation set."},{"location":"python/pytorch-lightning/#test-perform-one-evaluation-epoch-over-the-test-set","text":"","title":"test        Perform one evaluation epoch over the test set."},{"location":"python/pytorch-lightning/#predict-run-inference-on-your-data","text":"","title":"predict     Run inference on your data."},{"location":"python/pytorch-lightning/#tune-runs-routines-to-tune-hyperparameters-before-training","text":"$ python trainer.py test --trainer.limit_test_batches=10 [...]","title":"tune        Runs routines to tune hyperparameters before training."},{"location":"python/pytorch-lightning/#config-files","text":"trainer: max_epochs: 10 limit_train_batches: 100 callbacks: - class_path: pytorch_lightning.callbacks.EarlyStopping init_args: patience: 5 - class_path: pytorch_lightning.callbacks.LearningRateMonitor init_args: ...","title":"# CONFIG FILES"},{"location":"python/pytorch-lightning/#python-trainerpy-fit-print_config","text":"","title":"python trainer.py fit --print_config"},{"location":"python/pytorch-lightning/#python-trainerpy-fit-config-experiment_defaultsyaml-trainermax_epochs-100","text":"# python trainer.py --config config1.yaml \\ --config config2.yaml test --config config3.yaml [...]","title":"python trainer.py fit --config experiment_defaults.yaml --trainer.max_epochs 100"},{"location":"python/pytorch-lightning/#train","text":"# python trainer.py fit \\ # --optimizer=Adam \\ # --optimizer.lr=0.01 \\ # --lr_scheduler=ExponentialLR \\ # --lr_scheduler.gamma=0.1 \\ # --trainer.callbacks=EarlyStopping \\ # --trainer.callbacks.patience=5 \\ # --trainer.callbacks=LearningRateMonitor \\","title":"## TRAIN"},{"location":"python/pytorch-lightning/#-trainercallbackslogging_intervalepoch","text":"","title":"--trainer.callbacks.logging_interval=epoch"},{"location":"python/pytorch-lightning/#-traineraccelerator-null","text":"","title":"--trainer.accelerator: null"},{"location":"python/pytorch-lightning/#-traineraccumulate_grad_batches-1","text":"","title":"--trainer.accumulate_grad_batches: 1"},{"location":"python/pytorch-lightning/#-traineramp_backend-native","text":"","title":"--trainer.amp_backend: native"},{"location":"python/pytorch-lightning/#-traineramp_level-o2","text":"--model=MyModel --model.feat_dim=64 --data=MyData","title":"--trainer.amp_level: O2"},{"location":"python/pytorch-lightning/#python-trainerpy-test-chpt_pathypur_best_modelckpt","text":"","title":"python trainer.py test chpt_path=\"ypur_best_model.ckpt\""},{"location":"python/pytorch-lightning/#python-trainerpy-test-trainerlimit_test_batches10","text":"","title":"python trainer.py test --trainer.limit_test_batches=10"},{"location":"python/pytorch/","text":"Pytorch dataloader Naive implementatation Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502slow|slow| |slow| slow |unecesary\u2502 <-- No reads in parallel \u2502 CPU CORE1 \u2502read|read|...|read|Collate|copy from\u2502 <-- No queue/prefetching \u2502 Read batch 2 ... \u2502img1|img2| |imgN| |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 <-- No queue/prefetching on GPU \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 <-- Slow model \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Read faster Fast hardaware Try to store your dataset in a fast storage RAM SSDs NVMe RAID SSD NVMe SSDs SATA RAID SSD SATA HDD RAID HDD SATA Other machine in local network (/mnt/media mounting point) Internet Fast decoding libjpg-turbo Using jpeg4py : jpeg.JPEG(img).decode() instead of np.array(Image.open(img)) example of usage Using Pillow>=9.0.0 source Notese que a partir de la la verion 9 de PIL, viene por defecto Comprobar que PIL usa libjpg-turbo python import PIL.features print(PIL.features.check_feature(\"libjpeg_turbo\")) Even faster: Precompute tensors and save the on disk For reading just memap, No need to decoding Numpy Memmap Torch storage FFCV Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast| slow |unecesary\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Collate|copy from\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN| |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Fast collate (= concat imags into batch) https://www.pankesh.com/posts/2019-05-02-pytorch-augmentation-with-libjpeg-turbo/ Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast|fast|unecesary\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Coll|copy from\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN|ate |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The collate_fn is also useful to discard broken images # a collate function that filters the None records. def collate_fn(batch): # batch looks like [(x0,y0), (x4,y4), (x2,y2)... ] batch = [(Id, Date, Img) for (Id, Date, Img) in batch if Img is not None] #batch = list(filter(lambda x: x is not None, batch)) # Other way to do the same if len(batch) == 0: # If all images are broken, retrun None and discard in dl for loop return None, None, None else: return torch.utils.data.dataloader.default_collate(batch) Optimization: Avoid unnecessary host copies pin_memory=True Host (CPU) data allocations are pageable by default. The GPU cannot access data directly from pageable host memory, so when a data transfer from pageable host memory to device memory is invoked, the CUDA driver must first allocate a temporary page-locked, or \u201cpinned\u201d, host array, copy the host data to the pinned array, and then transfer the data from the pinned array to device memory, as illustrated below. https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/ if pin_memory=True is set on the Pytorch's dataloader, it will copy Tensors into device/CUDA pinned memory before returning them. Also, once you pin a tensor or storage, you can use asynchronous GPU copies. Just pass an additional non_blocking=True argument to a to() or a cuda() call. This can be used to overlap data transfers with computation. (Prefetching on GPU Optimization). Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast|fast\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Coll\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN|ate \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Optimization: Read images in parallel num_workers \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502 Read batch 1 \u2502 \u2502 Read batch 4 \u2502 (worker1) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502 Read batch 2 \u2502 \u00b7 \u2502 Read batch 5 \u2502 (worker2) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE3 \u2502 Read batch 3 \u2502 \u00b7 \u00b7 \u2502 Read batch 6 \u2502 (worker3) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER MODEL \u2502 \u2502 INFER MODEL \u2502 \u2502 INFER MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Memory optimization Avoid to each worker make a copy of the dataset!!! https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/ Optimization: Prefetching on CPU (Queue) prefetch_factor This is the defual behavior of Pytroch's dataloader . It does prefetching on the CPU RAM. the prefetch_factor parameter of PyTorch DataLoader class. The prefetch_factor parameter only controls CPU-side loading of the parallel data loader processes \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502Read batch 1\u2502Read batch 4\u2502Read batch 7\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502Read batch 2\u2502Read batch 5\u2502 \u2502Read batch 8\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CPU CORE3 \u2502Read batch 3\u2502Read batch 6\u2502 \u00b7 \u2502 Read B9 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 GPU \u2502INFER B1 into MODEL\u2502 \u2502INFER B2 into MODEL\u2502 \u2502INFER B3 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 But what are PyTorch DataLoaders really? Building a Multi-Process Data Loader from Scratch The full code for this project is available at github.com/teddykoker/tinyloader https://www.jpatrickpark.com/post/loader_sim/ Optimization: Prefetching on GPU \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502Read batch 1\u2502Read batch 4\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502Read batch 2\u2502Read batch 5\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE3 \u2502Read batch 3\u2502Read batch 6\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2502B4 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502INFER B1 into MODEL\u2502INFER B2 into MODEL\u2502INFER B3 into MODEL\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Prefetching Implementation #1: class data_prefetcher() in https://github.com/NVIDIA/apex/blob/master/examples/imagenet/main_amp.py#L265 Prefetching Implementation #2: Sacrife 1 data loader process into a prefetcher process https://www.jpatrickpark.com/post/prefetcher/ https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/ Achieving overlap between data transfers and other operations requires the use of CUDA streams, so first let\u2019s learn about streams. Faster Model: TensorRT engine --into--> TorchScript module https://pytorch.org/TensorRT/ https://pytorch.org/TensorRT/_notebooks/lenet-getting-started.html https://pytorch.org/TensorRT/py_api/ts.html?highlight=embed#torch_tensorrt.ts.embed_engine_in_new_module Summary For getting fast training/inference Data reading: Use fast data staorage hardware (RAM, NVMe, RAID,...) Use fast data decoding (libjpeg-turbo for images) Even faster is you store precomted tensors and load them with either Numpy.memmap torch.Storage FFIO Dataloader Read images in parallel num_workers Avoid unnecessary host copies pin_memory=True Prefetching on CPU (CPU Queue) prefetch_factor Prefetching on GPU (GPU Queue) Model TensorRT CUDA Programming Pytorch my_stream = torch.cuda.Stream() with torch.cuda.stream(my_stream): # Send data to GPU (NO BLOCKING) data = data.cuda(non_blocking=True) # or data.to(\"cuda\", non_blocking=True) PyCUDA my_stream = cuda.Stream() # Send data to GPU (NO BLOCKING) cuda.memcpy_htod_async(dest=gpu_mem[name], src=cpu_mem[name], stream=my_stream) cuda.memcpy_dtoh_async(dest=cpu_mem[name], src=gpu_mem[name], stream=my_stream) Copy betwwnn numpy and pytorch Copy by value, Deep copy Copy by reference, Shallow copy Numpy to Pytorch torch.tensor(my_npArr) torch.from_numpy(my_npArr) Pytorch to Numpy np.array(my_tensor) my_tensor.numpy() Reference Paul Bridger Twiter , Blog Solving Machine Learning Performance Anti-Patterns: a Systematic Approach Jun, 2021 Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization , Dec 2020 Horace He Twiter , Blog Making Deep Learning Go Brrrr From First Principles Mar, 2022 Another thing PyTorch 2.0 helps speed up - overhead Jan, 2023 Jungkyu Park Twiter Blog Visualizing data loaders to diagnose deep learning pipelines Apr, 2021 Data Prefetching on GPU in Deep Learning Feb, 2022 Yuxin Wu Twiter , Blog Demystify RAM Usage in Multi-Process Data Loaders Christian S. Perone https://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour Building a Multi-Process Data Loader from Scratch","title":"\ud83d\udfe5 Pytorch"},{"location":"python/pytorch/#pytorch-dataloader","text":"","title":"Pytorch dataloader"},{"location":"python/pytorch/#naive-implementatation","text":"Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502slow|slow| |slow| slow |unecesary\u2502 <-- No reads in parallel \u2502 CPU CORE1 \u2502read|read|...|read|Collate|copy from\u2502 <-- No queue/prefetching \u2502 Read batch 2 ... \u2502img1|img2| |imgN| |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 <-- No queue/prefetching on GPU \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 <-- Slow model \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Naive implementatation"},{"location":"python/pytorch/#read-faster","text":"","title":"Read faster"},{"location":"python/pytorch/#fast-hardaware","text":"Try to store your dataset in a fast storage RAM SSDs NVMe RAID SSD NVMe SSDs SATA RAID SSD SATA HDD RAID HDD SATA Other machine in local network (/mnt/media mounting point) Internet","title":"Fast hardaware"},{"location":"python/pytorch/#fast-decoding-libjpg-turbo","text":"Using jpeg4py : jpeg.JPEG(img).decode() instead of np.array(Image.open(img)) example of usage Using Pillow>=9.0.0 source Notese que a partir de la la verion 9 de PIL, viene por defecto Comprobar que PIL usa libjpg-turbo python import PIL.features print(PIL.features.check_feature(\"libjpeg_turbo\"))","title":"Fast decoding libjpg-turbo"},{"location":"python/pytorch/#even-faster","text":"Precompute tensors and save the on disk For reading just memap, No need to decoding Numpy Memmap Torch storage FFCV Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast| slow |unecesary\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Collate|copy from\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN| |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Even faster:"},{"location":"python/pytorch/#fast-collate-concat-imags-into-batch","text":"https://www.pankesh.com/posts/2019-05-02-pytorch-augmentation-with-libjpeg-turbo/ Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast|fast|unecesary\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Coll|copy from\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN|ate |pag 2 pin\u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 The collate_fn is also useful to discard broken images # a collate function that filters the None records. def collate_fn(batch): # batch looks like [(x0,y0), (x4,y4), (x2,y2)... ] batch = [(Id, Date, Img) for (Id, Date, Img) in batch if Img is not None] #batch = list(filter(lambda x: x is not None, batch)) # Other way to do the same if len(batch) == 0: # If all images are broken, retrun None and discard in dl for loop return None, None, None else: return torch.utils.data.dataloader.default_collate(batch)","title":"Fast collate (= concat imags into batch)"},{"location":"python/pytorch/#optimization-avoid-unnecessary-host-copies-pin_memorytrue","text":"Host (CPU) data allocations are pageable by default. The GPU cannot access data directly from pageable host memory, so when a data transfer from pageable host memory to device memory is invoked, the CUDA driver must first allocate a temporary page-locked, or \u201cpinned\u201d, host array, copy the host data to the pinned array, and then transfer the data from the pinned array to device memory, as illustrated below. https://developer.nvidia.com/blog/how-optimize-data-transfers-cuda-cc/ if pin_memory=True is set on the Pytorch's dataloader, it will copy Tensors into device/CUDA pinned memory before returning them. Also, once you pin a tensor or storage, you can use asynchronous GPU copies. Just pass an additional non_blocking=True argument to a to() or a cuda() call. This can be used to overlap data transfers with computation. (Prefetching on GPU Optimization). Read batch 1 (B1) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502fast|fast| |fast|fast\u2502 \u2502 CPU CORE1 \u2502read|read|...|read|Coll\u2502 \u2502 Read batch 2 ... \u2502img1|img2| |imgN|ate \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER B1 into MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Optimization: Avoid unnecessary host copies pin_memory=True"},{"location":"python/pytorch/#optimization-read-images-in-parallel-num_workers","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502 Read batch 1 \u2502 \u2502 Read batch 4 \u2502 (worker1) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502 Read batch 2 \u2502 \u00b7 \u2502 Read batch 5 \u2502 (worker2) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE3 \u2502 Read batch 3 \u2502 \u00b7 \u00b7 \u2502 Read batch 6 \u2502 (worker3) \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502 INFER MODEL \u2502 \u2502 INFER MODEL \u2502 \u2502 INFER MODEL \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Optimization: Read images in parallel num_workers"},{"location":"python/pytorch/#memory-optimization","text":"Avoid to each worker make a copy of the dataset!!! https://ppwwyyxx.com/blog/2022/Demystify-RAM-Usage-in-Multiprocess-DataLoader/","title":"Memory optimization"},{"location":"python/pytorch/#optimization-prefetching-on-cpu-queue-prefetch_factor","text":"This is the defual behavior of Pytroch's dataloader . It does prefetching on the CPU RAM. the prefetch_factor parameter of PyTorch DataLoader class. The prefetch_factor parameter only controls CPU-side loading of the parallel data loader processes \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502Read batch 1\u2502Read batch 4\u2502Read batch 7\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502Read batch 2\u2502Read batch 5\u2502 \u2502Read batch 8\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u00b7 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 CPU CORE3 \u2502Read batch 3\u2502Read batch 6\u2502 \u00b7 \u2502 Read B9 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u00b7 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502 \u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 GPU \u2502INFER B1 into MODEL\u2502 \u2502INFER B2 into MODEL\u2502 \u2502INFER B3 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 But what are PyTorch DataLoaders really? Building a Multi-Process Data Loader from Scratch The full code for this project is available at github.com/teddykoker/tinyloader https://www.jpatrickpark.com/post/loader_sim/","title":"Optimization: Prefetching on CPU (Queue) prefetch_factor"},{"location":"python/pytorch/#optimization-prefetching-on-gpu","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE1 \u2502Read batch 1\u2502Read batch 4\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE2 \u2502Read batch 2\u2502Read batch 5\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU CORE3 \u2502Read batch 3\u2502Read batch 6\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 CPU 2 GPU \u2502B1 to GPU\u2502B2 to GPU\u2502 \u2502B3 to GPU\u2502 \u2502B4 to GPU\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 GPU \u2502INFER B1 into MODEL\u2502INFER B2 into MODEL\u2502INFER B3 into MODEL\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Prefetching Implementation #1: class data_prefetcher() in https://github.com/NVIDIA/apex/blob/master/examples/imagenet/main_amp.py#L265 Prefetching Implementation #2: Sacrife 1 data loader process into a prefetcher process https://www.jpatrickpark.com/post/prefetcher/ https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/ Achieving overlap between data transfers and other operations requires the use of CUDA streams, so first let\u2019s learn about streams.","title":"Optimization: Prefetching on GPU"},{"location":"python/pytorch/#faster-model-tensorrt-engine-into-torchscript-module","text":"https://pytorch.org/TensorRT/ https://pytorch.org/TensorRT/_notebooks/lenet-getting-started.html https://pytorch.org/TensorRT/py_api/ts.html?highlight=embed#torch_tensorrt.ts.embed_engine_in_new_module","title":"Faster Model: TensorRT engine --into--&gt; TorchScript module"},{"location":"python/pytorch/#summary","text":"For getting fast training/inference Data reading: Use fast data staorage hardware (RAM, NVMe, RAID,...) Use fast data decoding (libjpeg-turbo for images) Even faster is you store precomted tensors and load them with either Numpy.memmap torch.Storage FFIO Dataloader Read images in parallel num_workers Avoid unnecessary host copies pin_memory=True Prefetching on CPU (CPU Queue) prefetch_factor Prefetching on GPU (GPU Queue) Model TensorRT","title":"Summary"},{"location":"python/pytorch/#cuda-programming","text":"Pytorch my_stream = torch.cuda.Stream() with torch.cuda.stream(my_stream): # Send data to GPU (NO BLOCKING) data = data.cuda(non_blocking=True) # or data.to(\"cuda\", non_blocking=True) PyCUDA my_stream = cuda.Stream() # Send data to GPU (NO BLOCKING) cuda.memcpy_htod_async(dest=gpu_mem[name], src=cpu_mem[name], stream=my_stream) cuda.memcpy_dtoh_async(dest=cpu_mem[name], src=gpu_mem[name], stream=my_stream)","title":"CUDA Programming"},{"location":"python/pytorch/#copy-betwwnn-numpy-and-pytorch","text":"Copy by value, Deep copy Copy by reference, Shallow copy Numpy to Pytorch torch.tensor(my_npArr) torch.from_numpy(my_npArr) Pytorch to Numpy np.array(my_tensor) my_tensor.numpy()","title":"Copy betwwnn numpy and pytorch"},{"location":"python/pytorch/#reference","text":"Paul Bridger Twiter , Blog Solving Machine Learning Performance Anti-Patterns: a Systematic Approach Jun, 2021 Object Detection at 2530 FPS with TensorRT and 8-Bit Quantization , Dec 2020 Horace He Twiter , Blog Making Deep Learning Go Brrrr From First Principles Mar, 2022 Another thing PyTorch 2.0 helps speed up - overhead Jan, 2023 Jungkyu Park Twiter Blog Visualizing data loaders to diagnose deep learning pipelines Apr, 2021 Data Prefetching on GPU in Deep Learning Feb, 2022 Yuxin Wu Twiter , Blog Demystify RAM Usage in Multi-Process Data Loaders Christian S. Perone https://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour Building a Multi-Process Data Loader from Scratch","title":"Reference"}]}