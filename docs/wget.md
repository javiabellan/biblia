# `Wget`

- `wget URL`:                    Download and store in the current directory.
- `wget -O CUSTOM_FILENAME URL`: Download and store in the current directory with a different file name.
- `wget -O - URL`:               Download and redirects to stdout
- `wget --limit-rate=200k URL`:  Specify download speed. Here speed is limited to 200k.
- `wget -c URL`:                 Continue the Incomplete Download
- `wget -b URL`:                 Download in the Background
- `wget --spider URL`:           Not download the webpage, just check that it is there.
- `wget --tries=75 URL`:         Increase Total Number of Retry Attempts
- `wget -i FILE_WITH_URLS.txt`   Download multiple URLs. Each line in the txt document is a URL.
- `-m` `--mirror`:               Turns on infinite recursion and time-stamping, and keeps FTP directory listings.
  - `-r` `--recursive`           Turn on recursive retrieving. The default maximum depth is 5.
  - `-l depth` `--level=depth`   Set the maximum number of subdirectories that Wget will recurse into to depth. `inf` means infinite
  - `-N` `--timestamping`        Turn on time-stamping.
  - `--no-remove-listing`        Don't remove the .listing files generated by FTP retrievals.
- `-p` `--page-requisites`       Downloads all files that are necessary to properly display a given HTML page.
- `-k` `--convert-links`         After the download, convert the external links to make the work.

-P ./LOCAL-DIR saves all the files and directories to the specified directory.
- `wget --mirror --page-requisites --convert-links -P ./LOCAL_DIR URL`: Download a Full Website
- `wget -Q5m -i FILE_WITH_URLS.txt`:   Quit Downloading When it Exceeds Certain Size
- `wget --ftp-user=USERNAME --ftp-password=PASSWORD URL`: FTP Download With wget
- `wget --reject=gif URL`:       Reject Certain File Types while Downloading
- `wget -o download.log URL`:    Log messages to a log file instead of stderr Using wget -o
